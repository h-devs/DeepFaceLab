<!DOCTYPE html>
<!-- saved from url=(0065)https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide -->
<html xml:lang="en" lang="en" xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>[GUIDE] - DeepFaceLab 2.0 Guide</title>
<!-- start: headerinclude -->

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="alternate" type="application/rss+xml" title="Latest Threads (RSS 2.0)" href="https://mrdeepfakes.com/forums/syndication.php">
<link rel="alternate" type="application/atom+xml" title="Latest Threads (Atom 1.0)" href="https://mrdeepfakes.com/forums/syndication.php?type=atom1.0">
<link rel="shortcut icon" type="image/png" href="https://mrdeepfakes.com/forums/images/generic/favicon.png">

<link href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/css" rel="stylesheet"> 
<link rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/font-awesome.min.css">
<link href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/jquery.tipsy.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/bootstrap.min.css">
<!-- UNREADPOSTS_CSS -->
<link href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/normalize.css" rel="stylesheet" type="text/css">
<link href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/index-sidebar.css" rel="stylesheet" type="text/css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/g33k_thankyoulike.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/showthread.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star_ratings.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/css3.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/alerts.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/global.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/theme.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/blue.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/responsive.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/thankyoulike.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/mentionme.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/automedia.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatarep.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/kvs.min.css">
<link type="text/css" rel="stylesheet" href="./[GUIDE] - DeepFaceLab 2.0 Guide_files/css.php">

<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/analytics.js.download"></script><script src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/jquery.min.js.download"></script>
<script src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/jquery-ui.js.download"></script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/inewsticker.js.download"></script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/jquery.js.download"></script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/jquery.plugins.min.js.download"></script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/general.js.download"></script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/theme.js.download"></script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatarep.js.download"></script>

<script type="text/javascript">
<!--
	lang.unknown_error = "An unknown error has occurred.";

	lang.select2_match = "One result is available, press enter to select it.";
	lang.select2_matches = "{1} results are available, use up and down arrow keys to navigate.";
	lang.select2_nomatches = "No matches found";
	lang.select2_inputtooshort_single = "Please enter one or more character";
	lang.select2_inputtooshort_plural = "Please enter {1} or more characters";
	lang.select2_inputtoolong_single = "Please delete one character";
	lang.select2_inputtoolong_plural = "Please delete {1} characters";
	lang.select2_selectiontoobig_single = "You can only select one item";
	lang.select2_selectiontoobig_plural = "You can only select {1} items";
	lang.select2_loadmore = "Loading more results…";
	lang.select2_searching = "Searching…";

	var cookieDomain = ".mrdeepfakes.com";
	var cookiePath = "/forums/";
	var cookiePrefix = "mybb";
	var cookieSecureFlag = "1";
	var deleteevent_confirm = "Are you sure you want to delete this event?";
	var removeattach_confirm = "Are you sure you want to remove the selected attachment from this post?";
	var loading_text = 'Loading. <br />Please Wait..';
	var saving_changes = 'Saving changes..';
	var use_xmlhttprequest = "1";
	var my_post_key = "0081696a220f9ed52fb7f1b39d30dbc9";
	var rootpath = "https://mrdeepfakes.com/forums";
	var imagepath = "https://mrdeepfakes.com/forums/images/generic";
  	var yes_confirm = "Yes";
	var no_confirm = "No";
	var MyBBEditor = null;
	var spinner_image = "https://mrdeepfakes.com/forums/images/generic/spinner.gif";
	var spinner = "<img src='" + spinner_image +"' alt='' />";
	var modal_zindex = 9999;
// -->
</script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/tabcontent.js.download">
</script>

<style>
ul.mycode_list, ol.mycode_list {
    margin: 15px 0 15px 30px;
}
ul.mycode_list li, ol.mycode_list li {
    list-style: initial;
} 
</style>
<!-- end: headerinclude -->
<script>
<!--
	var quickdelete_confirm = "Are you sure you want to delete this post?";
	var quickrestore_confirm = "Are you sure you want to restore this post?";
	var allowEditReason = "1";
	lang.save_changes = "Save Changes";
	lang.cancel_edit = "Cancel Edit";
	lang.quick_edit_update_error = "There was an error editing your reply:";
	lang.quick_reply_post_error = "There was an error posting your reply:";
	lang.quick_delete_error = "There was an error deleting your reply:";
	lang.quick_delete_success = "The post was deleted successfully.";
	lang.quick_delete_thread_success = "The thread was deleted successfully.";
	lang.quick_restore_error = "There was an error restoring your reply:";
	lang.quick_restore_success = "The post was restored successfully.";
	lang.editreason = "Edit Reason";
// -->
</script>
<!-- jeditable (jquery) -->
<script src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/report.js.download"></script>
<script src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/jeditable.min.js.download"></script>
<script src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/thread.js.download"></script>	
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/thankyoulike.min.js.download"></script>
<script type="text/javascript">
<!--
	var tylEnabled = "1";
	var tylDisplayGrowl = "1";
	var tylCollapsible = "1";
	var tylUser = "0";
	var tylSend = "Added Like to this post";
	var tylRemove = "Removed Like from this post";
// -->
</script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/thankyoulike.min.js.download"></script>
<script type="text/javascript">
<!--
	var tylEnabled = "1";
	var tylDisplayGrowl = "1";
	var tylCollapsible = "1";
	var tylUser = "0";
	var tylSend = "Added Like to this post";
	var tylRemove = "Removed Like from this post";
// -->
</script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/thread.min.js.download"></script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/thankyoulike.min.js.download"></script>
<script type="text/javascript">
<!--
	var tylEnabled = "1";
	var tylDisplayGrowl = "1";
	var tylCollapsible = "1";
	var tylUser = "0";
	var tylSend = "Added Like to this post";
	var tylRemove = "Removed Like from this post";
// -->
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-113474462-1', 'auto');
  ga('send', 'pageview');

</script><meta name="description" content="DeepFaceLab 2.0 Guide For general discussion and support please post in this thread: You are not allowed to view links. Register or Login to view. Before you ask a new question read all the guides/FAQ">
<link rel="canonical" href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide">
<style type="text/css">.a2a_menu,.a2a_menu *{-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box;float:none;margin:0;padding:0;position:static;height:auto;width:auto}.a2a_menu{border-radius:6px;display:none;direction:ltr;background:#FFF;font:16px sans-serif-light,HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Arial,Helvetica,"Liberation Sans",sans-serif;color:#000;line-height:12px;border:1px solid #CCC;vertical-align:baseline;overflow:hidden}.a2a_mini{min-width:200px;position:absolute;width:300px;z-index:9999997}.a2a_overlay{display:none;background:#616c7d;_height:expression( ((e=document.documentElement.clientHeight)?e:document.body.clientHeight)+"px" );_width:expression( ((e=document.documentElement.clientWidth)?e:document.body.clientWidth)+"px" );filter:alpha(opacity=90);opacity:.92;backdrop-filter:blur(8px);position:fixed;_position:absolute;top:0;right:0;left:0;bottom:0;z-index:9999998;-webkit-tap-highlight-color:rgba(0,0,0,0);transition:opacity .14s,backdrop-filter .14s}.a2a_full{background:#FFF;border:1px solid #FFF;height:auto;height:calc(320px);top:15%;_top:expression(40+((e=document.documentElement.scrollTop)?e:document.body.scrollTop)+"px");left:50%;margin-left:-320px;position:fixed;_position:absolute;text-align:center;width:640px;z-index:9999999;transition:transform .14s,opacity .14s}.a2a_full_footer,.a2a_full_header,.a2a_full_services{border:0;margin:0;padding:12px;box-sizing:border-box}.a2a_full_header{padding-bottom:8px}.a2a_full_services{height:280px;overflow-y:scroll;padding:0 12px;-webkit-overflow-scrolling:touch}.a2a_full_services .a2a_i{display:inline-block;float:none;width:181px;width:calc(33.334% - 18px)}div.a2a_full_footer{font-size:12px;text-align:center;padding:8px 14px}div.a2a_full_footer a,div.a2a_full_footer a:visited{display:inline;font-size:12px;line-height:14px;padding:8px 14px}div.a2a_full_footer a:focus,div.a2a_full_footer a:hover{background:0 0;border:0;color:#0166FF}div.a2a_full_footer a span.a2a_s_a2a,div.a2a_full_footer a span.a2a_w_a2a{background-size:14px;border-radius:3px;display:inline-block;height:14px;line-height:14px;margin:0 3px 0 0;vertical-align:top;*vertical-align:middle;width:14px}.a2a_modal{height:0;left:50%;margin-left:-320px;position:fixed;_position:absolute;text-align:center;top:15%;_top:expression(40+((e=document.documentElement.scrollTop)?e:document.body.scrollTop)+"px");width:640px;z-index:9999999;transition:transform .14s,opacity .14s;-webkit-tap-highlight-color:rgba(0,0,0,0)}.a2a_modal_body{background:0 0;border:0;font:24px sans-serif-light,HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Arial,Helvetica,"Liberation Sans",sans-serif;position:relative;height:auto;width:auto}.a2a_thanks{color:#fff;height:auto;margin-top:20px;width:auto}.a2a_thanks>div:first-child{margin:0 0 40px 0}.a2a_thanks div *{height:inherit}#a2a_copy_link{background:#FFF;border:1px solid #FFF;margin-top:15%}span.a2a_s_link#a2a_copy_link_icon,span.a2a_w_link#a2a_copy_link_icon{background-size:48px;border-radius:0;display:inline-block;height:48px;left:0;line-height:48px;margin:0 3px 0 0;position:absolute;vertical-align:top;*vertical-align:middle;width:48px}#a2a_modal input#a2a_copy_link_text{background-color:transparent;_background-color:#FFF;border:0;color:#2A2A2A;font:inherit;height:48px;left:62px;max-width:initial;padding:0;position:relative;width:564px;width:calc(100% - 76px)}#a2a_copy_link_copied{background-color:#0166ff;color:#fff;display:none;font:inherit;font-size:16px;margin-top:1px;padding:3px 8px}@media (prefers-color-scheme:dark){.a2a_menu a,.a2a_menu a.a2a_i,.a2a_menu a.a2a_i:visited,.a2a_menu a.a2a_more,i.a2a_i{border-color:#2a2a2a!important;color:#fff!important}.a2a_menu a.a2a_i:active,.a2a_menu a.a2a_i:focus,.a2a_menu a.a2a_i:hover,.a2a_menu a.a2a_more:active,.a2a_menu a.a2a_more:focus,.a2a_menu a.a2a_more:hover,.a2a_menu_find_container{border-color:#444!important;background-color:#444!important}.a2a_menu{background-color:#2a2a2a;border-color:#2a2a2a}.a2a_menu_find{color:#fff!important}.a2a_menu span.a2a_s_find svg{background-color:transparent!important}.a2a_menu span.a2a_s_find svg path{fill:#fff!important}}@media print{.a2a_floating_style,.a2a_menu,.a2a_overlay{visibility:hidden}}@keyframes a2aFadeIn{from{opacity:0}to{opacity:1}}.a2a_starting{opacity:0}.a2a_starting.a2a_full,.a2a_starting.a2a_modal{transform:scale(.8)}@media (max-width:639px){.a2a_full{border-radius:0;top:15%;left:0;margin-left:auto;width:100%}.a2a_modal{left:0;margin-left:10px;width:calc(100% - 20px)}}@media (min-width:318px) and (max-width:437px){.a2a_full .a2a_full_services .a2a_i{width:calc(50% - 18px)}}@media (max-width:317px){.a2a_full .a2a_full_services .a2a_i{width:calc(100% - 18px)}}@media (max-height:436px){.a2a_full{bottom:40px;height:auto;top:40px}}@media (max-height:550px){.a2a_modal{top:30px}}@media (max-height:360px){.a2a_modal{top:20px}.a2a_thanks>div:first-child{margin-bottom:20px}}.a2a_menu a{color:#0166FF;text-decoration:none;font:16px sans-serif-light,HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Arial,Helvetica,"Liberation Sans",sans-serif;line-height:14px;height:auto;width:auto;outline:0}.a2a_menu a.a2a_i:visited,.a2a_menu a.a2a_more{color:#0166FF}.a2a_menu a.a2a_i:active,.a2a_menu a.a2a_i:focus,.a2a_menu a.a2a_i:hover,.a2a_menu a.a2a_more:active,.a2a_menu a.a2a_more:focus,.a2a_menu a.a2a_more:hover{color:#2A2A2A;border-color:#EEE;border-style:solid;background-color:#EEE;text-decoration:none}.a2a_menu span.a2a_s_find{background-size:24px;height:24px;left:8px;position:absolute;top:7px;width:24px}.a2a_menu span.a2a_s_find svg{background-color:#FFF}.a2a_menu span.a2a_s_find svg path{fill:#CCC}#a2a_menu_container{display:inline-block}#a2a_menu_container{_display:inline}.a2a_menu_find_container{border:1px solid #CCC;border-radius:6px;padding:2px 24px 2px 0;position:relative;text-align:left}.a2a_cols_container .a2a_col1{overflow-x:hidden;overflow-y:auto;-webkit-overflow-scrolling:touch}#a2a_modal input,#a2a_modal input[type=text],.a2a_menu input,.a2a_menu input[type=text]{display:block;background-image:none;box-shadow:none;line-height:100%;margin:0;outline:0;overflow:hidden;padding:0;-moz-box-shadow:none;-webkit-box-shadow:none;-webkit-appearance:none}#a2apage_find_container input,#a2apage_find_container input[type=text]{background-color:transparent;_background-color:#FFF;border:0;box-sizing:content-box;color:#2A2A2A;font:inherit;font-size:16px;height:28px;line-height:20px;left:38px;outline:0;margin:0;max-width:initial;padding:2px 0;position:relative;width:99%}.a2a_clear{clear:both} .a2a_svg{background-repeat:no-repeat;display:block;overflow:hidden;height:32px;line-height:32px;padding:0;width:32px}.a2a_svg svg{background-repeat:no-repeat;background-position:50% 50%;border:none;display:block;left:0;margin:0 auto;overflow:hidden;padding:0;position:relative;top:0;width:auto;height:auto}a.a2a_i,i.a2a_i{display:block;float:left;border:1px solid #FFF;line-height:24px;padding:6px 8px;text-align:left;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;width:132px}a.a2a_i span,a.a2a_more span{display:inline-block;overflow:hidden;vertical-align:top;*vertical-align:middle}a.a2a_i .a2a_svg{margin:0 6px 0 0}a.a2a_i .a2a_svg,a.a2a_more .a2a_svg{background-size:24px;height:24px;line-height:24px;width:24px}a.a2a_sss:hover{border-left:1px solid #CCC}a.a2a_menu_show_more_less{border-bottom:1px solid #FFF;border-left:0;border-right:0;line-height:24px;margin:6px 0 0;padding:6px;-webkit-touch-callout:none}a.a2a_menu_show_more_less span{display:inline-block;height:24px;margin:0 6px 0 0}.a2a_kit .a2a_svg{background-repeat:repeat}.a2a_default_style a{float:left;line-height:16px;padding:0 2px}.a2a_default_style a:hover .a2a_svg,.a2a_floating_style a:hover .a2a_svg,.a2a_overlay_style a:hover .a2a_svg svg{opacity:.7}.a2a_overlay_style.a2a_default_style a:hover .a2a_svg{opacity:1}.a2a_default_style .a2a_count,.a2a_default_style .a2a_svg,.a2a_floating_style .a2a_svg,.a2a_menu .a2a_svg,.a2a_vertical_style .a2a_count,.a2a_vertical_style .a2a_svg{border-radius:4px}.a2a_default_style .a2a_counter img,.a2a_default_style .a2a_dd,.a2a_default_style .a2a_svg{float:left}.a2a_default_style .a2a_img_text{margin-right:4px}.a2a_default_style .a2a_divider{border-left:1px solid #000;display:inline;float:left;height:16px;line-height:16px;margin:0 5px}.a2a_kit a{cursor:pointer}.a2a_floating_style{background-color:#fff;border-radius:6px;position:fixed;z-index:9999995}.a2a_overlay_style{z-index:2147483647}.a2a_floating_style,.a2a_overlay_style{animation:a2aFadeIn .2s ease-in;padding:4px}.a2a_vertical_style a{clear:left;display:block;overflow:hidden;padding:4px;text-decoration:none}.a2a_floating_style.a2a_default_style{bottom:0}.a2a_floating_style.a2a_default_style a,.a2a_overlay_style.a2a_default_style a{padding:4px}.a2a_count{background-color:#fff;border:1px solid #ccc;box-sizing:border-box;color:#2a2a2a;display:block;float:left;font:12px Arial,Helvetica,sans-serif;height:16px;margin-left:4px;position:relative;text-align:center;width:50px}.a2a_count:after,.a2a_count:before{border:solid transparent;border-width:4px 4px 4px 0;content:"";height:0;left:0;line-height:0;margin:-4px 0 0 -4px;position:absolute;top:50%;width:0}.a2a_count:before{border-right-color:#ccc}.a2a_count:after{border-right-color:#fff;margin-left:-3px}.a2a_count span{animation:a2aFadeIn .14s ease-in}.a2a_vertical_style .a2a_counter img{display:block}.a2a_vertical_style .a2a_count{float:none;margin-left:0;margin-top:6px}.a2a_vertical_style .a2a_count:after,.a2a_vertical_style .a2a_count:before{border:solid transparent;border-width:0 4px 4px 4px;content:"";height:0;left:50%;line-height:0;margin:-4px 0 0 -4px;position:absolute;top:0;width:0}.a2a_vertical_style .a2a_count:before{border-bottom-color:#ccc}.a2a_vertical_style .a2a_count:after{border-bottom-color:#fff;margin-top:-3px}.a2a_nowrap{white-space:nowrap}.a2a_note{margin:0 auto;padding:9px;font-size:12px;text-align:center}.a2a_note .a2a_note_note{margin:0;color:#2A2A2A}.a2a_wide a{display:block;margin-top:3px;border-top:1px solid #EEE;text-align:center}.a2a_label{position:absolute!important;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);clip-path:polygon(0 0,0 0,0 0);-webkit-clip-path:polygon(0 0,0 0,0 0);overflow:hidden;height:1px;width:1px}.a2a_kit,.a2a_menu,.a2a_modal,.a2a_overlay{-ms-touch-action:manipulation;touch-action:manipulation;outline:0}.a2a_dd img{border:0}.a2a_button_facebook_like iframe{max-width:none}</style></head>
<body>
<!-- start: header -->
<script>
        function kvsForm(page) {
		$.get("https://mrdeepfakes.com/"+page, function(data) {
                        try{
                          let r = JSON.parse(data);
                          if (r.reload) {
                            location.reload();
                          }
                        } catch(e) {
                           //do nothing
                        }
                        var sec = $(data);
                        sec.find("form").submit(function(e){
                            e.preventDefault();
                            $.ajax({
                              url: '/'+page,
                              type: 'POST',
                              data: $(this).serialize() + "&format=json&mode=async",
                              success: function(r) {
                                  if (r === '') {
                                    location.reload();
                                  }
                                  if (r.status == "failure")  {
                                      for (var idx in r.errors) {
                                        var err = r.errors[idx];
                                        if (err.block == "logon" ) {
                                          sec.find(".generic-error").removeClass('hidden').css('display','block').html(err.message)
                                        } else {
                                          var inp = $("#"+err.block+"_"+err.field).addClass("error");
                                          inp.next().css('display','block').html(err.message);
                                        }
                                      }
                                      return false;
                                  }
                                  if (page == "login") {
                                    window.location = "https://mrdeepfakes.com/static/login";
                                  } else {
                                    window.location = "https://mrdeepfakes.com/static/register-thank-you";
                                  }
                                
                              }
                            });
                        });
			$('#'+page+'_quick .modal-dialog').html(sec);
			$('#'+page+'_quick').modal({ fadeDuration: 250, keepelement: true }); return false;
		});

		return false;
	}
        function signup() {
		$.get("https://mrdeepfakes.com/signup", function(data) {
                        var signup = $(data);
                        signup.find("form").submit(function(e){
                            e.preventDefault();
                            $.ajax({
                              url: '/signup',
                              type: 'POST',
                              data: $(this).serialize() + "&format=json&mode=async",
                              success: function(r) {
                                  if (r.status == "failure")  {
                                      for (var idx in r.errors) {
                                        var err = r.errors[idx];
                                        var inp = $("#"+err.block+"_"+err.field).addClass("error");
                                        inp.next().css('display','block').html(err.message);
                                      }
                                      return false;
                                  }
                                  window.location = "https://mrdeepfakes.com/static/register-thank-you";
                                
                              }
                            });
                        });
			$('#quick_register .modal-dialog').html(signup);
			$('#quick_register').modal({ fadeDuration: 250, keepelement: true }); return false;
		});

		return false;
	}
</script>
<div id="container">
<div id="header-navbar">
	<nav class="navbar navbar-inverse navbar-no-corners">
        	<div class="usersection">
				<!-- start: header_welcomeblock_guest -->

<div class="welcome-guest">
<a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;);" class="btn btn-sm btn-login"><i class="fa fa-power-off"></i> Login</a>
<a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);" class="btn btn-sm btn-register"><i class="fa fa-pencil-square-o"></i> Register</a>
</div> 
<div class="modal kvs" role="dialog" id="login_quick">
	<div class="modal-dialog" style="text-align:left;background-color:black;">
	</div>	
</div>
<div class="modal kvs" role="dialog" id="signup_quick">
	<div class="modal-dialog" style="min-width: 42rem;background-color: #151515;">
	</div>	
</div>
<script>
	$("#login_quick input[name='url']").val($(location).attr('href'));
</script>
<!-- end: header_welcomeblock_guest -->
				<!-- <a class="tt pull-right searchbtn" href="#search" title="Quick Search"><i class="fa fa-search-plus"></i></a> -->
        	</div>
  		<div class="container-fluid">
    		<div class="navbar-header">	
            <a class="visible-xs" style="float: left;" href="https://mrdeepfakes.com/forums"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/icon.png" alt="MrDeepFakes Forums" title="MrDeepFakes Forums"></a>			
      			<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
        			<span class="icon-bar"></span>
        			<span class="icon-bar"></span>
        			<span class="icon-bar"></span> 
      			</button>
   			</div>
    		<div class="collapse navbar-collapse" id="myNavbar">
			<div id="logo" class="col-lg-1 pull-left hidden-xs">
					<a href="https://mrdeepfakes.com/forums"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/icon.png" alt="MrDeepFakes Forums" title="MrDeepFakes Forums"></a>
			</div>			
     			<ul class="col-lg-8 nav navbar-nav text-center" style="width: 780px;">
					<li><a href="https://mrdeepfakes.com/" style="color: #da2657"> DeepFake Porn</a></li>
					<li><a href="https://mrdeepfakes.com/forums/"> Forums</a></li>
					<!-- start: header_menu_portal -->
<li><a href="https://mrdeepfakes.com/forums/portal.php">Portal</a></li>
<!-- end: header_menu_portal -->
					<!-- start: header_menu_search -->
<li><a href="https://mrdeepfakes.com/forums/search.php" class="search">Search</a></li>
<!-- end: header_menu_search -->
					<!-- start: header_menu_memberlist -->
<li><a href="https://mrdeepfakes.com/forums/memberlist.php">Members</a></li>
<!-- end: header_menu_memberlist -->
                                        <li class="rules_link"><a href="https://mrdeepfakes.com/forums/misc.php?action=rules" class="rules" border="0" alt="">Rules</a></li>
    <li style="margin-top: 27px;height: 0;margin-left: 10px;" class="li-more">
        <a data-target="#" href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" data-toggle="dropdown" class="dropdown-toggle" style="padding: 0;">
		<main><i class="tt label fa fa-chevron-down" title="CLICK" style="display: block;padding: 7px;background: rgba(250, 250, 250, .1);font-size: 14px;"></i></main>
		</a>
        <ul class="dropdown-menu" style="margin-top: 55px;background-color: rgba(56, 62, 71, 1);">
            <li class="vmore"><a href="https://mrdeepfakes.com/forums/search.php?action=unreads"><i class="fa fa-eye-slash" style="margin-right: 5px;"></i>Unread Posts</a></li>
            <li class="vmore"><a href="https://mrdeepfakes.com/forums/search.php?action=getnew"><i class="fa fa-eye" style="margin-right: 5px;"></i>View New Posts</a></li>
            <li class="vmore"><a href="https://mrdeepfakes.com/forums/search.php?action=getdaily"><i class="fa fa-eye" style="margin-right: 5px;"></i>View Today's Posts</a></li>
	        <li class="vmore"><a href="https://mrdeepfakes.com/forums/misc.php?action=help" title="FAQ"><i class="fa fa-support" style="margin-right: 5px;"></i>Help</a></li>

        </ul>   
    </li>
				</ul>	
    		</div>
  		</div>
	</nav>
</div>
	
<div class="hbanner">
	<div class="logo-inner">
		<a href="https://mrdeepfakes.com/forums/index.php"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/forums_logo.png" alt="MrDeepFakes Forums" title="MrDeepFakes Forums"></a>
	</div>
</div>
				
<div id="search">
    <button type="button" class="close"><i class="fa fa-times"></i></button>
    <form class="search-form" action="https://mrdeepfakes.com/forums/search.php" method="post">
		<input type="hidden" name="action" value="do_search">
         <input type="hidden" name="postthread" value="1">
         <input type="hidden" name="forums" value="all">
         <input type="hidden" name="showresults" value="threads">
        <input type="search" name="keywords" placeholder="type keyword(s) here">
        <button type="submit" class="btn btn-primary">Search</button>
    </form>
</div>
	
	<div id="content">
	  	<div class="main-wrapper">
		<div class="wrapper">
			
			
			
			
			
			 <!-- BAM --><!-- start: bam_announcement_container -->

<style>
        .bam_announcement {
             color:black !important;
        }
	.bam_announcement.yellow {
		background: #FFF6BF;
		border: 1px solid #FFD324;
	}

	.bam_announcement.green {
		background: #D6ECA6;
		border: 1px solid #8DC93E;
	}

	.bam_announcement.blue {
		background: #ADCBE7;
		border: 1px solid #0F5C8E;
	}

	.bam_announcement.red {
		background: #FBE3E4;
		border: 1px solid #A5161A;
	}

	.bam_announcement {
		-moz-border-radius: 5px;
		-webkit-border-radius: 5px;
		border-radius: 5px; 
		text-align: center;
		margin: 10px auto;
		padding: 8px 12px;
		background: #EBEBEB;
		color: #000000;
		border: 1px solid #ADADAD;
	}

	.bam_date {
		color: #636161;
		font-size: 0.78em;
		margin-left: 6px;
	}	

	/* Insert Custom CSS Here */
</style>
<div class="bam_announcements container-fluid"></div>
<!-- end: bam_announcement_container --><!-- /BAM -->
			<!-- start: nav -->
<div class="title_wrapper container-fluid" style="margin-bottom: 5px;">
	<div id="news" class="col-lg-12">
	<div class="col-lg-6" style="padding-left: 0px;padding-right:0px;">
				 <!-- BEGIN ticker -->
				 <div class="news-ticker"> 
					<div class="tt icon-ticker" title="ANNOUNCEMENTS"><i class="fa fa-bullhorn"></i></div>
					<div class="news-ticker-content">
					 <ul class="fade-ticker" style="direction: ltr; font-size: 12px; font-family: arial;"><!-- Chose class="fade-ticker" or "slide-ticker"-->
						
						 
					 <li style="">Guests can now comment on videos on the tube.</li><li style="display: none;">New and improved dark forum theme!</li></ul>
				 </div>
				 </div>
			 &nbsp; &nbsp;<!-- END ticker -->
	</div> 
	<div class="col-lg-6 breadcrumbs" style="padding-left: 0px;padding-right:0px;">
	<strong></strong>
	<div class="bbp-breadcrumb">
 &nbsp; 		<!-- start: nav_bit -->
<a href="https://mrdeepfakes.com/forums/index.php" itemprop="item"><span itemprop="name">MrDeepFakes Forums</span></a> »
<!-- end: nav_bit --><!-- start: nav_bit -->
<a href="https://mrdeepfakes.com/forums/forum-deepfake-creation-tools" itemprop="item"><span itemprop="name">DeepFake Creation Tools</span></a> »
<!-- end: nav_bit --><!-- start: nav_bit -->
<a href="https://mrdeepfakes.com/forums/forum-guides-and-tutorials" itemprop="item"><span itemprop="name">Guides and Tutorials</span></a> »
<!-- end: nav_bit --><!-- start: nav_bit_active -->
<span itemprop="name">[GUIDE] - DeepFaceLab 2.0 Guide</span><meta itemprop="position" content="">
<!-- end: nav_bit_active -->
 	</div>
 &nbsp; &nbsp;</div>
	</div>
	<div class="clear"></div>
</div>
<!-- end: nav -->
<!-- end: header -->
<div class="container-fluid">	
	
	
</div>	
<!-- start: multipage -->
<div class="container-fluid">
	<div class="row"> 		
 		<div class="col-lg-12 text-right">
			<ul class="pagination pagination-sm">
				<!-- start: multipage_page_current -->
<li class="active"><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#">1<span class="sr-only">(current)</span></a></li>
<!-- end: multipage_page_current --><!-- start: multipage_page -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=2">2</a></li>
<!-- end: multipage_page --><!-- start: multipage_page -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=3">3</a></li>
<!-- end: multipage_page --><!-- start: multipage_page -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=4">4</a></li>
<!-- end: multipage_page --><!-- start: multipage_page -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=5">5</a></li>
<!-- end: multipage_page --><!-- start: multipage_end -->
...  <li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=33">33</a></li>
<!-- end: multipage_end --><!-- start: multipage_nextpage -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=2">Next&nbsp;<i class="fa fa-angle-double-right"></i></a></li>
<!-- end: multipage_nextpage --><!-- start: multipage_jump_page -->
<div class="dropdown pull-right">
  <button class="btn btn-sm btn-primary dropdown-toggle" type="button" data-toggle="dropdown">
  <i class="fa fa-arrow-down" title="Jump to page"></i></button>
	<ul class="dropdown-menu">
		<li class="padding-8px">
			<form action="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=1" method="post">
				<label for="page">Jump to page:<input type="text" class="form-control input-sm" name="page" id="page" value="1" size="4"></label>
				<input type="submit" class="btn btn-sm btn-primary" value="Go">
			</form>
		</li>
	</ul>	
</div>
<script>
	var go_page = 'go_page_' + $(".go_page").length;
	$(".go_page").last().attr('id', go_page);
	$(".drop_go_page").last().attr('id', go_page + '_popup');
	$('#' + go_page).popupMenu(false).click(function() {
		var drop_go_page = $(this).prev('.drop_go_page');
		if (drop_go_page.is(':visible')) {
			drop_go_page.find('.textbox').focus();
		}
	});
</script>
<!-- end: multipage_jump_page -->
			</ul>
		</div>
	</div>	
</div>
<!-- end: multipage -->
<div class="container-fluid">
	<div class="row" style="padding-bottom:15px">
		<div class="col-lg-12">
			<span class="pull-right" style="padding-left:5px">
				
			</span>		
			<span class="pull-left">
				<div class="dropdown pull-left"> 				
					<button class="btn btn-sm btn-primary dropdown-toggle" type="button" data-toggle="dropdown">Thread tools
  					<i class="fa fa-wrench"></i></button>
  					<ul class="dropdown-menu">
	  					<li><a href="https://mrdeepfakes.com/forums/printthread.php?tid=3886"><i class="fa fa-print"></i>&nbsp;View a Printable Version</a></li>
	  					<li></li>
	  					<li></li>
	 					<li class="dropdown-header">Thread Modes</li>
	  					<li><a href="https://mrdeepfakes.com/forums/showthread.php?mode=linear&amp;tid=3886&amp;pid=16812#pid16812"><i class="fa fa-angle-right"></i>&nbsp;Linear Mode</a></li>
	  					<li><a href="https://mrdeepfakes.com/forums/showthread.php?mode=threaded&amp;tid=3886&amp;pid=16812#pid16812"><i class="fa fa-angle-right"></i>&nbsp;Threaded Mode</a></li>
  					</ul>			
				</div>
			</span>
			<span class="pull-right">
				
			</span>			
		</div>	
	</div>	
	<div class="panel panel-primary">
		<div class="panel-heading">
			<span class="panel-title line-height-title"><strong><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_24245.jpg" class="avatarep_img_contributor" alt="Tuts" onerror="this.src=\&#39;images/default_avatar.png\&#39;">[GUIDE] - DeepFaceLab 2.0 Guide</strong></span>
			<span class="pull-right text-right"><a class="tt btn" href="https://mrdeepfakes.com/forums/usercp2.php?action=addsubscription&amp;tid=3886&amp;my_post_key=0081696a220f9ed52fb7f1b39d30dbc9" title="Subscribe to this thread"><span class="addsubscription"><i class="fa fa fa-rss"></i></span></a></span>
		</div>
  		<div class="panel-body panel-no-padding">
			<div class="row">
				<div class="col-lg-12" id="posts_container">
					<div id="posts">
						<!-- start: postbit -->

<a name="pid16812" id="pid16812"></a>
<div class="post " style="" id="post_16812">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-tuts"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_24245.jpg" alt="" width="55" height="55"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				Moderator<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat0">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat0">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=16812#pid16812" title="[GUIDE] - DeepFaceLab 2.0 Guide">#1</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">02-05-2020, 12:31 PM <span class="post_edit" id="edited_by_16812"><!-- start: postbit_editedby -->
<span class="edited_post">(This post was last modified: 01-12-2021, 09:48 PM by <a href="https://mrdeepfakes.com/forums/user-tuts">Tuts</a>.)</span>
<!-- end: postbit_editedby --></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_16812">
			<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">DeepFaceLab 2.0 Guide</span></span></span></div>
<br>
<div style="text-align: center;" class="mycode_align"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/DFL_welcome.png" alt="[Image: DFL_welcome.png]" class="mycode_img"></div>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-size: small;" class="mycode_size">For general&nbsp;discussion and support please post in this thread:&nbsp;</span>You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</div>
<div style="text-align: center;" class="mycode_align"><span style="font-size: small;" class="mycode_size">Before you ask a new question read all the guides/FAQs first and use search future.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="font-size: small;" class="mycode_size">List of all guides and useful threads:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</span></div>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color"><span style="font-size: small;" class="mycode_size">DISCLAIMER: If you're planning on making your own guide based on mine please credit it by including link to it.</span></span></span></div>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-size: medium;" class="mycode_size"><span style="color: #ff3333;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">DOWNLOAD:&nbsp;Stable releases:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</span></span></span><br>
<span style="font-size: medium;" class="mycode_size"><span style="font-weight: bold;" class="mycode_b">GitHub page (new commits/branches, updates, issues):&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">If you don't have an NVIDIA GPU&nbsp;use Google&nbsp;Colab or DFL 1.0 for AMD cards. You can also train with CPU (slow).</span><br>
You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
<div style="text-align: left;" class="mycode_align"><div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">DFDNet - simple&nbsp;upscaling tool for fixing low resolution SRC faces.</span></div>
<div style="text-align: center;" class="mycode_align">You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</div>
</div>
<br>
<span style="font-weight: bold;" class="mycode_b">Official DFL paper:</span>&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color"><span style="font-size: small;" class="mycode_size">Main features and changes in 2.0:</span></span></span><ul class="mycode_list"><li>2 models: SAEHD and Quick 96<br>
</li>
<li>Supports&nbsp;multi-GPU setups<br>
</li>
<li>Better performance&nbsp;compared to DFL 1.0<br>
</li>
<li>Faceset enhancer for enhancing detail of source dataset and upscaling merger output<br>
</li>
<li>GAN training for more detailed results<br>
</li>
<li>True Face - (for DF architectures) - makes results&nbsp;more SRC like<br>
</li>
<li>Merging process now also&nbsp;outputs mask images for post process work in external video editing software<br>
</li>
<li>Face landmarks embedded into dataset samples (faces)<br>
</li>
<li>Training preview<br>
</li>
<li>Interactive merger<br>
</li>
<li>Debug (landmarks preview)&nbsp;option for datasets<br>
</li>
<li>Dataset extraction using&nbsp;S3FD&nbsp;and manual mode<br>
</li>
<li>Training&nbsp;at&nbsp;any resolution in increments of 16 or 32 pixels<br>
</li>
<li>Multiple architectures (DF, LIAE, -U, -D and -UD variants)<br>
</li>
<li>XSeg masking model with dataset label editor<br>
</li>
</ul>
<div style="text-align: left;" class="mycode_align">DeepFaceLab 2.0 is&nbsp;compatible with NVIDIA&nbsp;GPUs and most CPUs.&nbsp;If you want to train on AMD GPUs - use&nbsp;DFL 1.0.</div>
<div style="text-align: left;" class="mycode_align">DFL 2.0 requires CUDA Compute Capability&nbsp;3.0 capable GPU.</div>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">Explanation of all DFL functions:</span></span></span></div>
<br>
<span style="color: #ff3333;" class="mycode_color">DeepFaceLab 2.0</span> consists of several&nbsp;.bat files used to perform various tasks/steps&nbsp;of creating a&nbsp;deepfake, they are located in the main folder along with two subfolders:<ul class="mycode_list"><li><span style="color: #ff6633;" class="mycode_color">_internal</span>&nbsp;-&nbsp;internal files<br>
</li>
<li><span style="color: #33cc33;" class="mycode_color">workspace</span>&nbsp;-&nbsp;this is where your models, videos, datasets and final video outputs are<br>
</li>
</ul>
Terminology:<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Dataset (faceset)</span>&nbsp;-&nbsp;is a set of images that have been extracted (or aligned) from frames (extracted from video) or photos.<br>
<br>
There are <span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">two datasets</span></span> being used in <span style="font-weight: bold;" class="mycode_b">DFL 2.0</span> and they are <span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">data_dst</span></span> and <span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">data_src</span></span>:<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">- "data_dst"</span></span> is a folder that holds frames extracted from data_dst.mp4 file -&nbsp;target video onto which we swap faces. It also contains 2 folders that are created after running face&nbsp;extraction<br>
<span style="font-weight: bold;" class="mycode_b">"aligned"</span>&nbsp;containing images of faces&nbsp;(with embedded facial landmarks data)<br>
<span style="font-weight: bold;" class="mycode_b">"aligned_debug" </span>which contains original frames with landmarks overlaid&nbsp;on faces&nbsp;which is used to&nbsp;identify correctly/incorrectly aligned faces (and it doesn't take a part in training or merging process).<br>
After cleaning up the&nbsp;dataset&nbsp;it can be deleted. Generates always for DST.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">- "data_src"</span></span> is a folder that holds frames extracted from data_src.mp4 file or where you can place images of your source&nbsp;- the person whose face you want to swap onto the&nbsp;target video.&nbsp;As with data_dst, after extracting faces 2 folders are created:<br>
<span style="font-weight: bold;" class="mycode_b">"aligned"</span>&nbsp;containing images of faces.<br>
<span style="font-weight: bold;" class="mycode_b">"aligned_debug" </span>serves the same function as for DST however for SRC dataset extraction it is not generated by default, if you want it&nbsp;you need to select yes (y) when starting extraction to generate it. It can be also created after extraction.<br>
<br>
Before you get to extract faces however you must have something to extract them from:<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">- for data_dst</span></span> you should prepare the target (destination) video and name it data_dst.mp4<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">- for data_src</span></span>&nbsp;you should either prepare the source video (as in examples above)&nbsp;and name it data_src.mp4 or prepare images in jpg format.<br>
The process of extracting frames from video is also called extraction so for the rest of the guide/tutorial I'll be referring to both processes as "face extraction" and&nbsp;"frame extraction".<br>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">1.&nbsp;Workspace cleanup/deletion:</span></span></span></div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">1) Clear Workspace</span></span> - deletes all data from the&nbsp;"workspace" folder, feel free to delete this .bat&nbsp;file to prevent accidental removal of your workspace.<br>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">2. Frames extraction from source video (data_src.mp4):</span></span></span></div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">2) Extract images from video data_src</span></span> - extracts frames from&nbsp;data_src.mp4 video and puts them into automatically&nbsp;created "data_src" folder, available options:<br>
- FPS - skip for videos default frame rate, enter numerical value for other frame rate (for example entering 5 will only render the video as it was 5 frames per second, meaning less frames will be extracted)<br>
- JPG/PNG - choose the format of extracted frames, jpgs are smaller and generally have good enough quality so they are recommended, pngs are large and don't offer significantly higher quality but they are an option however because DFL uses JPGs only for training you should not use PNGs at all.<br>
<br>
<div style="text-align: left;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">3.&nbsp;Video cutting (optional):</span></div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">3) cut video (drop video on me)</span></span> - allows to quickly cut any&nbsp;video to desired length by dropping it onto that .bat file. Useful if you don't have video editing software and want to quickly cut the video, options:<br>
From time - start of the video<br>
End time - end of the video<br>
Audio track - leave at default<br>
Bitrate - let's you change bitrate (quality) of the video - best to be&nbsp;left&nbsp;at default<br>
<br>
<div style="text-align: center;" class="mycode_align"><span style="color: #ff6633;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="font-size: x-large;" class="mycode_size">3.&nbsp;Frames extraction from destination video (data_dst.mp4):</span></span></span></div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">3) extract images from video data_dst FULL FPS</span></span> - extracts frames from&nbsp;data_dst.mp4 video file&nbsp;and puts them into&nbsp;automatically&nbsp;created "data_dst" folder, available options:<br>
- JPG/PNG - same as in 2)<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">4. Data_src&nbsp;faces extraction/alignment:</span></span></span></div>
<br>
First stage of preparing source dataset is to align the landmarks and produce 512x512&nbsp;face images from the extracted frames located inside "data_src" folder.<br>
<br>
There are 2 options:<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4) data_src faceset extract MANUAL</span></span> - manual extractor, see 5.1 for usage.<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color"><br>
4) data_src faceset extract</span></span> - automated extractor using&nbsp;S3FD algorithm<br>
<br>
Available options for&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">S3FD</span></span> and <span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">MANUAL </span></span>extractor&nbsp;are:<br>
- choosing coverage area of extraction depending on face type of the model you want to train:<br>
a) full face (for FF models or lower)<br>
b) whole face (for WF models or lower)<br>
c) head (for HEAD models)<br>
- choosing which gpu (or cpu)&nbsp;to use for faces extraction<br>
- choosing whether to generate "aligned_debug" folder or not<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">4.&nbsp;Data_src cleanup:</span></span></span></div>
<br>
After that is finished next step is to clean the source faceset/dataset of false positives/incorrectly aligned faces, for a detailed info check this thread:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4.1) data_src view aligned result</span></span> - opens up external app that allows to quickly go through the contents of "data_src/aligned" folder for false positives and&nbsp;incorrectly aligned source faces as well as faces of other people&nbsp;so you can delete them.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4.2) data_src sort</span> - </span>contains&nbsp;various sorting algorithms to help you find unwanted faces, these are the available options:<br>
<br>
<span style="font-style: italic;" class="mycode_i">[0] blur</span><br>
<span style="font-style: italic;" class="mycode_i">[1] motion blur</span><br>
<span style="font-style: italic;" class="mycode_i">[2] face yaw direction</span><br>
<span style="font-style: italic;" class="mycode_i">[3] face pitch direction</span><br>
<span style="font-style: italic;" class="mycode_i">[4] face rect size in source image</span><br>
<span style="font-style: italic;" class="mycode_i">[5] histogram similarity</span><br>
<span style="font-style: italic;" class="mycode_i">[6] histogram dissimilarity</span><br>
<span style="font-style: italic;" class="mycode_i">[7] brightness</span><br>
<span style="font-style: italic;" class="mycode_i">[8] hue</span><br>
<span style="font-style: italic;" class="mycode_i">[9] amount of black pixels</span><br>
<span style="font-style: italic;" class="mycode_i">[10] original filename</span><br>
<span style="font-style: italic;" class="mycode_i">[11] one face in image</span><br>
<span style="font-style: italic;" class="mycode_i">[12] absolute pixel difference</span><br>
<span style="font-style: italic;" class="mycode_i">[13] best faces</span><br>
<span style="font-style: italic;" class="mycode_i">[14] best faces faster</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4.2) data_src util add landmarks debug images</span> </span>- let's you generate "aligned_debug" folder after extracting faces (if you wanted to have it but forgot or didn't select the right option in the first place.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4.2) data_src util faceset enhance</span></span> - uses special machine learning algorithm to upscale/enhance the look of faces in your dataset, useful if your dataset is a bit blurry or you want to make a sharp one have even more detail/texture.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Optionally for enhancing SRC sets (not recommended for DST) you can use DFDNet - Colab link here:</span></span><br>
You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
<span style="color: #ff3333;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">4.2) data_src util faceset metadata restore </span></span>and<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">&nbsp;4.2) data_src util faceset metadata save</span> </span>- let's you save and restore embedded alignment data from your source faceset/dataset so you can edit some face images after you extracted them (for example sharpen them, edit out glasses, skin blemishes, color correct) without loosing alignment data.<br>
<span style="color: #ff9933;" class="mycode_color">EDITING ANY IMAGES FROM "ALIGNED" FOLDER WITHOUT THIS STEP WILL REMOVE THAT ALIGNMENT&nbsp;DATA AND THOSE PICTURES WON'T BE USABLE IN TRAINING, WHEN EDITING KEEP THE NAMES THE SAME, NO FLIPPING/ROTATION IS ALLOWED, ONLY SIMPLE EDITS LIKE COLOR CORRECTION, OR RESIZING/UPSCALING ETC.</span><br>
<br>
<span style="color: #ff3333;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">4.2) data_src util faceset pack </span></span>and<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">&nbsp;4.2) data_src util faceset unpack</span> </span>- packs/unpacks all faces from "aligned" folder into/from one file. Used for preparing custom pretraining dataset,&nbsp;easier sharing as one file and greatly improves dataset load times (seconds instead of minutes).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4.2.other) data_src util recover original filename</span></span> - reverts names of face images back to&nbsp;original order/filename (after sorting). Optional, training and merging&nbsp;will run&nbsp;correctly regardless of the SRC faces file names.<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">5. Data_dst preparation:</span></span></span></div>
<br>
Here steps are pretty much the same as with source dataset, with few exceptions, let's start with faces extraction/alignment&nbsp;process.<br>
We still have&nbsp;Manual and S3FD extraction method but there is also one that combines both and a special manual extraction mode, "aligned_debug" folder is generated always.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">5) data_dst faceset&nbsp;extract MANUAL RE-EXTRACT DELETED ALIGNED_DEBUG</span></span> - manual re-extraction from frames&nbsp;deleted from "aligned_debug" folder.&nbsp;More on that in 5. Data_dst&nbsp;cleanup. Usage below in step 5.1.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">5) data_dst faceset extract MANUAL</span></span> - manual extractor, see 5.1 for usage.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">5) data_dst faceset&nbsp;extract&nbsp;+ manual fix</span></span> - automated + manual extractor&nbsp;for frames where algorithm couldn't properly detect faces.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">5) data_dst faceset&nbsp;extract</span></span>&nbsp;- automated extraction using S3FD algorithm.<br>
<br>
Available options for all&nbsp;extractor modes&nbsp;are:<br>
<br>
- choosing coverage area of extraction depending on face type of the model you want to train:<br>
a)&nbsp;full face (for half, mid-half and full face)<br>
b)&nbsp;whole face (for whole face but also works with others)<br>
c) head (for head type of model)<br>
- choosing which GPU (or CPU)&nbsp;to use for faces extraction/alignment process.<br>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">5.1&nbsp;Manual extractor usage:</span></span></span></div>
<br>
Upon starting the manual extractor or re-extractor a window will open up&nbsp;where you can manually locate faces you want to extract/re-extract:<br>
- use your mouse to locate face<br>
- use mouse wheel to change size of the search area<br>
- make sure all or at least most landmarks (in some cases depending on the angle, lighting or present obstructions it might not be possible to precisely align all landmarks so just try to find a spot that covers all the visible bits the most and isn't too misaligned) land on important spots like eyes, mouth, nose, eyebrows and follow the face shape correctly, an up arrow shows you where is the "up" or "top" of the face<br>
- use key A to change the precision mode, now landmarks won't "stick" so much to detected faces but you might be able to position landmarks more correctly<br>
- user &lt; and &gt; keys (or , and .) to move back and forwards, to confirm a detection&nbsp;either left mouse click and move to the next one or hit enter<br>
- right mouse button for aligning undetectable forward facing or non human faces (requires applying xseg for correct masking)<br>
- q to skip remaining faces and quit extractor (it will also close down when you reach the last face and confirm it)<br>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">5.2&nbsp;Data_dst&nbsp;cleanup:</span></span></span></div>
<br>
After we aligned data_dst faces we have to clean them up, similar to how we did it with source faceset/dataset we have a selection of sorting methods which I'm not going to explain as they work exactly the same as ones for src.<br>
However cleaning up the destination dataset is different than source because we want to have all the faces aligned for all the frames where they are present - including obstructed ones which we can mark in the XSeg editor and then train our XSeg model which will mask them out - effectively making obstructions clearly visible over the learned faces, more on that in the XSeg stage below.&nbsp;There are couple of tools at our disposal for that:<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">5.1) data_dst view aligned results</span></span> - let's you view the contents of "aligned" folder using external app (built into DFL) which offers quicker thumbnail generation than default windows explorer<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">5.1) data_dst view aligned_debug results</span></span> - let's you quickly browse contents of "aligned_debug" folder to locate and delete any frames where our target person face has incorrectly aligned landmarks or where landmarks weren't placed at all (which means face wasn't detected at all). In general you use this to find if all your faces are properly extracted and aligned (if landmarks on some frames aren't lining up with the shape of the face or eyes/nose/mouth/eyebrows or are missing - they should be deleted so we can later manually re-extract/align them).<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">5.2) data_dst sort</span></span> - same as with source faceset/dataset, this tool let's you sort all aligned faces within "data_dst/aligned" folder so that's it's easier to locate incorrectly aligned faces, false positives and faces of other people we don't want to train our model on/swap faces onto.<br>
<span style="color: #ff3333;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">5.2) data_dst util faceset pack</span> </span>and<span style="color: #ff3333;" class="mycode_color">&nbsp;</span><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">5.2) data_dst util faceset unpack</span> </span>- same as with source, let's you quickly pack entire dataset into one file.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">5.2) data_dst util recover original filename</span> </span>- same as with source, restores original names/order of all aligned faces after sorting.<br>
<br>
Now that you know your tools here is an example of my technique for cleaning up the <span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">data_dst dataset </span></span>that guarantees 100% of faces extraction.<br>
<br>
1. Start by sorting&nbsp;<span style="font-weight: bold;" class="mycode_b">data_dst</span>&nbsp;using&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">5.2) data_dst sort</span> </span>and use&nbsp;sorting by histogram, this will sort faces by their similarity in color/structure so it's likely to group similar ones together and separate any images that may contain&nbsp;false positives,&nbsp;faces of other people and incorrectly aligned/extracted faces.<br>
2. Delete all unwanted faces leaving only the good ones.<br>
3. Revert filenames/order of faces&nbsp;using&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">5.2) data_dst util recover original filename.</span></span><br>
4. Go into the folder <span style="color: #ff3333;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">"data_dst/aligned</span></span><span style="color: #ff3333;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">"</span></span>&nbsp;and use the following powershell command to remove&nbsp;_0 suffixes from filenames of aligned&nbsp;faces.<br>
<blockquote class="mycode_quote"><cite>Quote:</cite>- hold shift while right clicking, open powershell and use this command:<br>
<br>
get-childitem *.jpg | foreach {rename-item $_ $_.name.replace("_0","")}<br>
<br>
- wait for the folder address to be displayed again, indicating completion of the process and close the window</blockquote>
5. If your scene has crossfade transitions or mirrors, search for _1 files that may contain additional faces but also duplicates, move them to separate folder, run script again&nbsp;("_1","")}, copy back to main folder and make sure to keep all files but not the same ones (so select just one to keep if it's the same face or both if they are different faces of the same person from the same frame).<br>
6. Create a copy of the&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">"aligned_debug"</span></span>&nbsp;folder.<br>
7. Once done, select all files&nbsp;from&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">"aligned"</span></span> and copy them&nbsp;(don't move them)&nbsp;to the&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">"aligned_debug - copy"</span></span>&nbsp;folder, replace, wait for it to finish and while all replaced files are still&nbsp;highlighted delete them.<br>
8. Go through remaining frames and remove all that don't contain any faces you want to manually extract.<br>
9. Copy the rest back to the original&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">"aligned_debug"</span></span>&nbsp;folder, replace, wait for it to finish&nbsp;and while all replaced files are still&nbsp;highlighted delete them.<br>
10. Now your&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">"aligned_debug"</span></span>&nbsp;folder contains only frames from which faces were correctly extracted and all frames from which extractor failed to correctly extract faces or did not extract are gone which means you can run&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">5) data_dst faceset MANUAL RE-EXTRACT DELETED ALIGNED_DEBUG</span></span> to manually extract them. Before you do that you might want to run&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">5.1) data_dst view aligned_debug results</span> </span>to quickly scroll through the remaining good ones and see if landmarks look correct on all of them, if you spot some less ideal looking landmarks, delete them so you can extract them manually too.<br>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">5.3: XSeg model training and&nbsp;faceset marking.</span></span></span></div>
<br>
<span style="color: #a9afbc;" class="mycode_color">XSeg is a replacement for defunct FANSeg model that is used to automatically mask your result face on top of your target video. It is also used&nbsp;to make obstructions such as hair or hands visible over the swapped/fake face and is completely customizable by the means of manual dataset&nbsp;marking and model training.</span><br>
<br>
There is no pretrained XSeg model (unlike the old FANseg model) which means you need to create your own XSeg model or take advantage of the ones shared by other users.<br>
<br>
Such models can be also reused similarly to the swapping models (SAEHD, Quick96)&nbsp;so when you start working on a new video you don't need to train the model from scratch but instead can reuse existing one by&nbsp;feeding it marked (labeled)&nbsp;faces. Both SRC and DST datasets can be marked thus giving you options of using XSeg-prd (respects SRC face shape) and XSeg-dst (respects DST face shape) masking modes&nbsp;and also combine them both. It is also possible to&nbsp;combine both of them&nbsp;with learned mask (see the merger masking modes, merging step).<br>
<br>
XSeg works with all face types such as Full&nbsp;Face, Whole&nbsp;Face and even Head so you have full control of which parts of the DST faces get covered/swapped with new face and which parts (obstructions) are being left visible.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">New available .bat files/scripts are:</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">5.XSeg) data_dst mask for XSeg trainer - edit</span></span>&nbsp;-&nbsp;label tool to mark destination faces with XSeg polygons.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">5.XSeg) data_dst mask for XSeg trainer - fetch</span></span>&nbsp;-&nbsp;copies faces containing XSeg polygons to folder "aligned_xseg". Can be used&nbsp;to collect labeled faces so they can be reused in future XSeg model trainings.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">5.XSeg) data_dst mask for XSeg trainer - remove</span></span>&nbsp;-&nbsp;removes labeled/marked XSeg polygons from the extracted frames.<br>
<br>
<span style="color: #ff9933;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">5.XSeg) data_src mask for XSeg trainer - edit</span></span>&nbsp;- label tool to mark source faces with XSeg polygons.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">5.XSeg) data_src mask for XSeg trainer - fetch</span></span>&nbsp;-&nbsp;copies faces containing XSeg polygons to folder "aligned_xseg". Can be used&nbsp;to&nbsp;collect labeled faces so they can be reused in future XSeg model trainings.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">5.XSeg) data_src mask for XSeg trainer - remove</span></span>&nbsp;-&nbsp;removes labeled/marked XSeg polygons from the extracted frames.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">XSeg) train.bat</span></span>&nbsp;- runs the training of the XSeg model.<br>
<br>
<span style="color: #3399ff;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">5.XSeg.optional) trained mask for data_dst - apply</span></span>&nbsp;- replaces default DST&nbsp;masks derived from landmarks created during extraction&nbsp;with ones generated by the&nbsp;trained XSeg model, it is required for proper whole&nbsp;face and head face&nbsp;type model training and also if you plan on using style power with those 2 face types.<br>
<span style="color: #3399ff;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">5.XSeg.optional) trained mask for data_dst - remove</span></span>&nbsp;- removes XSeg masks and restores default DST masks.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #99cc33;" class="mycode_color">5.XSeg.optional) trained mask for data_src - apply</span></span>&nbsp;-&nbsp;replaces default DST&nbsp;masks derived from landmarks created during extraction&nbsp;with ones&nbsp;generated by the&nbsp;trained XSeg model, it is required for proper whole&nbsp;face and head face&nbsp;type model training and also if you plan on using style power with those 2 face types.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #99cc33;" class="mycode_color">5.XSeg.optional) trained mask for data_src - remove</span></span>&nbsp;-&nbsp;removes XSeg masks and restores default DST masks.<br>
<br>
Before you start it's important to know the difference between face marking/labeling and masking. Marks/labels are polygons you create manually in the editor which model uses to learn how to mask faces, mask are what gets applied by the apply .bat and also what merger will generate using your trained XSeg model during merging (XSeg model files are in the model folder and must be there during merging).<br>
<br>
Masks define which area on the face sample is the face itself and what is a background or obstruction, that's why you need to apply them for WF and HEAD model as default masks don't cover the area needed for those face types and also why even with full face I recommend to apply XSeg to both SRC and DST as XSeg masks are much more precise and true to face shape than extraction generated DST masks and even learned masks that model trains based on landmarks of SRC and DST faces to create learned-prd and learned-dst masks respectively during training (they don't understand face obstructions and if your landmarks are off/incorrect - so will be those learned masks).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">XSeg usage:</span></span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">1. Mark your datasets</span></span><br>
<br>
Start by marking both SRC* and DST faces using&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">5.XSeg) data_src&nbsp;mask for XSeg trainer - edit&nbsp;</span></span>and<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">&nbsp;</span></span><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">5.XSeg) data_dst mask for XSeg trainer - edit</span></span><br>
<br>
<span style="font-style: italic;" class="mycode_i"><span style="color: #ff9933;" class="mycode_color">Each tool has a written description that's displayed when you go over it with your mouse&nbsp;(en/ru/zn languages are supported).</span></span><br>
<br>
Mark 50 to&nbsp;200 different faces for both SRC and DST,&nbsp;you don't need to mark all faces but&nbsp;only those&nbsp;where the face looks&nbsp;significantly different, for&nbsp;example:<br>
<br>
- when facial expression changes (open mouth - closed mouth, big smile - frown)<br>
- when direction/angle of the face changes<br>
- or when lighting conditions/direction changes (usually together with face angle but in some cases the lighting might change while face still looks in the same direction)<br>
<br>
The more various faces you mark, the better quality masks&nbsp;Xseg model&nbsp;will generate for you. In general the smaller the dataset is the less faces will have to be marked and the same goes about the variety of angles, if you have many different angles and also expressions it will require you to mark more faces.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Keep the same "logic" of marking for all faces, for example:</span></span><br>
<br>
- the same approximated jaw line of the side faces, where the jaw is not visible<br>
- the same hair line<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Marking obstructions:</span></span><br>
<br>
While marking faces you will also probably want to&nbsp;exclude obstructions so that they are visible in the final video, to do so you can either:<br>
<br>
- not include obstructions in the main polygon that defines face area you want to be swapped.<br>
- or&nbsp;use exclude poly mode to draw additional label&nbsp;around the obstruction or part you want to be visible/not swapped.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">When marking obstructions you need to make sure you label them on&nbsp;several faces&nbsp;according to the same rules as when marking faces with no obstructions, mark the obstruction&nbsp;(even if it doesn't change appearance/shape/position when face/head:</span></span><br>
<br>
- changes&nbsp;angle<br>
- facial expression changes<br>
- lighting conditions change<br>
<br>
<span style="font-style: italic;" class="mycode_i">If the obstruction is additionally changing shape and/or moving across the face you need to mark it few times, not all obstructions&nbsp;on&nbsp;every face need to be labeled&nbsp;though but still the more variety of different obstructions occur in various conditions - the more faces you will have to label.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">How to mark faces for different face types:</span></span><br>
<br>
- For FF mark faces from chin up to slightly above eyebrows, if you're using FF faces then on some chin will be cut off, in that case you can round the edge of as to not have perfectly straight lines on some parts of the face, remember as with SAEHD model training you can use higher face type faces and train lower face type model, you can even use WF faces, train WF XSeg model but mark them in a way FF face would be marked. Profiles are almost always not fully covered with FF face type so make sure to also not have perfectly straight lines of your label on the parts that get cut off.<br>
<br>
- For WF mark faces from chin up to the hairline for frontal shots, for profile shots make sure to follow jawline (if it's pronounced it will be visible, if it's not as visible approximate it and use the same logic for marking of&nbsp;all faces), don't include ears if they are visible, mark up to where hair starts.<br>
<br>
- For HEAD include the whole face as well as hair, make sure the masks are precise, include ears, optionally you can also include a little bit of the neck.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">Do not include in the main label&nbsp;any major obstructions (or use exclude&nbsp;tool):</span></span><br>
<br>
- big hair strands.<br>
- hands and other obstructions (for NSFW obviously mark out all other obstructions too).<br>
- shoulders, legs and other big obstructions.<br>
- tongues when they are sticking out of the mouth.<br>
- for DST faces exclude mouth cavity&nbsp;when they are wide open, if teeth aren't visible mark it to where the lips start, if teeth are visible make sure to leave a decent offset to prevent double teeth after blurring the mask in the merger, for SRC faces you don't need to mark out mouth cavity&nbsp;but you can exclude tongues.<br>
- when marking out any liquids&nbsp;(tears, rain drops, milk)&nbsp;if the liquid&nbsp;looks like water and isn't contrasting with face a lot do not exclude it, it will confuse the model during training and it will treat all light reflections/skin highlights as those "liquids"&nbsp;which may end up showing too much of the DST face, especially if you blur the mask heavily during merging&nbsp;and there will be bright spots in crucial areas like mouth, nose or eyes.<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Once you finish marking DST faces scroll to the end of the list and&nbsp;hit Esc to save them, then you can move on to training your XSEG model.</span><br>
<br>
*If you're training a full face model you may skip marking of SRC faces and only do DST faces however if you plan on using&nbsp;Style Powers&nbsp;it's recommended to also mark SRC faces and as I've already explained you need to apply XSeg masks to both SRC and DST datasets before training (or at least before using Style Powers). Also if you want to use XSeg-prd you must mark your SRC faces, otherwise the model won't be able to correctly create masks that respect the shape of SRC faces.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">2. Train your XSeg&nbsp;model.</span></span><br>
<br>
When starting training for the first time&nbsp;you will see an option to select face_type of the XSeg model which should be set to be the same as face_type of&nbsp;your face swapping model although you can also use a higher option safely. Reason why you can use higher option is that even if you have a whole face dataset, marked as whole face set should be&nbsp;with which you train a WF XSeg&nbsp;and then you use a full face face_type SAEHD model,&nbsp;while merging the mask will be cropped to the highest area possible by the full face face_type. If you then take the same dataset but train an FF XSeg model the mask will be still cropped to the same size and they will be virtually the same, that's why I recommend to stick with WF XSeg for both FF&nbsp;and WF SAEHD models.<br>
<br>
You will also be able to choose device to train on as well as batch size which will typically be much higher as XSeg model is not that demanding as training of the face swapping model (you can also start off at lower value and raise it later).<br>
<br>
You can switch preview modes using space (there are 3 modes, DST training, SRC training and SRC+DST (distorted).<br>
To update preview progress press P.<br>
Esc to save and stop training.<br>
<br>
During training check previews often, if&nbsp;some faces have bad&nbsp;masks after about 50k iterations (bad shape, holes, blurry), save and stop training, apply masks to your dataset, run editor,&nbsp;find faces with bad masks&nbsp;by enabling XSeg mask overlay&nbsp;in the editor, mark them and hit esc to save and exit and then resume XSeg model training, when starting up an already trained model you will get a prompt if you want to restart training, select no (n) as selecting yes (y) will restart the model training from 0 instead of continuing. However in case your masks are not improving despite having marked many more faces and being well above 100k-150k iterations it might be necessary to mark even more faces or restart training from scratch.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">3. Apply XSeg masks to your datasets.</span></span><br>
<br>
This step has been already explained few times here but in any case I'm repeating it so it's all clear.<br>
After you're done training or after you've already applied XSeg once and then fixed faces that had bad masks it's time for final application of XSeg masks to your datasets.&nbsp;Also as I've already explained it is not necessary to apply datasets if you're using a full face SAEHD model, you can simply use XSeg during merging by selecting the new masking modes such as XSeg-Prd or XSeg-Dst (or combinations of them with themselves and learned masks) but for best results it's recommended to apply them anyway as you will get better results when using Style Power because those XSeg masks are much more precise&nbsp;than learned masks that are otherwise used to define areas of face and background for Style Transfer training.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">Extra tips:</span></span><br>
<br>
1. Don't bother making 1000 point label, it will take too much time to mark&nbsp;all the faces and won't affect the face vs if you use just 30-40 points to describe the face shape but also don't try to mark it with 10 points or the mask will not be smooth, the exception here would be marking hair for HEAD face type training&nbsp;where obviously some detail is needed to correctly resolve individual hair strands.<br>
2. Do not mark shadows unless they're pitch black.<br>
3. Don't mark out tongues or insides of the mouth if it's barely open.<br>
4. If obstruction or face is blurry mark as much as needed to cover everything that should or shouldn't be visible, do not make offsets too big<br>
5. Keep in mind that when you use blur the edge blurs both in and out, if you mark out a finger right on the edge it won't look bad on low blur but on higher one it will start to disappear and be replaced with the blurry version of what model learned, same goes for the&nbsp;mouth cavity, on low blur it will only show result face teeth but if you apply high blur then DST teeth will start to show and it will look bad (double teeth).<br>
This means:<br>
- when excluding&nbsp;obstructions like fingers - mark it on the edge or do a tiny offset. Both SRC and DST<br>
- when excluding mouth cavity&nbsp;-&nbsp;mark&nbsp;it with bigger offset from teeth. DST, SRC is optional<br>
- when excluding tongues - mark it on the edge, offset from teeth, only when it sticks out significantly. Both SRC and DST<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">XSeg editor:</span></span></span><br>
<br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/FOh51zc.jpg" width="1280" height="720" alt="[Image: FOh51zc.jpg]" class="mycode_img"><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">Training preview:</span></span></span><br>
<br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/NM1Kn3s.jpg" width="500" height="600" alt="[Image: NM1Kn3s.jpg]" class="mycode_img"><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="font-size: medium;" class="mycode_size">Some correctly masked faces examples:</span></span><br>
<br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/mC1fDgb.jpg" width="400" height="402" alt="[Image: mC1fDgb.jpg]" class="mycode_img"><br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/ohPhcrR.jpg" width="400" height="403" alt="[Image: ohPhcrR.jpg]" class="mycode_img"><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="font-size: small;" class="mycode_size">Example of faces with bad applied mask:</span></span><br>
<br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/mMSrUGJh.jpg" alt="[Image: mMSrUGJh.jpg]" class="mycode_img"><br>
<br>
<span style="font-size: small;" class="mycode_size"><span style="font-weight: bold;" class="mycode_b">Fixing the mask by marking those faces correctly:</span></span><br>
<br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/e354c5Vh.jpg" alt="[Image: e354c5Vh.jpg]" class="mycode_img"><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color"><span style="font-size: small;" class="mycode_size">How to use shared marked faces to train your own XSeg model:</span></span></span><br>
<br>
Download, extract and place faces into "data_src/aligned" or "data_dst/aligned". Make sure to rename them to not overwrite your own faces (I suggest XSEGSRC and XSEGDST for easy removal afterwards).<br>
You can mix shared faces with your own labeled to give the model as much data to learn masks as possible, don't mix face types, make sure all faces roughly follow the same logic of masking.<br>
Then just start training your XSeg model (or shared one).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color"><span style="font-size: small;" class="mycode_size">How to use shared XSeg model and apply it to your dataset:</span></span></span><br>
<br>
Simply place it into the "model" folder and use apply .bat files to apply masks to SRC or DST.<br>
After you apply masks open up XSeg editor and check how masks look by enabling XSeg mask overlay view, if some faces don't have good looking masks, mark them, exit the editor and start the training of the XSeg model again to fix them. You can also mix in some of the shared faces as described above (how to use shared marked faces). You can reuse XSeg models (like SAEHD models).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="font-size: medium;" class="mycode_size">User shared SAEHD&nbsp;models can be found in this thread:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</span></span><br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">6. Training:</span></span></span></div>
<br>
<div style="text-align: left;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">There are currently 2 models to choose from for training:</span></span></span></div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">SAEHD (6GB+):</span>&nbsp;</span>High Definition Styled Auto Encoder - for high end GPUs with at least 6GB of VRAM. Adjustable<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Quick96 (2-4GB):</span> </span>Simple mode dedicated for low end GPUs with 2-4GB of VRAM. Fixed parameters:<br>
<br>
- 96x96 Pixels resolution<br>
- Full Face<br>
- Batch size 4<br>
- DF-UD architecture<br>
<br>
Quick96 is recommended for low end cards or dataset testing only.<br>
Model settings&nbsp;spreadsheet:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
After you've checked other peoples settings and decided on a&nbsp;model you want to use you start it up using one of those:<br>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="color: #ffcc33;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">6) train SAEHD</span></span></div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">6) train Quick96</span></span></div>
<br>
<div style="text-align: justify;" class="mycode_align">Since Quick96 is not adjustable you will see the command window pop up and ask only 1 question - CPU or GPU (if you have more then it will let you choose either one of them or train with both).</div>
<div style="text-align: justify;" class="mycode_align">SAEHD however will present you with more options to adjust.</div>
<br>
<div style="text-align: justify;" class="mycode_align">In both cases first a command line window will appear where you input your model settings. On a first start will you will have access to all setting that are explained below, on startup of training with a model already trained and present in the "model" folder you will also receive a prompt where you can choose which model to train on (if you have more than one set of model files present in your "model" folder).<br>
You will also always get a prompt to select which GPU or CPU&nbsp;you want to run the trainer on.<br>
<br>
Second thing you will see once you startup is the preview window that looks like this:<br>
<br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/aNEoiAN.jpg" alt="[Image: aNEoiAN.jpg]" class="mycode_img"><br>
<br>
Here is a more detailed explanation of all functions in order they are presented to the user upon starting training of a new model:<br>
<br>
<span style="font-style: italic;" class="mycode_i">Note that some of these get locked and can't be changed once you start training due to way these models work, example of things that can't be changed later are:</span></div>
<div style="text-align: justify;" class="mycode_align">
<span style="color: #33cc33;" class="mycode_color">- model resolution<br>
- model architecture<br>
- models dimensions (dims)<br>
- face type</span><br>
</div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Autobackup every N hour ( 0..24 ?:help ) :</span></span>&nbsp;self explanatory -&nbsp;let's you enable automatic backups of your model every N hours. Leaving it at 0 (default) will disable auto backups. Default value is 0 (disabled).</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Target iteration :</span></span> will stop training after certain amount of iterations is reached, for example if you want to train you model to only 100.000 iterations you should enter a value of 100000. Leaving it at 0&nbsp;will make it run until you stop it manually. Default value is 0 (disabled).</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Flip faces randomly ( y/n ?:help ) :</span></span> Useful option in cases where you don't have all necessary angles of the persons face (source dataset)&nbsp;that you want to swap onto the target. For example if you have a target/destination video with person looking straight and&nbsp;to the right and your source only has faces looking straight and to the left you should enable this feature but bear in mind that because no face is symmetrical results may look less like src and also features on the source face (like beauty marks, scars, moles, etc.) will be mirrored. Default value is n (disabled).</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Batch_size ( ?:help ) :</span></span> Batch size settings affects how many faces are being compared to each other every each iteration. Lowest value is 2 and you can go as high as your GPU will allow which is affected by VRAM. The higher your models resolution, dimensions and the more features you enable the more VRAM will be needed so&nbsp;lower batch size might be required. It's recommended&nbsp;to not use value below 4. Higher batch size will provide better quality at the cost of slower training (higher iteration time). For the intial stage it can be set lower value to speed up initial training and then raised higher. Optimal values are between 6-12.&nbsp;How to guess what batch size to use? You can either use trial and error or help yourself by taking a look at what other people can achieve on their GPUs by checking out the DFL 2.0 spreadsheet:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Resolution ( 64-640 ?:help ) :</span></span>&nbsp;here you set your models resolution, bear in mind this option cannot be changed during training. It affects the resolution of swapped faces, the higher model resolution - the more detailed the learned face will be but also training will be much heavier and longer. Resolution can be increased&nbsp;from 64x64 to 640x640 by increments of:<br>
16 (for regular and -U architectures variants)<br>
32 (for -D and -UD architectures variants)</div>
<div style="text-align: justify;" class="mycode_align">Higher resolutions might require increasing of the model dimensions (dims).</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Face type ( h/mf/f/wf/head ?:help ) :</span></span>&nbsp;this option let's you set the area of the face you want to train, there are 5 options - half face, mid-half face,&nbsp;full face,&nbsp;whole face and head:</div>
<div style="text-align: justify;" class="mycode_align">
<span style="font-weight: bold;" class="mycode_b">a)&nbsp;Half face</span> - only trains from mouth to eybrows&nbsp;but&nbsp;can in some cases cut of top or bottom of the face (eyebrows, chin, bit of mouth).</div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">b) Mid-half face</span> -&nbsp;aims to fix this issue by covering&nbsp;30% larger&nbsp;portion of face compared to&nbsp;half face which should&nbsp;prevent most of the undesirable cut offs&nbsp;from occurring but they&nbsp;can still happen.</div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">c) Full face</span> - covers most of the face area, excluding forehead, can sometimes cut off a little bit of chin but this happens very rarely - most recommended when&nbsp;SRC and/or DST have hair covering forehead.</div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">d) Whole face</span> - expands that area even more to cover pretty much the whole face, including forehead and even a little bit of hair but this mode should be used when we want to make a swap of the entire face, excluding hair.</div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">e) Head</span> - is used to do a swap of the entire head, not suitable for subjects with long hair, works best if the source faceset/dataset&nbsp;comes from single source and both SRC and DST have short hair or one&nbsp;that doesn't change shape depending on the angle. Minimum recommended resolution for this face type is 224.<br>
</div>
<div style="text-align: justify;" class="mycode_align"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/UNDadcN.jpg" width="700" height="300" alt="[Image: UNDadcN.jpg]" class="mycode_img"></div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">Example of whole face type face&nbsp;swap:</span></div>
<br>
<div style="text-align: justify;" class="mycode_align"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/ldlVgZH.png" alt="[Image: ldlVgZH.png]" class="mycode_img"></div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">Example of head type&nbsp;face&nbsp;swap:&nbsp;</span>You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
</div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">AE architecture (df/liae/df-u/liae-u/df-d/liae-d/df-ud/liae-ud&nbsp;?:help ) :</span></span>&nbsp;This option let's you choose between 2 main learning architectures DF and LIAE as well as their -U, -D&nbsp;and -UD&nbsp;versions.</div>
<br>
<div style="text-align: left;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">DF </span>and<span style="font-weight: bold;" class="mycode_b"> LIAE</span> architectures are the base ones, both offering good quality with decent performance.</div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">DF-U,&nbsp;DF-UD,&nbsp;LIAE-U&nbsp;and&nbsp;LIAE-&nbsp;UD are additional architecture variants.</span></div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">DF:</span></span></span> This model architecture provides a&nbsp;more direct face swap, doesn't morph faces but requires that the source and target/destination face/head have similar face shape.</div>
<div style="text-align: justify;" class="mycode_align">This model works best on frontal shots and requires that your source dataset has all the required angles, can produce worse results on side profiles.</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">LIAE:</span></span></span> This model architecture isn't as strict when it comes to face/head shape similarity between source and target/destination but this model does morph the faces so it's recommended to have actual face features (eyes, nose, mouth, overall face structure) similar between source and&nbsp;target/destination. This model offers worse resemblance to source on frontal shots&nbsp;but can handle side profiles much better and is more forgiving when it comes to source faceset/dataset, often producing more refined face swaps with better color/lighting match.</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">-U:</span></span></span> this variant aims to improve similarity/likeness&nbsp;of trained result face to SRC dataset.<br>
</div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">-D:</span></span></span> this variant aims to improve performance, it let's you train your model at twice the resolution with no extra compute&nbsp;cost (VRAM usage) and similar performance, for example train 256 resolution model at the same VRAM usage and speed (iteration time) as 128 resolution model.&nbsp;However it requires longer training, model must be pretrained first for optimal results and resolution must be changed by the value of 32 as opposed to 16 in other variants.<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color"><span style="font-size: medium;" class="mycode_size"><br>
<br>
[b]<span style="color: #ff9933;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">-UD: </span></span></span></span></span>[/b]combines both variants for maximum likeness and increased resolution/performance. Also requires longer training and model to be pretrained.</div>
<br>
<div style="text-align: justify;" class="mycode_align"><div style="text-align: left;" class="mycode_align">The next 4 options control models neural network dimensions which affect models ability to learn, modifying these can have big impact on performance and quality of the learned faces so they should be left at default.</div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">AutoEncoder dims</span> ( 32-1024 ?:help ) :</span>&nbsp;Auto encoder dims setting, affects overall ability of the model to learn faces.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Encoder dims</span>&nbsp;( 16-256 ?:help ) :&nbsp;</span>Encoder dims setting, affects ability of the model to learn general structure of the faces.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">Decoder dims</span>&nbsp;( 16-256 ?:help ) :</span>&nbsp;Decoder&nbsp;dims&nbsp;setting, affects ability of the model to learn fine detail.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">Decoder mask dims</span> ( 16-256 ?:help ) :&nbsp;</span>Mask decoder&nbsp;dims&nbsp;setting, affects quality of the learned masks.&nbsp;May or may not affect some other aspects of training.<br>
<br>
The changes in performance when changing each setting&nbsp;can have varying effects on performance and it's not possible to measure effect of each one on performance and quality without extensive training. Each one is set&nbsp;at certain default value that should offer optimal results and good compromise between training speed and quality.<br>
<br>
Also when changing one parameter the other ones should be changed as well to keep the relations between them similar (for example if you drop Encoder and Decoder dimensions from 64 to 48 you could also decrease AutoEncoder dimension from 256 to 192-240).&nbsp;Feel free to experiment with various settings.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #3399ff;" class="mycode_color">If you want optimal results, keep them at default or increase them slightly for higher resolution models.</span></span><br>
</div>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Eyes and mouth&nbsp;priority ( y/n ?:help ) :</span></span>&nbsp;Attempts to&nbsp;fix problems with eye&nbsp;training by forcing the neural network to train eyes and mouth with higher priority.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Place models and optimizer on GPU ( y/n ?:help ) :</span></span>&nbsp;Enabling GPU optimizer puts all the load on your GPU which greatly improves&nbsp;performance (iteration time) but will lead to higher VRAM usage, disabling this feature will offload some work of the optimizer&nbsp;to CPU which decreases load on GPU and VRAM usage thus&nbsp;letting you achieve higher batch size or run more demanding models at the cost of longer iteration times.&nbsp;If you get OOM (out of memory) error and you don't want to lower your batch size or disable some feature&nbsp;you should disable this feature and thus some work will be offloaded to your CPU and some data from GPUs VRAM to system RAM - you will be able to run your model without OOM errors&nbsp;at the cost of lower speed. Default value is y (enabled).<br>
<br>
<div style="text-align: left;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Use learning rate dropout ( y/n/cpu ?:help ) :</span></span>&nbsp;LRD is used to&nbsp;accelerate&nbsp;training of faces and reduces sub-pixel shake in less iterations, you can&nbsp;use it:</div>
</div>
<div style="text-align: left;" class="mycode_align">- for a while&nbsp;before disabling RW (when loss values aren't improving by a lot anymore)</div>
<div style="text-align: left;" class="mycode_align">-&nbsp;and second time&nbsp;after RW has been&nbsp;disabled and other options have been already used (SP, TF, EMP, UY), and before enabling GAN (if you're using Adablief LRD during RW and after before/during GAN is not required but is optional and should still improve quality.</div>
<div style="text-align: justify;" class="mycode_align">
<div style="text-align: left;" class="mycode_align">This option affects VRAM usage&nbsp;so if you run into OOM errors you can run it on CPU at the cost&nbsp;of 20% slower iteration times or just lower your batch size.</div>
<div style="text-align: left;" class="mycode_align">For more detailed explanation of LRD and order of enabling main features during training please refer to&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</div>
</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Use AdaBelief optimizer? ( y/n ?:help ) : </span></span>AdaBelief (AB) is a new model optimize which increases model accuracy and quality of trained faces, when this option is enabled it replaces the default RMSProp optimizer.&nbsp;However those improvements come at a&nbsp;cost of higher VRAM usage, requiring existing or new models to be trained at lower batch size to prevent OOM errors.<br>
For best results this option should be only used on new models but can be also used with existing ones assuming one gives the model enough time to readapt, may require deactivation of all options and re-enabling of RW. Once this option is enabled it must remain enabled always.</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Enable random warp of samples ( y/n ?:help ) :</span></span>&nbsp;Random warp&nbsp;is used to generalize a model so that it correctly learns&nbsp;face features and&nbsp;expressions in the initial training stage but&nbsp;as long as&nbsp;it's enabled the model may have trouble learning the fine detail - because of it it's recommended to keep this feature enabled as long as your faces are still improving (by looking at decreasing loss values and face in the&nbsp;preview window improving) and&nbsp;once all faces look correct (and loss isn't decreasing anymore)&nbsp;you should disable it to start learning details, from then you don't re-enable it unless you ruin the results by applying to high values for certain settings (style power, true face, etc) or when you want to reuse that model for training of new target video with the same source or when reusing with combination of both new SRC and DST, you always start training with RW enabled and other options disabled.&nbsp;Default value is y (enabled).</div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Masked training&nbsp;( y/n ?:help ) : </span></span>Prioritizes training of what's masked (default mask or applied xseg mask), available only for WF and HEAD face types, disabling it trains the whole sample area (including background) at the same priority as the face itself. Default value is y (enabled).<br>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Uniform_yaw&nbsp;( y/n ?:help ) :</span></span>&nbsp;Helps with training of profile faces, forces model to train evenly on all faces depending on their yaw and prioritizes profile faces, may cause frontal faces to train slower, enabled by default during pretraining, can be used similarly to random warp (at the beginning of the training&nbsp;process) or enabled after RW is disabled&nbsp;when faces are more or less trained and you want profile faces to look better and less blurry. Useful when your source dataset doesn't have many profile shots. Can help lower loss values. Default value is n (disabled).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">GAN power ( 0.0 .. 10.0 ?:help ) :</span></span>&nbsp;GAN stands for Generative Adversarial Network and in case of DFL 2.0 it is implemented as an additional way of training&nbsp;to get more detailed/sharp&nbsp;faces. This option is adjustable on a scale from 0.0 to 10.0 and it should only be enabled once the model is more or less done training (after you've disabled&nbsp;<span style="font-weight: bold;" class="mycode_b">random warp of samples and enabled LRD</span>). It's recommended to start at low value of 0.1 which is also a recommended value in most cases, once it's enabled you should not disable it, make sure to make backups of your models in case you don't like the results.<br>
Default value is 0.0 (disabled).</div>
<br>
<div style="text-align: justify;" class="mycode_align"><span style="color: #33cc33;" class="mycode_color"><span style="font-style: italic;" class="mycode_i">Before/after example of a&nbsp;face trained with GAN at value of 0.1 for 40k&nbsp;iterations:<br>
</span></span><br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/Nbh3mw1.png" width="650" height="400" alt="[Image: Nbh3mw1.png]" class="mycode_img"><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">'True face' power. ( 0.0000 .. 1.0 ?:help ) :</span></span>&nbsp;True face training with a variable power settings let's you set the model discriminator to higher or lower value, what this does is it tries to make the final face look more like src, as with <span style="font-weight: bold;" class="mycode_b">GAN</span>&nbsp;this feature should only be enabled once random warp is disabled and model is fairly well trained.&nbsp;Consider making a backup&nbsp;before enabling this feature.&nbsp;Never use high values, typical value is 0.01 but you can use even lower ones like&nbsp;0.001.&nbsp;The higher the setting the more result face will look like faces in source dataset which may cause issues with color match and also cause artifacts to show up so it's important to not use high values.&nbsp;It has a small performance impact which may cause OOM error to occur.&nbsp;Default value is 0.0 (disabled).<br>
<br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/czScS9q.png" width="500" height="200" alt="[Image: czScS9q.png]" class="mycode_img"><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Face style power ( 0.0..100.0 ?:help ) </span></span><span style="color: #ffcc33;" class="mycode_color">and&nbsp;<span style="font-weight: bold;" class="mycode_b">Background style power ( 0.0..100.0 ?:help ) :</span></span>&nbsp;This setting controls&nbsp;style transfer of either face or background part of the image, it is used to transfer the style of your target/destination faces (data_dst) over to the final learned face which can improve quality and look of the final result after merging but high values can cause learned face to look more like data_dst than data_src. It&nbsp;will transfer some color/lighting information from DST to result face. It's recommended to not use values higher than&nbsp;10. Start with small values like 0.001-0.01.&nbsp;This feature has big performance impact and using it will increase iteration time and may require you to lower your <span style="font-weight: bold;" class="mycode_b">batch size</span>,&nbsp;<span style="font-weight: bold;" class="mycode_b">disable gpu optimizer or run LRD on CPU</span>.&nbsp;Consider&nbsp;making a&nbsp;backup&nbsp;before enabling this feature.&nbsp;Default value is 0.0 (disabled).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Color transfer for src faceset ( none/rct/lct/mkl/idt/sot ?:help ) :</span></span>&nbsp;this features is used to match the colors of your data_src to the data_dst so that the final result has similar skin color/tone to the data_dst and the final result after training doesn't change colors when face moves around (which may happen if various face angles were taken from various sources that contained different light conditions or were color graded differently). There are several options to choose from:<br>
<br>
<span style="font-weight: bold;" class="mycode_b">- rct</span> (reinhard color transfer): based on:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<span style="font-weight: bold;" class="mycode_b">- lct</span> (linear color transfer):&nbsp;Matches the color distribution of the target image to that of the source image using a linear transform.<br>
<span style="font-weight: bold;" class="mycode_b">- mkl</span> (Monge-Kantorovitch linear): based on:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<span style="font-weight: bold;" class="mycode_b">- idt</span> (<span style="color: #a9afbc;" class="mycode_color">Iterative Distribution Transfer</span>): based on:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<span style="font-weight: bold;" class="mycode_b">- sot</span> (sliced optimal transfer): based on:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Enable gradient clipping ( y/n ?:help ) :</span></span>&nbsp;This feature is implemented to prevent so called model collapse/corruption which may occur when using various features of DFL 2.0. It has small performance impact so if you really don't want to use it you must enable auto backups as a collapsed model cannot recover and must be scraped and training must be started all over. Default value is n (disabled) but since the performance impact is so low and it can save you a lot of time by preventing model collapse if you leave it&nbsp;enabled. Model collapse is most likely to happen when using Style Powers so if you're using them it's highly advised to enable gradient clipping or backups (you can also do them manually).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">Enable pretraining mode ( y/n ?:help ) :</span></span>&nbsp;Enables pretraining process that uses a dataset of random peoples faces to initially train your model, after training it to around 200k-400k iterations such model can be then used when starting training with actual&nbsp;data_src and data_dst you want to train, it saves time because you don't have to start training all over from 0 every time (the model will "know" how faces should look like and thus speed up the initial training stage).<br>
<br>
<span style="font-weight: bold;" class="mycode_b">User shared SAEHD&nbsp;models can be found in this thread:</span>&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
</div>
<div style="text-align: justify;" class="mycode_align"><span style="color: #ff6633;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">1. What are pretrained models?</span></span><br>
<br>
<div style="text-align: left;" class="mycode_align">Pretrained models are made by training them with random faces of various people.&nbsp;Using a model prepared in such a way significantly speeds up the initial training stage because model already knows how face should look so you don't have to wait as much for faces to start showing up and they'll become sharp faster compared to training on a fresh and non-pretrained model.</div>
<br>
<div style="text-align: left;" class="mycode_align">You can now also share your custom pretraining sets (SFW/NSFW) for various face_types (full face, whole face and head).</div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">2. How to use pretrained models?</span><br>
</span><br>
Simply download it and place all the files directly into your model folder, start training, after selecting model for training (if you have more than one&nbsp;in your model&nbsp;folder) and device to train with (GPU/CPU)&nbsp;press any key within 2 seconds (you'll see a prompt that says this exact thing)&nbsp;to override model settings&nbsp;and make sure the pretrain option is set to disabled (N)&nbsp;so that you start training and not continue pretraining.<br>
<br>
If&nbsp;you leave pretrain option enabled (Y)&nbsp;the model will continue to&nbsp;pretrain&nbsp;using built-in pretrain dataset that comes with DFL (in this thread you will find models trained with both the old full face&nbsp;pretrain dataset set as well as with the new whole face&nbsp;FFHQ dataset).<br>
<br>
Note that the model will revert iteration count to 0 when you disable pretrain&nbsp;and start regular training, that's normal behavior for pretrained models. However if the model is described as "regular training" this means it was not pretrained but instead trained to certain amount of iterations where both SRC and DST dataset contained random faces of people, in this case model will carry on training and iteration count won't start at 0 but at the value it was when training was ended by the user who is sharing the model.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">3. How to create your own pretrained model?</span></span><br>
<br>
1. The official and recommended way to&nbsp;create one is to use pretrain&nbsp;option&nbsp;which will use DFL's built-in random celebrity faces dataset and train your model like this for at least 250k&nbsp;iterations (recommended to train to 350-500k).<br>
After model is sufficiently trained (most faces in the preview should look sharp by then, with well defined teeth, eyes but not necessarily with a lot of pixel/sub-pixel details).<br>
<br>
1.1&nbsp;You can also change the default pretrain dataset to your own which you can make by placing random faces of people you're most likely to fake (it can be all male, female, mix of male and female, celebrities only, random people) and then packing it using&nbsp;util faceset pack.bat and then naming it "CelebA" and replacing the original file in&nbsp;\_internal\pretrain_CelebA with this new dataset.<br>
<br>
2. Alternative way to pretrain a model is&nbsp;to&nbsp;prepare data_src and data_dst datasets with faces of random&nbsp;people, from various angles and with different expressions and train models as if you would normally (pretrain disabled). For source dataset you&nbsp;can use faces of celebs you are most likely to swap in the future and for DST you can use any faces from&nbsp;types of videos you're most likely to use as your target videos.<br>
<br>
It should be noted however that&nbsp;preparing your model by simply training it on random faces can introduce some morphing and make result faces look slightly less like&nbsp;the&nbsp;source for a while. However after few retrains using the same source the src likeness of the predicted (result, 5th column) face&nbsp;should improve. This method can be faster to adapt to new faces compared to training on pretrained model (because we are simply reusing a model, but instead of reusing one that was trained on specific src dataset we reuse a model that contains random faces, as mentioned above you can include faces of people you're most likely to fake as a part of your src and dst datasets).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">NOTE: If you're pretraining a HEAD model consider using your custom pretrain set as the included FFHQ dataset is of&nbsp;Whole Face&nbsp;type&nbsp;(WF).</span></span><br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">Old pretrain set is also not suitable as it's only FF (full face).</span></span></div>
		</div>
		
		<!-- start: postbit_signature -->
<div class="panel panel-primary">
<div class="signature scaleimages padding-8px">
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Open for commissions</span>, if you want a custom deepfake made,&nbsp;send me a private message.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="color: #ffcc33;" class="mycode_color">Want to learn DFL and guides aren't enough? I offer DeepFaceLab courses, message me for details.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Also consider donation&nbsp;towards running our website!</span></span></div>

</div>
</div>
<!-- end: postbit_signature -->
		<div class="post_meta" id="post_meta_16812">
                        
                        <div style="" id="tyl_16812"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(16812);return false;" title="[-]" id="tyl_a_expcol_16812"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_16812"></a> 
	<span id="tyl_title_16812" style=""><strong>The following 22 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post:</strong></span><span id="tyl_title_collapsed_16812" style="display: none;"><strong>22 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post</strong></span><br>
	<span id="tyl_data_16812" style="">&nbsp;&nbsp;• <span class="smalltext"></span><a href="https://mrdeepfakes.com/forums/user-anon13337" class="tt smalltext" title="10-05-2020">Anon13337</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-arearelove" class="tt smalltext" title="03-02-2020">arearelove</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-baza0" class="tt smalltext" title="04-30-2020">baza0</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-bbailey24" class="tt smalltext" title="12-20-2020">bbailey24</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-clovis-brithgtex" class="tt smalltext" title="03-27-2020">clovis-brithgtex</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-demo10mdf" class="tt smalltext" title="04-19-2020">Demo10MDF</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-dephie1" class="tt smalltext" title="08-28-2020">Dephie1</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-df-7777" class="tt smalltext" title="10-03-2020">df_7777</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-dronedro23" class="tt smalltext" title="09-27-2020">dronedro23</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-eloquant888" class="tt smalltext" title="07-25-2020">eloquant888</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-evieboleyn" class="tt smalltext" title="04-26-2020">EvieBoleyn</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-hodi97" class="tt smalltext" title="02-26-2020">hodi97</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-hryhorjuk" class="tt smalltext" title="05-02-2020">hryhorjuk</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-jessica2020" class="tt smalltext" title="04-18-2020">Jessica2020</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-ktpxfun" class="tt smalltext" title="12-29-2020">ktpxfun</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-mrbilis" class="tt smalltext" title="11-25-2020">mrbilis</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-numlocker" class="tt smalltext" title="02-25-2020">Numlocker</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-ozzef" class="tt smalltext" title="08-02-2020">Ozzef</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-positiveraisin2" class="tt smalltext" title="07-25-2020">positiveraisin2</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-sirfakelot" class="tt smalltext" title="06-05-2020">SirFakelot</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-tthxalot" class="tt smalltext" title="01-11-2021">tthxalot</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-yeji" class="tt smalltext" title="02-28-2020">yeji</a></span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=24245" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=16812" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_16812_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_16812">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=16812" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_16812").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit --><!-- start: postbit -->

<a name="pid16813" id="pid16813"></a>
<div class="post " style="" id="post_16813">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-tuts"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_24245.jpg" alt="" width="55" height="55"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				Moderator<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat1">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat1">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=16813#pid16813" title="RE: (DFL 2.0) [GUIDE] - DeepFaceLab 2.0 EXPLAINED AND TUTORIALS.">#2</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">02-05-2020, 11:54 PM <span class="post_edit" id="edited_by_16813"><!-- start: postbit_editedby -->
<span class="edited_post">(This post was last modified: 01-11-2021, 01:08 AM by <a href="https://mrdeepfakes.com/forums/user-tuts">Tuts</a>.)</span>
<!-- end: postbit_editedby --></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_16813">
			<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">7. Merging:</span></span></span></div>
<br>
<div style="text-align: left;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">After you're done training your model it's time to merge learned face over original frames to form final video&nbsp;(convert).</span></span></div>
<br>
For that we have 2 converters corresponding to&nbsp;2&nbsp;available&nbsp;models:<br>
<br>
<span style="color: #33cc33;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">7) merge SAEHD</span></span><br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">7) merge Quick96</span></span><br>
<br>
Upon selecting any of those a command line window will appear with several prompts.<br>
<br>
1st one will ask you if you want to use an interactive converter,&nbsp;default value is y (enabled) and it's recommended to use it over the regular one because it has all the features and also an interactive preview where you see the effects of all changes&nbsp;you make when changing various options and enabling/disabling various features<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Use interactive merger? ( y/n ) :</span></span><br>
<br>
2nd one will ask you which model you want to use:<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Choose one of saved models, or enter a name to create a new model.</span></span><br>
<span style="font-style: italic;" class="mycode_i">[r] : rename</span><br>
<span style="font-style: italic;" class="mycode_i">[d] : delete</span><br>
<span style="font-style: italic;" class="mycode_i">[0] : df192 - latest</span><br>
<span style="font-style: italic;" class="mycode_i">:</span><br>
<br>
3rd one will ask you which GPU/GPUs or CPU you want to use for the merging (conversion) process:<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Choose one or several GPU idxs (separated by comma).</span></span><br>
<span style="font-style: italic;" class="mycode_i">[CPU] : CPU</span><br>
<span style="font-style: italic;" class="mycode_i">[0] : Your GPU</span><br>
<span style="font-style: italic;" class="mycode_i">[0] Which GPU indexes to choose? :</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">Pressing enter will use default value (0).</span><br>
<br>
After that's done you will see a command line window with current settings as well as preview window which shows all the controls needed to operate the interactive converter/merger.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">Here is a quick look at both the command line window and converter preview window:</span></span></span><br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/BT6vAzW.png" width="1080" height="500" alt="[Image: BT6vAzW.png]" class="mycode_img"><br>
<br>
<span style="font-size: medium;" class="mycode_size">Converter features many options that you can use to change the mask type, it's size, feathering/blur, you can add additional color transfer and sharpen/enhance final trained face even further.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">Here is the list of all merger/converter features explained:</span></span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">1. Main overlay modes:</span></span><br>
- original: displays original frame without swapped face<br>
- overlay: simple overlays learned&nbsp;face over the frame<br>
- hist-match: overlays the learned face and tires to match it based on histogram (has 2 modes: normal and masked that can be switched&nbsp;with Z)<br>
- seamless: uses&nbsp;opencv poisson seamless clone function to blend new learned face over the head in the original frame<br>
- seamless hist match: combines both hist-match and seamless.<br>
- raw-rgb: overlays raw learned face without any masking<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">NOTE: Seamless modes can cause flickering.</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">2. Hist match threshold:</span></span>&nbsp;controls strength of the histogram matching in hist-match and seamless hist-match overlay mode.<br>
<span style="font-style: italic;" class="mycode_i">Q - increases value<br>
A - decreases value</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">3. Erode mask:</span></span>&nbsp;controls the size of a mask.<br>
<span style="font-style: italic;" class="mycode_i">W - increases mask erosion (smaller mask)<br>
S - decreases mask erosion (bigger mask)</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">4. Blur mask:</span></span>&nbsp;blurs/feathers the edge of the mask for smoother transition<br>
<span style="font-style: italic;" class="mycode_i">E - increases blur<br>
D - decreases blur</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">5. Motion blur:</span></span>&nbsp;after entering initial parameters (converter mode, model, GPU/CPU) merger loads all frames and data_dst aligned data, while it's doing it, it calculates motion vectors that are being used to create effect of motion blur which this setting controls, it let's you add it in places where face moves around but high values may blur the face even with small movement. The option only works if one set of faces is present in the "data_dst/aligned" folder - if during cleanup you had some faces with _1 prefixes (even if only faces of one person are present) the effect won't work, same goes if there is a mirror that reflects target persons face, in such case you cannot use motion blur and the only way to add it is to train each set of faces separately.<br>
<span style="font-style: italic;" class="mycode_i">R - increases motion blur<br>
F - decreases motion blur</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">6. Super resolution:</span></span>&nbsp;uses similar algorithm as data_src dataset/faceset enhancer, it can add some more definitions to areas such as teeth, eyes and enhance detail/texture of the learned face.<br>
<span style="font-style: italic;" class="mycode_i">T - increases the enhancement effect<br>
G - decreases the enhancement effect</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">7. Blur/sharpen:</span></span>&nbsp;blurs or sharpens the learned face using box or gaussian method.<br>
<span style="font-style: italic;" class="mycode_i">Y - sharpens the face<br>
H - blurs the face<br>
N - box/gaussian mode switch</span><br>
<br>
<span style="color: #ff9933;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">8. Face scale</span><span style="font-weight: bold;" class="mycode_b">:</span>&nbsp;</span>scales learned&nbsp;face to be larger or smaller.<br>
<span style="font-style: italic;" class="mycode_i">U - scales learned face down</span><br>
<span style="font-style: italic;" class="mycode_i">J - scales learned face up</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">9. Mask modes</span>:</span>&nbsp;there are 6 masking modes:<br>
<br>
<span style="font-weight: bold;" class="mycode_b">dst:</span>&nbsp;uses masks derived from the shape of the landmarks generated during data_dst faceset/dataset extraction.<br>
<span style="font-weight: bold;" class="mycode_b">learned-prd:&nbsp;</span>uses masks learned during training. Keep shape of SRC faces.<br>
<span style="font-weight: bold;" class="mycode_b">learned-dst:&nbsp;</span>uses masks learned during training. Keep shape of DST faces.<br>
<div style="text-align: justify;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">learned-prd*dst:&nbsp;</span>combines both masks, smaller size of both.</div>
<span style="font-weight: bold;" class="mycode_b">learned-prd+dst:&nbsp;</span>combines both masks, bigger size of both.<br>
<span style="font-weight: bold;" class="mycode_b">XSeg-prd:&nbsp;</span>uses XSeg model to mask using data from source faces.<br>
<span style="font-weight: bold;" class="mycode_b">XSeg-dst:&nbsp;</span>uses XSeg model to mask using data from destination faces.<br>
<span style="font-weight: bold;" class="mycode_b">XSeg-prd*dst:&nbsp;</span>combines both masks, smaller size of both.<br>
<span style="font-weight: bold;" class="mycode_b">learned-prd*dst*XSeg-dst*prd:&nbsp;</span>combines all 4&nbsp;mask modes, smaller size of all.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">10. Color transfer modes:</span></span>&nbsp;similar to color transfer during training, you can use this feature to better match skin color of the learned face to the original frame for more seamless and realistic face swap. There are 8 different modes:<br>
<span style="font-weight: bold;" class="mycode_b">RCT<br>
LCT<br>
MKL<br>
MKL-M<br>
IDT<br>
IDT-M<br>
SOT - M<br>
MIX-M</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">11. Image degrade modes:</span></span>&nbsp;there are 3 settings that you can use to affect the look of the original frame (without affecting the swapped face):<br>
<span style="font-weight: bold;" class="mycode_b">Denoise</span>&nbsp;- denoises image making it slightly blurry (I - increases&nbsp;effect,&nbsp;K - decrease effect)<br>
<span style="font-weight: bold;" class="mycode_b">Bicubic</span>&nbsp;- blurs the image using bicubic method (O - increases&nbsp;effect,&nbsp;L - decrease&nbsp;effect)<br>
<span style="font-weight: bold;" class="mycode_b">Color</span>&nbsp;- decreases color bit depth (P - increases&nbsp;effect, ;&nbsp;- decrease&nbsp;effect)<br>
<br>
<span style="color: #33cc33;" class="mycode_color"><span style="font-size: medium;" class="mycode_size"><span style="font-weight: bold;" class="mycode_b">Additional controls:</span></span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">TAB button</span>&nbsp;-&nbsp;switches between main preview&nbsp;window and help screen.<br>
For complete list of keys (and what they control, such as moving forward/backward, starting merging) check the help screen.<br>
<span style="color: #ff3333;" class="mycode_color">Bear in mind these will only work&nbsp;in the main preview window, pressing any button while&nbsp;on the help screen won't do anything.</span><br>
<br>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: x-large;" class="mycode_size">8. Conversion of frames back into video:</span></span></span></div>
<br>
After you merged/convert all the faces and you will have a folder named "merged" inside your "data_dst" folder containing all frames as well as "merged_masked" which contains mask frames.<br>
Last step is to convert them back into video and combine with original audio track from data_dst.mp4 file.<br>
<br>
To do so you will use one of 4 provided .bat files that will use FFMPEG to combine all the frames into a video in one of the following formats - avi, mp4, loseless mp4 or loseless mov:<br>
- 8) merged to avi<br>
-&nbsp;8) merged to mov lossless<br>
-&nbsp;8) merged to mp4 lossless<br>
-&nbsp;8) merged to mp4<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">And that's it!</span></span>&nbsp;After you've done all these steps you should have a file called result.xxx (avi/mp4/mov) which is your deepfake video as well as result_mask.xxx which you can import into your video editing software to use as the source of masks to further refine your swapped face without affecting the rest of the video.<br>
<br>
For more info on how to post process your video check this thread:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view. or simply look up videos about compositing in your video editor of choice.<br>
<br>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">If you have more questions that weren't covered in this thread check other guides and threads related to DFL 2.0 and deepfake creation in general:</span></div>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b">You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</span></div>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">Current issues/bugs:</span></span></span><br>
<br>
Github page for issues reports:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
If you can't find the exact issue in existing forum threads, it wasn't mentioned on github and you believe no one else discovered it yet create a new thread here:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
If your issue is common your thread will be deleted without a notice. Use search feature, if you search for errors by copying them directly from command line window remember to only copy key errors parts as directories names will differ between various users. When reporting issues make sure to include your full PC specs (CPU, GPU, RAM amount, OS) as well as your DFL version and model settings, describe what leads to the issues you're experiencing.<br>
<br>
<span style="font-weight: bold;" class="mycode_b">CHANGELOG:</span><br>
<br>
<div class="codeblock"><div class="title">Code:</div><div class="body" dir="ltr"><code>Official repository:&nbsp;https://github.com/iperov/DeepFaceLab<br>
&nbsp;<br>
Please consider a donation.<br>
&nbsp;<br>
============ CHANGELOG ============<br>
<br>
Windows 10 users important notice!<br>
<br>
You should set this setting in order to work correctly.<br>
<br>
System – Display – Graphics settings<br>
<br>
https://i.imgur.com/fwy9iW8.jpg<br>
<br>
== 16.12.2020 ==<br>
<br>
Now single build for all video cards.<br>
<br>
Upgraded to Tensorflow 2.4.0, CUDA 11.2, CuDNN 8.0.5.<br>
<br>
You don’t need to install anything.<br>
<br>
== 11.12.2020 ==<br>
<br>
Upgrade to Tensorflow 2.4.0rc4<br>
<br>
Now support RTX 3000 series.<br>
<br>
Videocards with Compute Capability 3.0 are no longer supported.<br>
<br>
CPUs without AVX are no longer supported.<br>
<br>
SAEHD: added new option<br>
<br>
Use AdaBelief optimizer?<br>
<br>
Experimental AdaBelief optimizer. It requires more VRAM, but the accuracy of the model is higher, and lr_dropout is not needed.&nbsp;<br>
<br>
== 02.08.2020 ==<br>
&nbsp;<br>
SAEHD: now random_warp is disabled for pretraining mode by default<br>
Merger: fix load time of xseg if it has no model files<br>
&nbsp;<br>
== 18.07.2020 ==<br>
&nbsp;<br>
Fixes<br>
&nbsp;<br>
SAEHD: write_preview_history now works faster<br>
The frequency at which the preview is saved now depends on the resolution.<br>
For example 64x64 – every 10 iters. 448x448 – every 70 iters.<br>
&nbsp;<br>
Merger: added option “Number&nbsp;of&nbsp;workers?”<br>
Specify&nbsp;the&nbsp;number&nbsp;of&nbsp;threads&nbsp;to&nbsp;process.&nbsp;<br>
A&nbsp;low&nbsp;value&nbsp;may&nbsp;affect&nbsp;performance.&nbsp;<br>
A&nbsp;high&nbsp;value&nbsp;may&nbsp;result&nbsp;in&nbsp;memory&nbsp;error.&nbsp;<br>
The&nbsp;value&nbsp;may&nbsp;not&nbsp;be&nbsp;greater&nbsp;than&nbsp;CPU&nbsp;cores.<br>
&nbsp;<br>
== 17.07.2020 ==<br>
&nbsp;<br>
SAEHD:<br>
&nbsp;<br>
Pretrain dataset is replaced with high quality FFHQ dataset.<br>
&nbsp;<br>
Changed help for “Learning rate dropout” option:<br>
When&nbsp;the&nbsp;face&nbsp;is&nbsp;trained&nbsp;enough,&nbsp;you&nbsp;can&nbsp;enable&nbsp;this&nbsp;option&nbsp;to&nbsp;get&nbsp;extra&nbsp;sharpness&nbsp;and&nbsp;reduce&nbsp;subpixel&nbsp;shake&nbsp;for&nbsp;less&nbsp;amount&nbsp;of&nbsp;iterations.&nbsp;<br>
Enabled&nbsp;it&nbsp;before&nbsp;“disable&nbsp;random&nbsp;warp”&nbsp;and&nbsp;before&nbsp;GAN.&nbsp;n&nbsp;disabled. y&nbsp;enabled<br>
cpu&nbsp;enabled&nbsp;on&nbsp;CPU.&nbsp;This&nbsp;allows&nbsp;not&nbsp;to&nbsp;use&nbsp;extra&nbsp;VRAM,&nbsp;sacrificing&nbsp;20%&nbsp;time&nbsp;of&nbsp;iteration.<br>
&nbsp;<br>
Changed help for GAN option:<br>
Train&nbsp;the&nbsp;network&nbsp;in&nbsp;Generative&nbsp;Adversarial&nbsp;manner.&nbsp;<br>
Forces&nbsp;the&nbsp;neural&nbsp;network&nbsp;to&nbsp;learn&nbsp;small&nbsp;details&nbsp;of&nbsp;the&nbsp;face.&nbsp;<br>
Enable&nbsp;it&nbsp;only&nbsp;when&nbsp;the&nbsp;face&nbsp;is&nbsp;trained&nbsp;enough&nbsp;and&nbsp;don't&nbsp;disable.&nbsp;<br>
Typical&nbsp;value&nbsp;is&nbsp;0.1<br>
&nbsp;<br>
improved GAN. Now it produces better skin detail, less patterned aggressive artifacts, works faster.<br>
[img=896x548]https://i.imgur.com/Nbh3mw1.png[/img]<br>
&nbsp;<br>
== 04.07.2020 ==<br>
&nbsp;<br>
Fix bugs.<br>
Renamed some 5.XSeg) scripts.<br>
Changed help for GAN_power.<br>
&nbsp;<br>
== 27.06.2020 ==<br>
&nbsp;<br>
Extractor:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Extraction now can be continued, but you must specify the same options again.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;added ‘Max&nbsp;number&nbsp;of&nbsp;faces&nbsp;from&nbsp;image’ option.<br>
If&nbsp;you&nbsp;extract&nbsp;a&nbsp;src&nbsp;faceset&nbsp;that&nbsp;has&nbsp;frames&nbsp;with&nbsp;a&nbsp;large&nbsp;number&nbsp;of&nbsp;faces,&nbsp;<br>
it&nbsp;is&nbsp;advisable&nbsp;to&nbsp;set&nbsp;max&nbsp;faces&nbsp;to&nbsp;3&nbsp;to&nbsp;speed&nbsp;up&nbsp;extraction.<br>
0 - unlimited<br>
&nbsp;<br>
added ‘Image&nbsp;size’ option.<br>
The&nbsp;higher&nbsp;image&nbsp;size,&nbsp;the&nbsp;worse&nbsp;face-enhancer&nbsp;works.<br>
Use&nbsp;higher&nbsp;than&nbsp;512&nbsp;value&nbsp;only&nbsp;if&nbsp;the&nbsp;source&nbsp;image&nbsp;is&nbsp;sharp&nbsp;enough&nbsp;and&nbsp;the&nbsp;face&nbsp;does&nbsp;not&nbsp;need&nbsp;to&nbsp;be&nbsp;enhanced.<br>
&nbsp;<br>
added ‘Jpeg&nbsp;quality’ option in range 1-100. The&nbsp;higher&nbsp;jpeg&nbsp;quality&nbsp;the&nbsp;larger&nbsp;the&nbsp;output&nbsp;file&nbsp;size<br>
<br>
== 22.06.2020 ==<br>
&nbsp;<br>
XSegEditor:<br>
changed hotkey for xseg overlay mask<br>
“overlay xseg mask” now works in polygon mode<br>
<br>
&nbsp;<br>
== 21.06.2020 ==<br>
&nbsp;<br>
SAEHD:<br>
Resolution for –d archi is now automatically adjusted to be divisible by 32.<br>
‘uniform_yaw’ now always enabled in pretrain mode.<br>
&nbsp;<br>
Subprocessor now writes an error if it does not start.<br>
&nbsp;<br>
XSegEditor: fixed incorrect count of labeled images.<br>
&nbsp;<br>
XNViewMP: dark theme is enabled by default<br>
<br>
&nbsp;<br>
== 19.06.2020 ==<br>
&nbsp;<br>
SAEHD:<br>
&nbsp;<br>
Maximum resolution is increased to 640.<br>
&nbsp;<br>
‘hd’ archi is removed. ‘hd’ was experimental archi created to remove subpixel shake, but ‘lr_dropout’ and ‘disable random warping’ do that better.<br>
&nbsp;<br>
‘uhd’ is renamed to ‘-u’<br>
dfuhd and liaeuhd will be automatically renamed to df-u and liae-u in existing models.<br>
&nbsp;<br>
Added new experimental archi (key -d) which doubles the resolution using the same computation cost.<br>
It is mean same configs will be x2 faster, or for example you can set 448 resolution and it will train as 224.<br>
Strongly recommended not to train from scratch and use pretrained models.<br>
&nbsp;<br>
New archi naming:<br>
'df'&nbsp;keeps&nbsp;more&nbsp;identity-preserved&nbsp;face.<br>
'liae'&nbsp;can&nbsp;fix&nbsp;overly&nbsp;different&nbsp;face&nbsp;shapes.<br>
'-u'&nbsp;increased&nbsp;likeness&nbsp;of&nbsp;the&nbsp;face.<br>
'-d'&nbsp;(experimental) doubling&nbsp;the&nbsp;resolution&nbsp;using&nbsp;the&nbsp;same&nbsp;computation&nbsp;cost<br>
Opts can be mixed (-ud)<br>
Examples:&nbsp;df,&nbsp;liae,&nbsp;df-d,&nbsp;df-ud,&nbsp;liae-ud,&nbsp;...<br>
&nbsp;<br>
Not the best example of 448 df-ud trained on 11GB:<br>
<br>
&nbsp;<br>
Improved GAN training (GAN_power option).&nbsp;&nbsp;It was used for dst model, but actually we don’t need it for dst.<br>
Instead, a second src GAN model with x2 smaller patch size was added, so the overall quality for hi-res models should be higher.<br>
&nbsp;<br>
Added option&nbsp;‘Uniform&nbsp;yaw&nbsp;distribution&nbsp;of&nbsp;samples (y/n)’:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Helps&nbsp;to&nbsp;fix&nbsp;blurry&nbsp;side&nbsp;faces&nbsp;due&nbsp;to&nbsp;small&nbsp;amount&nbsp;of&nbsp;them&nbsp;in&nbsp;the&nbsp;faceset.<br>
&nbsp;<br>
Quick96:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Now based on df-ud archi and 20% faster.<br>
&nbsp;<br>
XSeg trainer:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Improved sample generator.<br>
Now it randomly adds the background from other samples.<br>
Result is reduced chance of random mask noise on the area outside the face.<br>
Now you can specify ‘batch_size’ in range 2-16.<br>
&nbsp;<br>
Reduced size of samples with applied XSeg mask. Thus size of packed samples with applied xseg mask is also reduced.<br>
&nbsp;<br>
&nbsp;<br>
== 11.06.2020 ==<br>
&nbsp;<br>
Trainer: fixed "Choose image for the preview history". Now you can switch between subpreviews using 'space' key.<br>
Fixed "Write preview history". Now it writes all subpreviews in separated folders<br>
&nbsp;<br>
<br>
also the last preview saved as _last.jpg before the first file<br>
<br>
thus you can easily check the changes with the first file in photo viewer<br>
&nbsp;<br>
&nbsp;<br>
XSegEditor:&nbsp;added text label of total labeled images<br>
Changed frame line design<br>
Changed loading frame design<br>
&nbsp;<br>
<br>
&nbsp;<br>
== 08.06.2020 ==<br>
&nbsp;<br>
SAEHD: resolution &gt;= 256 now has second dssim loss function<br>
&nbsp;<br>
SAEHD: lr_dropout now can be ‘n’, ‘y’, ‘cpu’. ‘n’ and ’y’ are the same as before.<br>
‘cpu’ mean enabled&nbsp;on&nbsp;CPU.&nbsp;This&nbsp;allows&nbsp;not&nbsp;to&nbsp;use&nbsp;extra&nbsp;VRAM,&nbsp;sacrificing&nbsp;20%&nbsp;time&nbsp;of&nbsp;iteration.<br>
fix errors<br>
&nbsp;<br>
reduced chance of the error "The paging file is too small for this operation to complete."<br>
&nbsp;<br>
updated XNViewMP to 0.96.2<br>
&nbsp;<br>
== 04.06.2020 ==<br>
&nbsp;<br>
Manual extractor: now you can specify the face rectangle manually using ‘R Mouse button’.<br>
It is useful for small, blurry, undetectable faces, animal faces.<br>
<br>
Warning:<br>
Landmarks cannot be placed on the face precisely, and they are actually used for positioning the red frame.<br>
Therefore, such frames must be used only with XSeg workflow !<br>
Try to keep the red frame the same as the adjacent frames.<br>
&nbsp;<br>
added script<br>
10.misc) make CPU only.bat<br>
This script will convert your DeepFaceLab folder to work on CPU without any problems. An internet connection is required.<br>
It is useful to train on Colab and merge interactively on your comp without GPU.<br>
&nbsp;<br>
== 31.05.2020 ==<br>
&nbsp;<br>
XSegEditor: added button "view XSeg mask overlay face"<br>
&nbsp;<br>
== 06.05.2020 ==<br>
&nbsp;<br>
Some fixes<br>
&nbsp;<br>
SAEHD: changed UHD arhis. You have to retrain uhd models from scratch.<br>
&nbsp;<br>
== 20.04.2020 ==<br>
&nbsp;<br>
XSegEditor: fix bug<br>
&nbsp;<br>
Merger: fix bug<br>
&nbsp;<br>
== 15.04.2020 ==<br>
&nbsp;<br>
XSegEditor: added view lock at the center by holding shift in drawing mode.<br>
&nbsp;<br>
Merger: color transfer “sot-m”: speed optimization for 5-10%<br>
&nbsp;<br>
Fix minor bug in sample loader<br>
&nbsp;<br>
== 14.04.2020 ==<br>
&nbsp;<br>
Merger: optimizations<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;color transfer ‘sot-m’ : reduced color flickering, but consuming x5 more time to process<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;added mask mode ‘learned-prd + learned-dst’ – produces largest area of both dst and predicted masks<br>
XSegEditor : polygon is now transparent while editing<br>
&nbsp;<br>
New example data_dst.mp4 video<br>
&nbsp;<br>
New official mini tutorial&nbsp;https://www.youtube.com/watch?v=1smpMsfC3ls<br>
&nbsp;<br>
== 06.04.2020 ==<br>
&nbsp;<br>
Fixes for 16+ cpu cores and large facesets.<br>
&nbsp;<br>
added 5.XSeg) data_dst/data_src mask for XSeg trainer - remove.bat<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;removes labeled xseg polygons from the extracted frames<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
== 05.04.2020 ==<br>
&nbsp;<br>
Decreased amount of RAM used by Sample Generator.<br>
&nbsp;<br>
Fixed bug with input dialog in Windows 10<br>
&nbsp;<br>
Fixed running XSegEditor when directory path contains spaces<br>
&nbsp;<br>
SAEHD: ‘Face&nbsp;style&nbsp;power’ and ‘Background&nbsp;style&nbsp;power’&nbsp;&nbsp;are now available for whole_face<br>
&nbsp;New help messages for these options.<br>
&nbsp;<br>
XSegEditor: added button ‘view trained XSeg mask’, so you can see which frames should be masked to improve mask quality.<br>
&nbsp;<br>
Merger:<br>
added ‘raw-predict’ mode. Outputs raw predicted square image from the neural network.<br>
&nbsp;<br>
mask-mode ‘learned’ replaced with 3 new modes:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‘learned-prd’ – smooth learned mask of the predicted face<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‘learned-dst’ – smooth learned mask of DST face<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;‘learned-prd*learned-dst’ – smallest area of both (default)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
Added new face type : head<br>
Now you can replace the head.<br>
Example: https://www.youtube.com/watch?v=xr5FHd0AdlQ<br>
Requirements:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Post processing skill in Adobe After Effects or Davinci Resolve.<br>
Usage:<br>
1)&nbsp;&nbsp;Find suitable dst footage with the monotonous background behind head<br>
2)&nbsp;&nbsp;Use “extract head” script<br>
3)&nbsp;&nbsp;Gather rich src headset from only one scene (same color and haircut)<br>
4)&nbsp;&nbsp;Mask whole head for src and dst using XSeg editor<br>
5)&nbsp;&nbsp;Train XSeg<br>
6)&nbsp;&nbsp;Apply trained XSeg mask for src and dst headsets<br>
7)&nbsp;&nbsp;Train SAEHD using ‘head’ face_type as regular deepfake model with DF archi. You can use pretrained model for head. Minimum recommended resolution for head is 224.<br>
8)&nbsp;&nbsp;Extract multiple tracks, using Merger:<br>
a.&nbsp;&nbsp;Raw-rgb<br>
b.&nbsp;&nbsp;XSeg-prd mask<br>
c.&nbsp;&nbsp;XSeg-dst mask<br>
9)&nbsp;&nbsp;Using AAE or DavinciResolve, do:<br>
a.&nbsp;&nbsp;Hide source head using XSeg-prd mask: content-aware-fill, clone-stamp, background retraction, or other technique<br>
b.&nbsp;&nbsp;Overlay new head using XSeg-dst mask<br>
&nbsp;<br>
Warning: Head faceset can be used for whole_face or less types of training only with XSeg masking.<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
== 30.03.2020 ==<br>
&nbsp;<br>
New script:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.XSeg) data_dst/src mask for XSeg trainer - fetch.bat<br>
Copies&nbsp;faces&nbsp;containing&nbsp;XSeg&nbsp;polygons&nbsp;to aligned_xseg\&nbsp;dir.<br>
Useful only if you want to collect labeled faces and reuse them in other fakes.<br>
&nbsp;<br>
Now you can use trained XSeg mask in the SAEHD training process.<br>
It’s mean default ‘full_face’ mask obtained from landmarks will be replaced with the mask obtained from the trained XSeg model.<br>
use<br>
5.XSeg.optional) trained mask for data_dst/data_src - apply.bat<br>
5.XSeg.optional) trained mask for data_dst/data_src - remove.bat<br>
&nbsp;<br>
Normally you don’t need it. You can use it, if you want to use ‘face_style’ and ‘bg_style’ with obstructions.<br>
&nbsp;<br>
XSeg trainer : now you can choose type of face<br>
XSeg trainer : now you can restart training in “override settings”<br>
Merger: XSeg-* modes now can be used with all types of faces.<br>
&nbsp;<br>
Therefore old MaskEditor, FANSEG models, and FAN-x modes have been removed,<br>
because the new XSeg solution is better, simpler and more convenient, which costs only 1 hour of manual masking for regular deepfake.<br>
&nbsp;<br>
&nbsp;<br>
== 27.03.2020 ==<br>
&nbsp;<br>
XSegEditor: fix bugs, changed layout, added current filename label<br>
&nbsp;<br>
SAEHD: fixed the use of pretrained liae model, now it produces less face morphing<br>
&nbsp;<br>
== 25.03.2020 ==<br>
&nbsp;<br>
SAEHD: added 'dfuhd' and 'liaeuhd' archi<br>
uhd version is lighter than 'HD' but heavier than regular version.<br>
liaeuhd provides more "src-like" result<br>
comparison:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;liae:&nbsp;&nbsp;&nbsp;&nbsp;https://i.imgur.com/JEICFwI.jpg<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;liaeuhd:&nbsp;https://i.imgur.com/ymU7t5E.jpg<br>
&nbsp;<br>
&nbsp;<br>
added new XSegEditor !<br>
&nbsp;<br>
here new whole_face + XSeg workflow:<br>
&nbsp;<br>
with XSeg model you can train your own mask segmentator for dst(and/or src) faces<br>
that will be used by the merger for whole_face.<br>
&nbsp;<br>
Instead of using a pretrained segmentator model (which does not exist),<br>
you control which part of faces should be masked.<br>
&nbsp;<br>
new scripts:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.XSeg) data_dst edit masks.bat<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.XSeg) data_src edit masks.bat<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.XSeg) train.bat<br>
&nbsp;<br>
Usage:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;unpack dst faceset if packed<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;run 5.XSeg) data_dst edit masks.bat<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read tooltips on the buttons (en/ru/zn languages are supported)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mask the face using include or exclude polygon mode.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;repeat for 50/100 faces,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;!!! you don't need to mask every frame of dst<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;only frames where the face is different significantly,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for example:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;closed eyes<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;changed head direction<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;changed light<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the more various faces you mask, the more quality you will get<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Start masking from the upper left area and follow the clockwise direction.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Keep the same logic of masking for all frames, for example:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the same approximated jaw line of the side faces, where the jaw is not visible<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the same hair line<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mask the obstructions using exclude polygon mode.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;run XSeg) train.bat<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;train the model<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Check the faces of 'XSeg dst faces' preview.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if some faces have wrong or glitchy mask, then repeat steps:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;run edit<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;find these glitchy faces and mask them<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;train further or restart training from scratch<br>
&nbsp;<br>
Restart training of XSeg model is only possible by deleting all 'model\XSeg_*' files.<br>
&nbsp;<br>
If you want to get the mask of the predicted face (XSeg-prd mode) in merger,<br>
you should repeat the same steps for src faceset.<br>
&nbsp;<br>
New mask modes available in merger for whole_face:<br>
&nbsp;<br>
XSeg-prd&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- XSeg mask of predicted face&nbsp;&nbsp;&nbsp;-&gt; faces from src faceset should be labeled<br>
XSeg-dst&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- XSeg mask of dst face&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&gt; faces from dst faceset should be labeled<br>
XSeg-prd*XSeg-dst - the smallest area of both<br>
&nbsp;<br>
if workspace\model folder contains trained XSeg model, then merger will use it,<br>
otherwise you will get transparent mask by using XSeg-* modes.<br>
&nbsp;<br>
Some screenshots:<br>
XSegEditor:&nbsp;https://i.imgur.com/7Bk4RRV.jpg<br>
trainer&nbsp;&nbsp;&nbsp;:&nbsp;https://i.imgur.com/NM1Kn3s.jpg<br>
merger&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;https://i.imgur.com/glUzFQ8.jpg<br>
&nbsp;<br>
example of the fake using 13 segmented dst faces<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;https://i.imgur.com/wmvyizU.gifv<br>
&nbsp;<br>
&nbsp;<br>
== 18.03.2020 ==<br>
&nbsp;<br>
Merger: fixed face jitter<br>
&nbsp;<br>
== 15.03.2020 ==<br>
&nbsp;<br>
global fixes<br>
&nbsp;<br>
SAEHD: removed option learn_mask, it is now enabled by default<br>
&nbsp;<br>
removed liaech arhi<br>
&nbsp;<br>
removed support of extracted(aligned) PNG faces. Use old builds to convert from PNG to JPG.<br>
&nbsp;<br>
&nbsp;<br>
== 07.03.2020 ==<br>
&nbsp;<br>
returned back<br>
3.optional) denoise data_dst images.bat<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Apply it if dst video is very sharp.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Denoise dst images before face extraction.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This technique helps neural network not to learn the noise.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The result is less pixel shake of the predicted face.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
SAEHD:<br>
&nbsp;<br>
added new experimental archi<br>
'liaech' - made by @chervonij. Based on liae, but produces more src-like face.<br>
&nbsp;<br>
lr_dropout is now disabled in pretraining mode.<br>
&nbsp;<br>
Sorter:<br>
&nbsp;<br>
added sort by "face rect size in source image"<br>
small faces from source image will be placed at the end<br>
&nbsp;<br>
added sort by "best faces faster"<br>
same as sort by "best faces"<br>
but faces will be sorted by source-rect-area instead of blur.<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
== 28.02.2020 ==<br>
&nbsp;<br>
Extractor:<br>
&nbsp;<br>
image size for all faces is now 512<br>
&nbsp;<br>
fix RuntimeWarning during the extraction process<br>
&nbsp;<br>
SAEHD:<br>
&nbsp;<br>
max resolution is now 512<br>
&nbsp;<br>
fix hd arhitectures. Some decoder's weights haven't trained before.<br>
&nbsp;<br>
new optimized training:<br>
for every &lt;batch_size*16&gt; samples,<br>
model collects &lt;batch_size&gt; samples with the highest error and learns them again<br>
therefore hard samples will be trained more often<br>
&nbsp;<br>
'models_opt_on_gpu' option is now available for multigpus (before only for 1 gpu)<br>
&nbsp;<br>
fix 'autobackup_hour'<br>
&nbsp;<br>
== 23.02.2020 ==<br>
&nbsp;<br>
SAEHD: pretrain option is now available for whole_face type<br>
&nbsp;<br>
fix sort by abs difference<br>
fix sort by yaw/pitch/best for whole_face's<br>
&nbsp;<br>
== 21.02.2020 ==<br>
&nbsp;<br>
Trainer: decreased time of initialization<br>
&nbsp;<br>
Merger: fixed some color flickering in overlay+rct mode<br>
&nbsp;<br>
SAEHD:<br>
&nbsp;<br>
added option Eyes priority (y/n)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Helps to fix eye problems during training like "alien eyes"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and wrong eyes direction ( especially on HD architectures )<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;by forcing the neural network to train eyes with higher priority.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;before/after&nbsp;https://i.imgur.com/YQHOuSR.jpg<br>
&nbsp;<br>
added experimental face type 'whole_face'<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Basic usage instruction:&nbsp;https://i.imgur.com/w7LkId2.jpg<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'whole_face' requires skill in Adobe After Effects.<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For using whole_face you have to extract whole_face's by using<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4) data_src extract whole_face<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5) data_dst extract whole_face<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Images will be extracted in 512 resolution, so they can be used for regular full_face's and half_face's.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'whole_face' covers whole area of face include forehead in training square,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;but training mask is still 'full_face'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;therefore it requires manual final masking and composing in Adobe After Effects.<br>
&nbsp;<br>
added option 'masked_training'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This option is available only for 'whole_face' type.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default is ON.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Masked training clips training area to full_face mask,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thus network will train the faces properly.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;When the face is trained enough, disable this option to train all area of the frame.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Merge with 'raw-rgb' mode, then use Adobe After Effects to manually mask, tune color, and compose whole face include forehead.<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
== 03.02.2020 ==<br>
&nbsp;<br>
"Enable autobackup" option is replaced by<br>
"Autobackup every N hour" 0..24 (default 0 disabled), Autobackup model files with preview every N hour<br>
&nbsp;<br>
Merger:<br>
&nbsp;<br>
'show alpha mask' now on 'V' button<br>
&nbsp;<br>
'super resolution mode' is replaced by<br>
'super resolution power' (0..100) which can be modified via 'T' 'G' buttons<br>
&nbsp;<br>
default erode/blur values are 0.<br>
&nbsp;<br>
new multiple faces detection log:&nbsp;https://i.imgur.com/0XObjsB.jpg<br>
&nbsp;<br>
now uses all available CPU cores ( before max 6 )<br>
so the more processors, the faster the process will be.<br>
&nbsp;<br>
== 01.02.2020 ==<br>
&nbsp;<br>
Merger:<br>
&nbsp;<br>
increased speed<br>
&nbsp;<br>
improved quality<br>
&nbsp;<br>
SAEHD: default archi is now 'df'<br>
&nbsp;<br>
== 30.01.2020 ==<br>
&nbsp;<br>
removed use_float16 option<br>
&nbsp;<br>
fix MultiGPU training<br>
&nbsp;<br>
== 29.01.2020 ==<br>
&nbsp;<br>
MultiGPU training:<br>
fixed CUDNN_STREAM errors.<br>
speed is significantly increased.<br>
&nbsp;<br>
Trainer: added key 'b' : creates a backup even if the autobackup is disabled.<br>
&nbsp;<br>
== 28.01.2020 ==<br>
&nbsp;<br>
optimized face sample generator, CPU load is significantly reduced<br>
&nbsp;<br>
fix of update preview for history after disabling the pretrain mode<br>
&nbsp;<br>
&nbsp;<br>
SAEHD:<br>
&nbsp;<br>
added new option<br>
GAN power 0.0 .. 10.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Train the network in Generative Adversarial manner.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Forces the neural network to learn small details of the face.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You can enable/disable this option at any time,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;but better to enable it when the network is trained enough.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Typical value is 1.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GAN power with pretrain mode will not work.<br>
&nbsp;<br>
Example of enabling GAN on 81k iters +5k iters<br>
https://i.imgur.com/OdXHLhU.jpg<br>
https://i.imgur.com/CYAJmJx.jpg<br>
&nbsp;<br>
&nbsp;<br>
dfhd: default Decoder dimensions are now 48<br>
the preview for 256 res is now correctly displayed<br>
&nbsp;<br>
fixed model naming/renaming/removing<br>
&nbsp;<br>
&nbsp;<br>
Improvements for those involved in post-processing in AfterEffects:<br>
&nbsp;<br>
Codec is reverted back to x264 in order to properly use in AfterEffects and video players.<br>
&nbsp;<br>
Merger now always outputs the mask to workspace\data_dst\merged_mask<br>
&nbsp;<br>
removed raw modes except raw-rgb<br>
raw-rgb mode now outputs selected face mask_mode (before square mask)<br>
&nbsp;<br>
'export alpha mask' button is replaced by 'show alpha mask'.<br>
You can view the alpha mask without recompute the frames.<br>
&nbsp;<br>
8) 'merged *.bat' now also output 'result_mask.' video file.<br>
8) 'merged lossless' now uses x264 lossless codec (before PNG codec)<br>
result_mask video file is always lossless.<br>
&nbsp;<br>
Thus you can use result_mask video file as mask layer in the AfterEffects.<br>
&nbsp;<br>
&nbsp;<br>
== 25.01.2020 ==<br>
&nbsp;<br>
Upgraded to TF version 1.13.2<br>
&nbsp;<br>
Removed the wait at first launch for most graphics cards.<br>
&nbsp;<br>
Increased speed of training by 10-20%, but you have to retrain all models from scratch.<br>
&nbsp;<br>
SAEHD:<br>
&nbsp;<br>
added option 'use float16'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Experimental option. Reduces the model size by half.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Increases the speed of training.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Decreases the accuracy of the model.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The model may collapse or not train.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Model may not learn the mask in large resolutions.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You enable/disable this option at any time.<br>
&nbsp;<br>
true_face_training option is replaced by<br>
"True face power". 0.0000 .. 1.0<br>
Experimental option. Discriminates the result face to be more like the src face. Higher value - stronger discrimination.<br>
Comparison -&nbsp;https://i.imgur.com/czScS9q.png<br>
&nbsp;<br>
== 23.01.2020 ==<br>
&nbsp;<br>
SAEHD: fixed clipgrad option<br>
&nbsp;<br>
== 22.01.2020 == BREAKING CHANGES !!!<br>
&nbsp;<br>
Getting rid of the weakest link - AMD cards support.<br>
All neural network codebase transferred to pure low-level TensorFlow backend, therefore<br>
removed AMD/Intel cards support, now DFL works only on NVIDIA cards or CPU.<br>
&nbsp;<br>
old DFL marked as 1.0 still available for download, but it will no longer be supported.<br>
&nbsp;<br>
global code refactoring, fixes and optimizations<br>
&nbsp;<br>
Extractor:<br>
&nbsp;<br>
now you can choose on which GPUs (or CPU) to process<br>
&nbsp;<br>
improved stability for &lt; 4GB GPUs<br>
&nbsp;<br>
increased speed of multi gpu initializing<br>
&nbsp;<br>
now works in one pass (except manual mode)<br>
so you won't lose the processed data if something goes wrong before the old 3rd pass<br>
&nbsp;<br>
Faceset enhancer:<br>
&nbsp;<br>
now you can choose on which GPUs (or CPU) to process<br>
&nbsp;<br>
Trainer:<br>
&nbsp;<br>
now you can choose on which GPUs (or CPU) to train the model.<br>
Multi-gpu training is now supported.<br>
Select identical cards, otherwise fast GPU will wait slow GPU every iteration.<br>
&nbsp;<br>
now remembers the previous option input as default with the current workspace/model/ folder.<br>
&nbsp;<br>
the number of sample generators now matches the available number of processors<br>
&nbsp;<br>
saved models now have names instead of GPU indexes.<br>
Therefore you can switch GPUs for every saved model.<br>
Trainer offers to choose latest saved model by default.<br>
You can rename or delete any model using the dialog.<br>
&nbsp;<br>
models now save the optimizer weights in the model folder to continue training properly<br>
&nbsp;<br>
removed all models except SAEHD, Quick96<br>
&nbsp;<br>
trained model files from DFL 1.0 cannot be reused<br>
&nbsp;<br>
AVATAR model is also removed.<br>
How to create AVATAR like in this video?&nbsp;https://www.youtube.com/watch?v=4GdWD0yxvqw<br>
1) capture yourself with your own speech repeating same head direction as celeb in target video<br>
2) train regular deepfake model with celeb faces from target video as src, and your face as dst<br>
3) merge celeb face onto your face with raw-predict mode<br>
4) compose masked mouth with target video in AfterEffects<br>
&nbsp;<br>
&nbsp;<br>
SAEHD:<br>
&nbsp;<br>
now has 3 options: Encoder dimensions, Decoder dimensions, Decoder mask dimensions<br>
&nbsp;<br>
now has 4 arhis: dfhd (default), liaehd, df, liae<br>
df and liae are from SAE model, but use features from SAEHD model (such as combined loss and disable random warp)<br>
&nbsp;<br>
dfhd/liaehd - changed encoder/decoder architectures<br>
&nbsp;<br>
decoder model is combined with mask decoder model<br>
mask training is combined with face training,<br>
result is reduced time per iteration and decreased vram usage by optimizer<br>
&nbsp;<br>
"Initialize CA weights" now works faster and integrated to "Initialize models" progress bar<br>
&nbsp;<br>
removed optimizer_mode option<br>
&nbsp;<br>
added option 'Place models and optimizer on GPU?'<br>
&nbsp;&nbsp;When you train on one GPU, by default model and optimizer weights are placed on GPU to accelerate the process.<br>
&nbsp;&nbsp;You can place they on CPU to free up extra VRAM, thus you can set larger model parameters.<br>
&nbsp;&nbsp;This option is unavailable in MultiGPU mode.<br>
&nbsp;<br>
pretraining now does not use rgb channel shuffling<br>
pretraining now can be continued<br>
when pre-training is disabled:<br>
1) iters and loss history are reset to 1<br>
2) in df/dfhd archis, only the inter part of the encoder is reset (before encoder+inter)<br>
&nbsp;&nbsp;&nbsp;thus the fake will train faster with a pretrained df model<br>
&nbsp;<br>
Merger ( renamed from Converter ):<br>
&nbsp;<br>
now you can choose on which GPUs (or CPU) to process<br>
&nbsp;<br>
new hot key combinations to navigate and override frame's configs<br>
&nbsp;<br>
super resolution upscaler "RankSRGAN" is replaced by "FaceEnhancer"<br>
&nbsp;<br>
FAN-x mask mode now works on GPU while merging (before on CPU),<br>
therefore all models (Main face model + FAN-x + FaceEnhancer)<br>
now work on GPU while merging, and work properly even on 2GB GPU.<br>
&nbsp;<br>
Quick96:<br>
&nbsp;<br>
now automatically uses pretrained model<br>
&nbsp;<br>
Sorter:<br>
&nbsp;<br>
removed all sort by *.bat files except one sort.bat<br>
now you have to choose sort method in the dialog<br>
&nbsp;<br>
Other:<br>
&nbsp;<br>
all console dialogs are now more convenient<br>
&nbsp;<br>
XnViewMP is updated to 0.94.1 version<br>
&nbsp;<br>
ffmpeg is updated to 4.2.1 version<br>
&nbsp;<br>
ffmpeg: video codec is changed to x265<br>
&nbsp;<br>
_internal/vscode.bat starts VSCode IDE where you can view and edit DeepFaceLab source code.<br>
&nbsp;<br>
removed russian/english manual. Read community manuals and tutorials here<br>
https://mrdeepfakes.com/forums/forum-guides-and-tutorials<br>
&nbsp;<br>
new github page design<br>
&nbsp;<br>
== for older changelog see github page ==</code></div></div>
		</div>
		
		<!-- start: postbit_signature -->
<div class="panel panel-primary">
<div class="signature scaleimages padding-8px">
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Open for commissions</span>, if you want a custom deepfake made,&nbsp;send me a private message.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="color: #ffcc33;" class="mycode_color">Want to learn DFL and guides aren't enough? I offer DeepFaceLab courses, message me for details.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Also consider donation&nbsp;towards running our website!</span></span></div>

</div>
</div>
<!-- end: postbit_signature -->
		<div class="post_meta" id="post_meta_16813">
                        
                        <div style="" id="tyl_16813"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(16813);return false;" title="[-]" id="tyl_a_expcol_16813"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_16813"></a> 
	<span id="tyl_title_16813" style=""><strong>The following 4 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post:</strong></span><span id="tyl_title_collapsed_16813" style="display: none;"><strong>4 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post</strong></span><br>
	<span id="tyl_data_16813" style="">&nbsp;&nbsp;• <span class="smalltext"></span><a href="https://mrdeepfakes.com/forums/user-clovis-brithgtex" class="tt smalltext" title="03-27-2020">clovis-brithgtex</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-glaewion" class="tt smalltext" title="10-03-2020">glaewion</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-howdoigitgud" class="tt smalltext" title="06-18-2020">HowDoIGitGud</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-umair" class="tt smalltext" title="06-21-2020">umair</a></span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=24245" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=16813" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_16813_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_16813">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=16813" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_16813").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit --><!-- start: postbit -->

<a name="pid16814" id="pid16814"></a>
<div class="post " style="" id="post_16814">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-tuts"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_24245.jpg" alt="" width="55" height="55"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				Moderator<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat2">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat2">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=16814#pid16814" title="RE: [GUIDE] - DeepFaceLab 2.0 EXPLAINED AND TUTORIALS (recommended)">#3</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">02-10-2020, 08:27 PM <span class="post_edit" id="edited_by_16814"><!-- start: postbit_editedby -->
<span class="edited_post">(This post was last modified: 01-11-2021, 12:31 AM by <a href="https://mrdeepfakes.com/forums/user-tuts">Tuts</a>.)</span>
<!-- end: postbit_editedby --></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_16814">
			<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">DFL 2.0 Frequently asked questions - workflow tips, methods and techniques. - in making.</span></span></span><br>
<br>
For XSEG FAQ visit XSEG guide:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
Use ctrl+f to find what you are looking for, scroll to the bottom for some tips and links to some useful&nbsp;stuff.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">1.Q: What's the difference between 1.0 and 2.0?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: 2.0 is an improved and more optimized version, because of the optimization it offers better performance which means you can train higher resolution models or train existing ones faster. Merging and extraction is also significantly faster.<br>
</span><br>
"That's great" you say... "But where is the catch?"<br>
<br>
The catch is that&nbsp;DFL 2.0 no longer supports AMD GPUs/OpenCL, the only way to use it is with Nvidia GPU (minimum 3.0 CUDA compute level supported GPU required) or CPU.<br>
Bear in mind training on a CPU is much slower and so is every other step like extraction&nbsp;and merging (previously called conversion).<br>
<br>
Also the new version comes only with 2 models - SAEHD&nbsp;and Quick 96, no H128/H64/DF/LIAEF/SAE models are available. Also all&nbsp;trained/pretrained&nbsp;models (SAE/SAEHD) from 1.0 are not compatible with 2.0 so you need to train new models. There are also some other changes about which you can read about&nbsp;more in the main guide post above.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">2. Q:&nbsp;How long does it take to make a deepfake?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A:&nbsp;Depending on how long your target (DST) video is, how large your SRC dataset/faceset&nbsp;is and what kind of model you are using to train your fake as well as your hardware (GPU).<br>
<br>
</span>It may take anywhere from&nbsp;half a&nbsp;day for a simple, short fake&nbsp;on a pretrained model to even 5-7&nbsp;days if you are training your model&nbsp;from scratch or making a longer deepfake, especially if it's high resolution whole face type one that requires additional training of XSeg model and maybe even some work after&nbsp;merging in video editing software. It also depends on the hardware you have, if you'r gpu has less VRAM (4-6 GB) it will take longer to train a model that with a more capable GPU (8-24GB). It also depends on your skills, how fast you can find source materials for SRC dataset/faceset, how fast you can find suitable target (DST) video and how fast you can prepare both datasets for training.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">3. Q: Can you make a deepfake video with just a few pictures?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A:&nbsp;In general, the answer will be no. The recommended way to make a faceset to make a decent deepfake is to use videos.</span><br>
The more angles and facial expressions the better. Sure you can try to make a deepfake video with just a couple hundred photos, it will work, but the results will be less convincing.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">4. Q:&nbsp;What is the ideal faceset size?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A:&nbsp;For the data_src (celebrity) faceset, It's recommend to have at least 4000-6000 different images.<br>
</span>Of course&nbsp;you can have more but generally 10.000-15.000 images is more than enough as long as there is variety in the dataset (different face angles and expressions).<br>
It's best to take them for as little sources as possible, the more sources are used (especially when similar expressions/angles "overlap" between different sources) the higher the chance of model morphing to DST and looking more like SRC which may require running TF or keeping model training with RW enabled longer. For more detailed guide on making source facesets/datasets check this guide:<br>
You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">5. Q:&nbsp;Why are my deepfakes turning out blurry?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A:&nbsp;There are many reasons for blurry faces.</span><br>
Most often causes include - not training long enough, lack of necessary angles in the source dataset, bad alignment of the extracted source or destination facesets/datasets, bad settings during training or merging, blurry faces in the source or destination facesets/datasets. If you want to know what to do and what to avoid when making a deepfake please read the first post in this thread (guide part).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">6. Q: Why is my result face&nbsp;not blinking/eyes look&nbsp;wrong/are cross-eyed?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: This is most likely due to the lack of images in your data_src containing faces with closed eyes or with eyes looking in specific directions on some or all angles.</span><br>
Make sure you have a decent amount of different facial expressions at all possible angles to match the expressions and angles of faces in the destination/target video - that includes faces with closed eyes and looking in different directions, without those the model doesn't know how face's eyes should look like, resulting in eyes not opening or looking all wrong.<br>
Another cause for this might be running training with wrong settings or decreased dims settings.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">7. Q: When should I stop training?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: There is no correct answer, but the general consensus is to use the preview window to judge when to stop training and convert.</span><br>
<span style="color: #ff3333;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">There is no exact iteration number or loss value where you should stop training.</span></span>&nbsp;I would recommend at least 100.000 iterations if you are running a pretrained model or 200.000 iterations if you are running a fresh model from 0&nbsp;but that number might be even as high as 300.000 iterations (depending on the variety and number of faces the model must learn).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">8. Q: When should I enable or&nbsp;disable random warp, GAN, True Face, Style Power, Color Transfer and Learning Rate Dropout?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: There is no correct answer as to when as it depends on how well your model is trained and performing in a given time, but there is a correct order of enabling/disabling them.</span><br>
<br>
1. Starting with Random Warp, it should be enabled as long as needed to get the model to generalize and reach&nbsp;loss values around&nbsp;0.4-0.6 -&nbsp;predicted faces (2nd and 4th column in the preview) and final result face (5th column) should look correct but may still be blurry.<br>
<br>
2. Next you can enable options like Uniform Yaw to help generalize profile face or help train them in case you don't have many in your source dataset but this option is not necessary always to be ran with RW and can be enabled later when you disable RW.<br>
<br>
3. Before you disable RW you can enable LRD and train your model more with it enabled to help it&nbsp;learn more during this stage, next you will&nbsp;disable RW and LRD so that model can carry on training correctly in this next stage. Later after you train with RW being disabled and optionally run some other options for 4-9 you can enable LRD for the 2nd time, after LRD you shouldn't be enabling any other options except for GAN.<br>
<br>
4.&nbsp;True Face&nbsp;and Style Power&nbsp;can be used before or after disabling Random Warp but it's recommended to use them once RW is disabled and before enabling LRD.<br>
<br>
5. GAN&nbsp;should be enabled last and must be enabled when LRD is also enabled.<br>
<br>
6. Color transfer can be enabled from the start or near the&nbsp;end of training, it all depends on how well your SRC faceset/dataset is matched color wise to your DST/target video.<br>
<br>
7.&nbsp;Random Flip should be only enabled if&nbsp;your&nbsp;source faceset/dataset that is missing some angles - beware that using random flip may cause some issues and if face has some unsymmetrical features - they will be mirrored, also it's recommended to start random flip while RW is still enabled.<br>
<br>
8. Masked training (whole face only) should be enabled for most of the training as it helps to train just what the model needs to learn, which is face area defined by the applied XSeg mask (or default full face mask if XSeg mask is not applied) but if you're planning on eroding the mask during merging (if the source face is bigger/wider than DST and you don't want it's shape to be clipped by the mask) you can disable it, if you do it make sure you do it before enabling GAN.<br>
<br>
9. Eyes&nbsp;priority should be enabled after disabling RW but before LRD and&nbsp;GAN, as for other options it might cause issues (true face, style power). In some cases users reported good results when running it when RW was still on so experiment but remember that enabling it will prioritize eyes area and rest of the face won't be learning nearly as quickly as it normally would.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">9. Q: DFL isn't working at all (extraction, training, merging) and/or I'm getting an error message.</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">Your GPU might&nbsp;not be supported, you are trying to run an old model on newer version of DFL (or the other way) or there is an issue with the software or your PC.<br>
</span><br>
First check if your GPU is supported, DFL requires CUDA compute capability of 3.0:<br>
You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
Then see if you have the newest version of DFL which you can get here:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
Then check if the model you are trying to run is still compatible, the easiest way is to try run a new model with the same parameters (adjust batch size to a low value like 2-4 for testing purposes)<br>
If you are still having issue, check your PC, things like out of date GPU drivers and pending Windows updates can cause some issues.<br>
If then it's still not working you can create a new thread in the question section, but before you do that check the issues tab on github to see if other users don't have the same issue/error:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
If you can't find anything and you've&nbsp;searched forum for similar issues&nbsp;make a new thread here:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.&nbsp;or post about it here.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">10. I'm getting OOM/out of memory errors while training SAEHD.</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">If you are getting OOM errors it means you are running out of VRAM, there are various settings you can change&nbsp;to fix that:</span><br>
<br>
a) decrease batch size - lower batch size means the model trains on less images thus using less VRAM but it means that you will have to train longer to achieve the same result than with higher batch size, extremely low batch size like 2-4 may also lead to less accurate results.<br>
<br>
b) change&nbsp;optimizer setting (<span style="color: #ffcc33;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">models_opt_on_gpu</span></span>)&nbsp;- when set to True the optimizer and model are both handled by GPU which means faster iteration times/performance/faster training but VRAM usage is higher, when set to False the duty of running network optimizer is handled by your CPU which means less VRAM usage and possible no OOM or even higher possible batch size but the training will be slower due to longer iteration time.<br>
<br>
c) turn off additional features like&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">face and bg style transfer, True Face training, GAN training or&nbsp;performance&nbsp;heavy CT method like SOT-M&nbsp;</span></span>- enabling them increases iteration/training time and uses more VRAM.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">11. Q:&nbsp;I've turned off all additional features and the training is still giving me OOM errors even at low batch size.</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: In that case you change even more settings but it will require you to start new model training because following can be only set once:</span><br>
<br>
a) run models with reduced resolution&nbsp;-&nbsp;even with all the optimization you can do and disabling various features you may still not be able to run your desired resolution, just decrease it till you can run it (by the factor of 16)<br>
<br>
b) decrease&nbsp;<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">AutoEncoder dimensions</span>,&nbsp;</span></span><span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Encoder dimensions</span>,&nbsp;</span></span><span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">Decoder dimensions</span>,&nbsp;</span></span><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color">Decoder mask dimensions.</span><br>
</span></span>These settings control models dimensions so changing them can have dramatic effect on the models ability to learn features of the face and expressions. To low value may mean the model won't close eyes or not learn some facial feature. Only change them if there is nothing else you can do. For more info on what they do check the guide.<br>
<br>
c) buy a GPU with more VRAM.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">12. Q: I have too many similar faces in my source dataset, is there a tool I can use to remove them?<br>
</span></span><br>
<span style="font-weight: bold;" class="mycode_b">A: Yes, you can either use DFL built in sorting methods or use app like&nbsp;VisiPics to detect similar looking faces in your source dataset and remove them.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">13. Q: I was training my model that already had several thousands iterations&nbsp;but the faces in&nbsp;preview window suddenly turned black/white/look weird, my loss values went up/are at zero.</span><br>
<br>
A: Your model has collapsed, it means you cannot use it anymore and you have to start all over or if you had backups, use them.<br>
</span>To prevent model collapsing use gradient clipping or just enable backups, usually models don't collapse unless you use style power (in that case enabling gradient clipping is highly recommended) but if you're afraid of it collapsing anyway even without any other features enabled you can leave it enabled all the time at the small performance impact (might be hard to notice, about 50-100ms extra at most according to my tests).<br>
<span style="color: #ff6633;" class="mycode_color"><br>
<span style="font-weight: bold;" class="mycode_b">14. Q:&nbsp;</span></span><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">If I train a model on Celeb A (data_src) and Celeb B (data_dst) can I use the same model trained to swap Celeb A onto Celeb C (new data_dst)? Can/Should I reuse models when training the same source?</span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color">A: Yes, it is actually recommended to re</span><span style="color: #a9afbc;" class="mycode_color">use you models if you plan on making more fakes of the same source. You can also resuse model when working with completely different source and destination/target datasets. Make sure to re-enable RW when starting training for optimal results (especially if the new target dataset face differs significantly from previous one or both source and destination datasets are different/new).</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">15. Q: Should I pretrain my models?</span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color">A: As with reusing, yes, you should pretrain.</span></span><br>
<span style="color: #a9afbc;" class="mycode_color">Use the built in pretrain function inside DFL which you can select when starting up a model. It is the correct way to pretrain your model, run this feature for anywhere from 200k to 400k&nbsp;iterations and turn it off once you want to finish pretraining.<br>
<br>
</span><span style="color: #ff6633;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">16. Q: I'm getting an error:&nbsp;is not a dfl image file required for training in DeepFaceLab<br>
<br>
</span></span><span style="font-weight: bold;" class="mycode_b">A: It means that the pictures inside data_src/aligned and/or data_dst are not valid for training in DFL.<br>
</span><br>
This can be caused be several things:<br>
<br>
1. You are using one of the shared datasets of a celebrity, chances are they were made in a different software than DFL or in older version of it, even though the look like aligned faces (256x256 images) they may be just pictures extracted in different app that stored landmarks/alignment data in different way. To fix them all&nbsp;you need to is to just run alignment process on them, just place them into a "data_src" folder (not "aligned" folder inside it)&nbsp;and align them again by using&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4) data_src extract faces S3FD</span></span><br>
<br>
2. You edited&nbsp;faces/images inside aligned folder of data_src or data_dst in gimp/photoshop after aligning.<br>
When you edit those images you overwrite landmarks/alignments data that is stored inside them.<br>
If you want to edit these images first run&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4.2) data_src util faceset metadata save</span></span>&nbsp;to save alignment info in a separate file, then edit your images&nbsp;and run&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4.2) data_src util faceset metadata restore</span></span>&nbsp;to restore that data.<br>
Only edits allowed are AI&nbsp;up-scaling/enhancing&nbsp;(which you can now also do using&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">4.2) data_src util faceset enhance</span></span>&nbsp;instead of using external apps like Gigapixel), color correction or edits to the face that don't change it's shape (like removing or adding stuff), no flipping/mirroring or rotation is allowed.<br>
<br>
3. You have regular, non extracted/aligned images in your "data_src/dst" or "aligned" folder.<br>
<br>
4. You have _debug faces in your "data_src/aligned" folder. Delete them.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">17.&nbsp;Q: I'm getting errors during conversion:&nbsp;</span></span><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">no faces found for XYZ.jpg/png, copying without faces.</span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color">A: It means that for XYZ frame in "data_dst" folder&nbsp;</span><span style="color: #a9afbc;" class="mycode_color">no faces were extracted into "aligned" folder.</span></span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color">This may be because there were actually no faces visible in that frame (which is normal)&nbsp;</span><span style="color: #a9afbc;" class="mycode_color">or they were visible but due to an&nbsp;</span><span style="color: #a9afbc;" class="mycode_color">angle at which they were</span><span style="color: #a9afbc;" class="mycode_color">&nbsp;or obstruction they were not detected.</span><br>
<span style="color: #a9afbc;" class="mycode_color">To fix that you need to&nbsp;</span><span style="color: #a9afbc;" class="mycode_color">extract those faces manually. Check the main guide, especially the section on cleaning up your data_dst dataset.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Overall you should make sure that you have as many faces aligned and properly extracted BEFORE starting to train.</span></span><br>
And remember that both datasets should be cleaned up before training, to know more check the first post (guide) and also read this thread about preparing source datasets for use in training and for sharing on our forum:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">18.&nbsp;Q: I'm getting errors:&nbsp;Warning: several faces detected. Highly recommended to treat them separately and&nbsp;</span></span><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">Warning: several faces detected. Directional Blur will not be used. during conversion</span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color">A: It's caused by multiple faces within</span><span style="color: #a9afbc;" class="mycode_color">&nbsp;your data_dst/aligned folder.</span></span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color">The extraction process attemps to detect face in each frame at all cost.&nbsp;If it does detect multiple faces or one real face and falsely detects something else as a face it&nbsp;creates multiple files for each frames&nbsp;that look like this:&nbsp;</span><span style="color: #a9afbc;" class="mycode_color">0001_0.jpg 0001_1.jpg 0001_2.jpg (in case of detecting 3 faces).</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">19. Q: After merging I see original/DST faces on some or all merged&nbsp;frames.</span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color">A: Make sure your converter mode is set to overlay or any other mode except for&nbsp;"original" and make sure you've&nbsp;aligned faces from all frames of your data_dst.mp4 file.<br>
<br>
</span></span>If you only see original faces on some frames,&nbsp;it's because they were not detected/aligned from those&nbsp;corresponding&nbsp;frames, it may happen due to various reasons: extreme angle where it's hard to see the face,&nbsp;blur/motion blur,&nbsp;obstructions, etc.&nbsp;Overall you want to always have all faces from your data_dst.mp4 aligned.<br>
<br>
<span style="color: #ff6633;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">20.&nbsp;Q: What do those 0.2513&nbsp;</span><span style="font-weight: bold;" class="mycode_b">0.5612&nbsp;</span><span style="font-weight: bold;" class="mycode_b">numbers mean when training?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: These are loss values. They indicate how well model is trained.</span><br>
But you shouldn't focus on them unless you see sudden spikes in their value (up or down) after they already settled around some value (assuming you didn't change any model parameters), instead focus on preview windows and look for details like teeth separation, beauty marks, nose, eyes, if they are sharp and look good, then you don't have to worry about anything. If you notice loss values going up for some reason despite not changing any values consider stopping training and resuming it with gradient clipping or disabling some additional options that you might have enabled at the wrong setting which is now causing issues.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">21. Q: What are the ideal loss values, how low/high loss values should be?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: It all depends on the settings, datasets and various different factors.</span><br>
Generally you want to start training with all features disabled except for&nbsp;<span style="color: #ffcc33;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">random warp of samples</span></span>&nbsp;(and optionally&nbsp;<span style="color: #ffcc33;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">gradient clipping&nbsp;</span></span>to prevent model collapses and&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">random flip</span></span>&nbsp;in case your source dataset is lacking some face/head angles) to a loss under 0.4-0.5 (depending on the model architecture and whether it's a full face model that runs with masked training disabled or whole face/head model that runs with masked training enabled as well as models resolution or model dimensions).<br>
After you disable random warp model should be able to reach loss values between 0.15 and 0.25.<br>
In some cases your model might get stuck at certain loss value or never reach lower one.<br>
<br>
<span style="color: #ff6633;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">22. Q: My model has collapsed, can I somehow recover it?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: No, you need to start over, or use backup if you made them.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">23. Q: What to do if you trained with a celebtity faceset and you want to add more faces/images/frames to it? How to add more variety to existing src/source/celebrity dataset?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: Safest way is to change the name of the entire "data_src" folder to anything else or to temporarily move&nbsp;it somewhere else, then just extract frames from new data_src.mp4 file or if you already have the frames extracted and some pictures ready, create a new folder "data_src", copy them inside it and run data_src extraction/aligning process, then just copy aligned images from the old data_src/aligned folder into the new one and upon being asked by windows to replace or skip, select the option to rename files so you keep all of them and not end up replacing old ones with new ones.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">24. Q: Does the dst faceset/data_dst.mp4 also need to be&nbsp;sharp and&nbsp;high quality? Can some faces in dst faceset/dataset/data_dst be a bit blurry/have shadows, etc? What to do with blurry faces in my data_dst/aligned folder</span></span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">A: You want your data_dst to be as sharp and free of any motion blur as possible.&nbsp;Blurry faces in data_dst can cause a couple issues:</span><br>
<br>
-&nbsp;first is that some of the faces in certain frames will not get detected - this will cause original faces to be shown on these frames when converting/merging because they couldn't be properly aligned during extraction so you will have to extract them manually.<br>
</span>- second is that others may be incorrectly aligned - this will cause final faces on this frames to be rotated/blurry and just look all wrong and similar to other blurry faces will have to be manually aligned to be used in training and conversion.<br>
- third - even with manual aligning in some cases it may not be possible to correctly detect/align faces which again - will cause original faces to be visible&nbsp;on corresponding frames.<br>
- faces that contain motion blur or are blurry (not sharp) that are correctly aligned may still produce bad results because the models that are used in training cannot understand motion blur, certain parts of the face like mouth when blurred out may appear bigger/wider or just different and the model will interpret this as a change of the shape/look of that part and thus both the predicted and the final faked face will look unnatural.<br>
You should remove those blurry faces from training dataset (data_dst/aligned folder) and put them aside somewhere else and then copy them back into data_dst/aligned folder before converting so that we get the swapped face to show up on frames corresponding to those blurry faces.<br>
To combat the odd look on face in motion you can use motion blur within the merger (but not it will only work if one set of faces is in the "data_dst/aligned" folder and all files end with _0 prefix).<br>
<br>
You want both your SRC datasets and DST datasets to be as sharp and high quality&nbsp;as possible.<br>
Small amount of blurriness&nbsp;on some frames shouldn't cause many issues. As for shadows, this depends on how much shadow we are talking about, small, light shadows will probably not be visible, you can get good results with shadows on faces but to much will also look bad, you want your faces to be&nbsp;lit as evenly as&nbsp;possible with as little of&nbsp;harsh/sharp and dark shadows as possible.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">25. Q: I'm getting error&nbsp;reference_file not found when I try to convert my deepfake back into mp4 with&nbsp;8) converted to&nbsp;</span></span><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">mp4.</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: You are missing data_dst.mp4 file in your "workspace" folder, check if it wasn't deleted:</span><br>
<br>
Reason why you need it is that even though you separated it into individual frames with&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">3) extract images from video data_dst FULL FPS</span></span>&nbsp;all there is inside "data_dst" folder is just frames of the video, you also need sound, which is taken from the original data_dst.mp4 file.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">26. Q: I accidentally deleted my data_dst.mp4 file and cannot recover it, can I still turn merged/converted frames into an mp4 video?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: Yes, in case you've permanently deleted data_dst.mp4 and you have no way of recovering it or rendering identical file you can still convert it back into mp4 (albeit&nbsp;without sound) manually by using ffmpeg and a proper command:</span><br>
<br>
- start by going into folder ...:\_internal\ffmpeg and copy ffmpeg.exe<br>
- paste it into the merged folder<br>
-&nbsp;open up command line by pressing windows key + r (run) and typing cmd or searching it up after pressing windows key and typing cmd/cmd.exe<br>
- copy address of your merged folder (example: D:\DFL\workspace\data_dst\merged)<br>
- in the command line type the letter of your drive,&nbsp;as in example above that would be "d:" (without quotation marks) and press enter<br>
- line D:\&gt; should appear, next type "cd:&nbsp;FULL_ADDRESS", example: "cd:&nbsp;D:\workspace\data_dst\merged"<br>
- you should now see your entire address like this:&nbsp;D:\DFL\workspace\data_dst\merged&gt;<br>
- enter this command:<br>
<br>
ffmpeg -r xx&nbsp;-i %d.jpg -vcodec libx264 -crf 20&nbsp; -pix_fmt yuv420p result.mp4<br>
<br>
- xx&nbsp;is framerate<br>
-&nbsp;d is a number representing amount of numbers in the file name so if your merged frames have names like 15024.jpg that&nbsp;would be&nbsp;5, if it's 5235.jpg it is 4, etc.<br>
If your images are pngs, change .jpg to .png<br>
- crf is quality setting, best to be left at 20.<br>
If your merged file names have some letters in front like out12345.jpg add "out" before the % sign.<br>
<br>
<span style="color: #ff9933;" class="mycode_color">Example command for converting frames named "out_2315.png" into an 30 fps .mp4 file named "deepfake".</span><br>
<br>
<span style="color: #ff9933;" class="mycode_color">ffmpeg -r 30&nbsp;-i out%4.png&nbsp;-vcodec libx264 -crf 20&nbsp; -pix_fmt yuv420p deepfake.mp4<br>
</span><br>
If you want to use x265 encoding change&nbsp;<span style="color: #ff9933;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">libx264</span>&nbsp;</span>to<span style="color: #ff9933;" class="mycode_color">&nbsp;<span style="font-weight: bold;" class="mycode_b">libx265</span></span>.<br>
<br>
<span style="color: #ff9933;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">27. Q: Can you pause merging and resume it later? Can you save merger settings? My merging failed/I got error during merging and it's stuck at %, can I start it again and merge from last successfully merged frame?</span></span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: Yes, by default interactive converter/merger creates session file in the "model" folder that saves both progress and settings.</span><br>
<br>
If you want to just pause the training you can hit &gt;&nbsp;and it will pause. If however you need to turn it off completely/restart pc, etc you exit from merger with esc and wait for it to save your progress, next time you launch merging, after selecting interactive merger/converter (Y/N) - Y you'll get a prompt asking if you want to use the save/session file and resume the progress, merger will load with the right settings at the right frame.<br>
<br>
If your merging failed and it didn't save the progress you will have to resume it manually, you do it by first backing up your "data_dst"&nbsp;folder and then deleting all extracted frames inside data_dst&nbsp;as well as all images from "aligned"&nbsp;folder inside "data_dst"&nbsp;that correspond&nbsp;to frames already converted/merged inside folder "merged". Then just start merger/converter, enter settings you used before and convert rest of frames, then combine new merged frames with old ones from&nbsp;the backup "data_dst" folder and convert to .mp4 as usual.<br>
<br>
<span style="color: #ff9933;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">28. Q: Faces in preview during training&nbsp;look good but after converting them they look bad. I see parts of the original face (chin, eyebrows, double face outline).</span></span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: Faces in preview are the raw output of the AI that then need to be composited over the original footage.<br>
</span>Because of it, when faces have different shapes, or are slightly smaller/bigger you may see parts of the original face around/outside the mask that DFL merger creates.<br>
To fix it you need to change conversion settings, start by:<br>
<br>
- adjusting the mask type<br>
<br>
- adjust mask erosion (size) and blur (feathering, smoothing the edge)<br>
<br>
- adjust face size (scale)<br>
<br>
NOTE: Negative erosion&nbsp;increases the mask size (covers more), positive decreases it.<br>
<br>
<span style="color: #ff9933;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">29. Q: Final result/deepfake has weird artifacts,&nbsp;face changes colors, color bleed from background and make it flicker/darken/change color in the corners/on the edges when using Seamless mode.</span></span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A:&nbsp;You are using seamless/hist/seamless+hist overlay&nbsp;mode or you trained your model with source dataset/faceset&nbsp;with varying lighting conditions and didn't use any color transfer during training.<br>
<br>
</span>- use overlay or any other mode besides seamless/hist/seamless+hist<br>
- if you want to use seamless:<br>
-&nbsp;decrease&nbsp;size&nbsp;of the mask/face so it doesn't "touch" areas outside and doesn't as a result get the color of background/area outside of the face/head by increasing&nbsp;<span style="font-weight: bold;" class="mycode_b">"Erode Mask"&nbsp;</span>value.<br>
- or smooth out the edge of the mask/face&nbsp;by increasing&nbsp;<span style="font-weight: bold;" class="mycode_b">"Blur Mask"&nbsp;</span>value which may hide some of the color changes, also helps make the face seem more... "seamless"&nbsp; when you decrease mask size.<br>
Both of these may or may not fix the issue, if still persist use simple overlay mode as stated above.<br>
<br>
If your source dataset contained images of faces with varying lighting conditions and didn't use color transfer you may need to go back and keep training some more with color transfer enabled.<br>
In case turning it on severely washes out colors or affects colors of training data/faces in a bad way (washed out colors, wrong colors, over saturated colors, noise) or makes the learned face blurry (due to too much variations that the model must learn all over as if there were new faces in your source and destination&nbsp;dataset) you may want to save landmarks data and edit your source dataset colors to better match your destination dataset&nbsp;and also have less variation.<br>
<br>
I recommend to NOT use&nbsp;seamless unless it's absolutely needed and even then I recommend stopping on every major angle and camera&nbsp;shift/light change to see if it doesn't cause those artifacts.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><br>
30. Q: What's the difference between half face, mid-half face,&nbsp;full face and whole face&nbsp;face_type modes?</span></span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">A:&nbsp;</span>Whole face is a new mode that covers entire face/head, that means it also covers entire forehead and even some hair and other features that could be cut of by the full face mode and would definitely never be visible when using mid-half or half face mode. It also comes with new option during training that let's you train the forehead called&nbsp;</span><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">masked_training</span></span>. First you start with it enabled and it clips the training mask to full face area, once face is trained sufficiently you disable it and it trains the whole face/head. This mode requires either manual masking in post or training your own XSeg model:<br>
<span style="color: #a9afbc;" class="mycode_color">You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
Full face is a recommended face_type mode to get as much coverage of face as possible without anything that's not needed (hairline, forehead and other parts of the head)<br>
Half face mode was a default face_type mode in H64 and H128 models. It covers only half of the face (from mouth to a bit below eyebrows)</span><br>
<span style="color: #a9afbc;" class="mycode_color">Mid-half face is a mode that covers around 30% larger area than half face.</span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">31. Q: What is the best GPU for deepfakes? I want to upgrade my gpu, which one should I get?</span></span></span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">A:</span>&nbsp;<span style="font-weight: bold;" class="mycode_b">Answer to this will change as deepfaking software gets further developed and GPUs become more powerful but for now the best GPU is the one that has most VRAM and is generally fas</span></span></span><span style="font-weight: bold;" class="mycode_b">t.</span><br>
<br>
For performance figures check our SAE spreadsheet:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
<span style="color: #a9afbc;" class="mycode_color">Recommended minimum is 6GB of VRAM 10 series GPU (1060 6GB) - good for resolutions between 128-160.<br>
For higher resolution models (160-192) it's recommended to get at least 8GB VRAM equipped 10/20 series&nbsp;GPU (1070/2070) or higher.<br>
For highest resolutions (192-256) you may need as much as 11GB or more VRAM 10/20 series GPU (1080Ti,2080Ti, RTX Titan)&nbsp;or higher.<span style="color: #a9afbc;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color"><br>
<br>
Bear in mind that training performance depends on settings used during training, a full enabled (all features on) 128 DF model may run slower than an 192 DFHD model with turned down dims and all features disabled.<br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">32. Q: What do the AutoEncoder, Encoder, Decoder and D_Mask_Decoder dims settings do? What does changing them does?</span></span></span></span></span></span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">A:&nbsp;</span><span style="font-weight: bold;" class="mycode_b">AutoEncoder, Encoder, Decoder and D_Mask_Decoder dims affect models neural network dimensions.<br>
</span></span></span><br>
They can be changed to either increase performance or quality, setting them to high will make models really hard to train (slow, high vram usage) but will give more accurate results and more src like looking face, set it to low and performance will increase but the results will be less accurate and model may not learn certain features of the faces, resulting in generic output that looks more like dst or nothing like either dst or src.<br>
</span><br>
AutoEncoder dimensions&nbsp;( 32-1024 ?:help ) :&nbsp;this is the overall model capacity to learn.<br>
Too low value and it won't be able to learn everything - higher value will make model be able to learn more expressions and be more accurate at the cost of performance.<br>
<br>
Encoder dimensions&nbsp;( 16-256 ?:help ) :&nbsp;this&nbsp;affects the ability&nbsp;of the model to learn different expressions, states of the face, angles, lighting conditions.<br>
Too low value and model may not be able to learn certain expressions, model might not be closing eyes, mouth, some angles may be less detailed accurate, higher value will lead to more accurate and expressive model assuming AE dims will be increased accordingly&nbsp;at the cost of performance.<br>
<br>
Decoder dimensions&nbsp;( 16-256 ?:help ) :&nbsp;this&nbsp;affects the ability of the model to learn fine detail, textures, teeth, eyes - small things that make face detailed and recognizable.<br>
Too low value will cause some details to not be learned (such as teeth and eyes looking blurry, lack of texture), also some subtle expressions and facial features/texture may not be learned properly, resulting in less src like looking face, higher value will make the face more detailed and model will be able to pick up more of those subtle details&nbsp;at the cost of performance.<br>
<br>
Decoder mask dimensions&nbsp;( 16-256 ?:help ) :&nbsp;affects quality of the learned mask when training with&nbsp;Learn mask&nbsp;enabled. Does not affect the quality of training.<br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">33. Q: Whats the recommended batch size? How high should I set the batch size? How low can batch size be set?</span></span></span></span></span></span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color"><span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">A:&nbsp;</span><span style="font-weight: bold;" class="mycode_b">There is no recommended batch size but the reasonable value is between 8-12, with values above 16-22 being exceptionally good and 4-6 being a minimum.<br>
</span></span></span><br>
Batch size of 2 is not enough to correctly train a model so value of 4 is the recommended minimum, the higher the value the better but at some point higher batch size may not be beneficial, especially if your iteration time starts to increase or you have to disable&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">models_opt_on_gpu</span></span></span>&nbsp;- and thus forcing optimizer on CPU which slows down training/increases iteration time.<br>
You can calculate when increasing batch size is becoming less efficient by dividing iteration time by the batch size. Choose that batch size that gives you lower ms value per batch for a given iteration time, for example:<br>
<br>
1000 ms at batch 8 - 1000 / 8 = 128<br>
1500 ms at batch 10 - 1500 / 10 = 150<br>
<br>
In this case running with batch 8 will be feeding model more data in a given time than with batch 10. However the difference is small. If say we want to use batch 12 but we get an OOM - so we disable&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #a9afbc;" class="mycode_color"><span style="color: #ffcc33;" class="mycode_color">models_opt_on_gpu</span></span></span>&nbsp;it may now look like this:<br>
2300 ms at batch 12 (Optimizer on CPU) - 2300 / 12 = 191 ms which is much longer that 128 ms with batch 8 and iteration time of 1000 ms.<br>
<br>
When starting model it's better to go with lower batch size - higher iteration time and then increase it once we disable random warp.<br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">34. Q:&nbsp;How to use pretrained model?</span><br>
</span></span><br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">A: Simply download it and put all the files directly into your model folder.</span></span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color">Start training, press any key within 2 seconds after selecting model for training (if you have more in the folder) and device to train with (GPU/CPU) to override model settings and make sure the pretrain option is disabled so that you start proper training, if you leave pretrain options enabled the model will carry on with pretraining. Note that the model will revert iteration count to 0, that's normal behavior for pretrained model, unlike a model that was just trained on random faces without the use of pretrain function.</span><br>
<br>
<span style="color: #a9afbc;" class="mycode_color">35. Q: My GPU usage is very low/GPU isn't being used despite selecting GPU for training/merging.<br>
<br>
A: It probably is being used but Windows doesn't report just CUDA usage (which is what you should be looking at) but total GPU usage which may be lower (around 5-10%).<br>
<br>
To see true CUDA/GPU usage during training (in Windows 10), go into Task Manager -&gt; Performance -&gt; Select GPU -&gt; Change one of the 4 smaller graphs to CUD.</span><br>
<br>
If you are using different version of Windows - download external monitoring software such as HWmonitor or GPU-Z or look at the VRAM usage which should be close to maximum during training.<br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">35. Q: Training freezes on RTX 3090, RTX cards training crashing, model not training with AdaBelief, model stops training after 12.16 16.12 update.</span><br>
</span></span><br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">A: Make sure to enable hardware accelerate GPU scheduling in Windows 10</span></span><br>
<br>
You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">36. Q: How to train with AdaBelief enabled?</span><br>
</span></span><br>
<span style="color: #a9afbc;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">A: Same as you would&nbsp;do without it enabled except without using learning rate dropout which is not needed with AB enabled.</span></span><br>
<br>
Whether you're starting to pretrain a new model, starting training on a pretrained model or want to carry on training with old model but use AdaBelief to improve quality of your fakes enable it and&nbsp;remember to never turn it off once it's enabled.<br>
<br>
Don't use LRD, this option should disable itself but just to be sure run your model once, disable LRD, save and then start it again, select Y to enable AdaBelief optimizer and pretrain or train&nbsp;as usual.<br>
<br>
There is no&nbsp;need to enable LRD before GAN, once you've disabled RW and are ready to start GAN simply enable it, no need to run LRD and wait&nbsp;for the model to reach lower loss, AB will ensure the model trains more accurately and naturally reaches lower loss values.<br>
<br>
If it's a pretrained model or one that was heavily trained before and you want to use it with AB make sure to enable it and RW, let the model relearn everything, if you instead just enable AB and carry on with RW disabled or some other options enabled it may not improve or it will get worse.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="font-size: large;" class="mycode_size"><span style="color: #ff3333;" class="mycode_color">XSeg FAQ</span><br>
<br>
</span></span><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">1.Q: Can XSeg models be reused?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: Yes.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">2.Q: Can XSeg be trained on variety of different faces to work like FANSeg.</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: Yes.</span><br>
<br>
XSeg models can be trained on dataset of random faces which will make it act like FANSeg, which means there won't be a need to further train XSeg on new datasets before applying masks to them or using it in the merger. However for best results it's best to refine your model by adding couple faces it has trouble with, to do so use the refinement technique described in the guide (applying masks, checking,&nbsp;fixing bad masks, retraining, re applying, checking again).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">3.Q: Is there a limit to diversity and/or amount of marked/masked faces that we feed into XSeg training?</span></span><br>
<br>
<span style="font-weight: bold;" class="mycode_b">A: No, you can mask as many faces as you want however at some point there may be too many faces for XSeg to learn therefor I suggest keeping your training set (SRC and DST counted together) under 10k faces with 5k faces dataset trained XSeg models to be performing really good as a general "pretrained" model.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">4.Q: What should I train first? Regular model or XSeg model?</span><br>
</span><br>
<span style="font-weight: bold;" class="mycode_b">A: It depends if you want to do WF/HEAD SAEHD model training/face swap and whether you're planning on using Style Power during training with those 2 face types.</span><br>
<br>
If you do, you need to first train your XSeg model and once it's trained apply it your datasets (both SRC and DST) by using&nbsp;5.XSeg.optional) trained mask for data_dst - apply and&nbsp;5.XSeg.optional) trained mask for data_src&nbsp;- apply.<br>
If you don't plan on using style powers you can train SAEHD model&nbsp;first and then the XSeg one or the other way around, it doesn't matter.<br>
Reason for training XSeg model&nbsp;first and applying it to your datasets&nbsp;is to replace the default full face&nbsp;masks generated from landmarks during dataset extraction, style powers need correct mask to be able to distinguish between face and the background, since default masks are full face they will limit trained area of whole face and head face_type models and will also prevent style powers from working correctly, that's why it's required to have XSeg applied before training those face_types.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">5.Q: Is XSeg available for Quick96 model too?</span><br>
</span><br>
<span style="font-weight: bold;" class="mycode_b">A: No, it's only for SAEHD model.<br>
</span><br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">6.Q: XSeg doesn't let me change face type on startup/I'm receiving some&nbsp;errors when starting training.</span><br>
</span><br>
<span style="font-weight: bold;" class="mycode_b">A: Make sure you are running newest version of DeepFaceLab, if not, get newest one or if you do, check for reported bugs on github or on the forum by using search feature and make sure you're doing everything correctly (location of marked faces and model files, batch size, your OS/drivers/GPU is fine, etc).</span><br>
<br>
If you can't find any mention of your issue/error, make a new thread in the questions section:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.&nbsp;or report it on the DFL 2.0 Github page after testing it's&nbsp;repeatability, restarting your PC will often fix some issues so do that before you report something.<br>
<br>
If you get OOM errors - lower your batch size.<br>
<br>
If you get errors about missing faces for training make sure your marked faces are in the "aligned" folder.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">7.Q: Does XSeg model/model files have to be in the same folder as regular model/model files?</span><br>
</span><br>
<span style="font-weight: bold;" class="mycode_b">A: Yes, XSeg model files are created in the same model file as regular model files, they have XSeg in the name so they are easy to distinguish from regular model files.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">8.Q: After running XSeg labeling tool I see UI but no frames.</span><br>
</span><br>
<span style="font-weight: bold;" class="mycode_b">A: Make sure your faceset isn't packed into .pak file, if it is&nbsp;unpack it using&nbsp;4.2) data_src(dst) util faceset unpack.</span><br>
<br>
Also if you will be creating your own pretrain dataset for SAEHD model and it is for WF or even FF model pretraining it's good to apply XSeg to it so that even during pretrain you're training everything you want your model to learn. After you apply your XSeg to it you can use the pack .bat to turn it into a file you can then place into your "CelebA" folder and replace default pretrain dataset (see the main DFL 2.0 guide and model sharing guide for more info on how to prepare your own pretraining dataset for SAEHD model training).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">9.Q: Is XSeg just for whole face or also for head face type?</span><br>
</span><br>
<span style="font-weight: bold;" class="mycode_b">A: XSeg works with all face types, including full face, whole face and head face_types.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">10.Q: What's the difference between 3 polygon color schemes in the XSeg labeling/marking/masking tool?</span><br>
</span><br>
<span style="font-weight: bold;" class="mycode_b">A: There is no difference between them, there are 3 options so that you can use one that suits you the most by being the most&nbsp;visible&nbsp;on the face you're labeling.<br>
<br>
<span style="color: #ff6633;" class="mycode_color">11.Q: What to do if I want obstructions visible over the face</span><br>
<br>
A: Mark the face area you want to be visible and then use poly exclude mode and label&nbsp;the obstruction by going around it, try to do it as accurately as you can and mark it on several faces.</span><br>
<br>
Doing it on just one face (even if the shape doesn't change nor does face angle/expression/lighting) may not be enough for the model to learn it correctly, if the obstruction moves across the face mark it where it's in the middle of the face and then 1-2 faces where it enters and exits the face/head area. If the obstructions stays in the same place but face changes (lighting, angle or expression) you also should mark it few times on different faces.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">12.Q: Can you add XSeg to an already existing model (that used FANSeg)?</span><br>
</span><br>
<span style="font-weight: bold;" class="mycode_b">A: Yes you can, model files and FANSeg/XSeg are separate so you can use old trained models and improve fakes made with them by masking them using XSeg in the merger or by training them with applied XSeg masks.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">13.Q: How to make inside of the mouth, tongue or eyes&nbsp;be of the DST face instead of SRC one?</span><br>
<br>
A: Use exclude poly mode and mark&nbsp;those areas on several faces (those on which you've already marked face/head area).<br>
<br>
<span style="color: #ff6633;" class="mycode_color">14.Q: Can you train XSeg model for full face type model using whole face extracted dataset that has been marked&nbsp;as a whole face (from chin up to hairline)?</span><br>
<br>
A: Yes you can, regular models with smaller area coverage face type&nbsp;can be trained on bigger area coverage face type datasets like whole face and head and so can XSeg.</span><br>
<br>
The full face type&nbsp;XSeg&nbsp;training will trim the masks to the the biggest area possible by full face (that's about half of the forehead although depending on the face angle the coverage might be even bigger and&nbsp;closer to WF, in other cases face might be cut off oat the bottom, in particular chin when mouth is wide open will often get cut off with full face).<br>
<br>
Doing it the other way (training whole face XSeg model on full face extracted and marked/masked faces) will result in issues and incorrectly learned masks. The best way is to have WF datasets, mark them as WF and also train an XSeg model as WF as it can be then used with pretty much all face types that are the same scale as it or smaller (so it will also work with full face and possibly even mid-half and half face although the latter two are no longer recommended as they don't cover enough of the face for realistic face swap, full face and above are recommended).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">15.Q: I have holes in my masks despite not marking out anything in the middle.</span><br>
<br>
A: See the above, it might be that you are training XSeg model on face type that has higher coverage than your dataset is.</span><br>
<br>
Another issue is that you may just not have trained it enough, marked not enough faces or made it not carefully enough. In that case stop training, apply XSeg&nbsp;to the dataset faces from which look bad in the training&nbsp;preview, go back to the XSeg editor and mark&nbsp;some of these problematic faces, then resume training, if the issue doesn't disappear you may need to start training from scratch or mark even more faces.
		</div>
		
		<!-- start: postbit_signature -->
<div class="panel panel-primary">
<div class="signature scaleimages padding-8px">
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Open for commissions</span>, if you want a custom deepfake made,&nbsp;send me a private message.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="color: #ffcc33;" class="mycode_color">Want to learn DFL and guides aren't enough? I offer DeepFaceLab courses, message me for details.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Also consider donation&nbsp;towards running our website!</span></span></div>

</div>
</div>
<!-- end: postbit_signature -->
		<div class="post_meta" id="post_meta_16814">
                        
                        <div style="" id="tyl_16814"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(16814);return false;" title="[-]" id="tyl_a_expcol_16814"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_16814"></a> 
	<span id="tyl_title_16814" style=""><strong>The following 3 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post:</strong></span><span id="tyl_title_collapsed_16814" style="display: none;"><strong>3 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post</strong></span><br>
	<span id="tyl_data_16814" style="">&nbsp;&nbsp;• <span class="smalltext"></span><a href="https://mrdeepfakes.com/forums/user-clovis-brithgtex" class="tt smalltext" title="03-27-2020">clovis-brithgtex</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-lx68z" class="tt smalltext" title="04-18-2020">lx68z</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-slyfaker99" class="tt smalltext" title="03-28-2020">slyfaker99</a></span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=24245" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=16814" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_16814_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_16814">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=16814" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_16814").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit --><!-- start: postbit -->

<a name="pid18459" id="pid18459"></a>
<div class="post " style="" id="post_18459">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-tuts"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_24245.jpg" alt="" width="55" height="55"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				Moderator<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat3">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat3">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=18459#pid18459" title="RE: [GUIDE] - DeepFaceLab 2.0 EXPLAINED AND TUTORIALS (recommended)">#4</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">04-03-2020, 03:03 AM <span class="post_edit" id="edited_by_18459"><!-- start: postbit_editedby -->
<span class="edited_post">(This post was last modified: 01-11-2021, 12:36 AM by <a href="https://mrdeepfakes.com/forums/user-tuts">Tuts</a>.)</span>
<!-- end: postbit_editedby --></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_18459">
			<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">DATASET/FACESET GUIDE - EXTRA INFO.</span></span></span><br>
<br>
<span style="color: #ff9933;" class="mycode_color">NOTE FOR USERS WHO ARE UNABLE TO USE DFL OR ANY OTHER FACE SWAP SOFTWARE!</span><br>
You can still make a dataset by just collecting good quality photos and videos and then extracting just the frames from video, it will produce higher size zip file to upload but is still more helpful for creators than nothing, you can extract frames from videos by using the same software DFL uses - FFMPEG or any video editing software.<br>
<br>
<blockquote class="mycode_quote"><cite>Quote:</cite>FFMPEG:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</blockquote>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ffcc33;" class="mycode_color">You can then upload those extracted frames or just edited clips from movies and other sources (photos too) in this thread:</span></span><br>
You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Before you start here is some terminology:</span><br>
<br>
- data_src, src, source, celebrity faceset, celebrity dataset, source dataset, source images - images of the celebrity that are used in training the AI model.<br>
- frame,frames - self explanatory, just individual frames extracted from video, located inside workspace/data_src.<br>
- faces - aligned pictures of faces, located inside workspace/data_src/aligned<br>
<br>
To create a source faceset you will need software that is used to create deepfakes, this guide focuses on using DFL 2.0:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.<br>
<div style="text-align: left;" class="mycode_align">Download links:&nbsp;You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</div>
After downloading it just unpack it and you are pretty much ready to go.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color"><span style="font-size: medium;" class="mycode_size">General guidelines on types of faces to have in your source dataset for optimal results.</span></span></span><br>
<br>
To create a good quality source dataset you'll need to find source material of your subject, that can be photos or videos, videos are preferred due to variety of expressions and angles that are needed to cover all possible appearances of face so that model can learn it correctly. You can also combine videos and photos. Below are some things that you need to ensure so that your source dataset is as good as it can be.<br>
<br>
<span style="color: #ffcc33;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">1.</span>&nbsp;<span style="font-weight: bold;" class="mycode_b">Videos/photos should cover all or at least most of possible face/head angles</span></span>&nbsp;- looking up, down, left, right, straight at camera and everything in between, the best way to achieve it is to use more than one interview or grab clips from movies instead of relying on single interview (which will mostly feature one angle and some small variations).<br>
<br>
<span style="color: #ff6633;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">TIP&nbsp;#1:</span>&nbsp;</span>If DST does not contain certain angles (like&nbsp;side face profiles) there is no need to include them in SRC, for those cases such angles can be temporarily removed from source faceset/dataset but it's good to always prepare source datasets in such a way that they can work with DST that contains all the angles/expressions. Basically don't half-ass making of them, get all angles you can, if needed remove for training but never delete them.<br>
<br>
<span style="color: #33cc33;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">2. V</span><span style="font-weight: bold;" class="mycode_b">ideos/photos should cover all different facial expressions</span></span>&nbsp;- that includes open/closed mouths, open/closed eyes, smiles, frowns, eyes looking in different directions - the more variety in expressions you can get the better results will be.<br>
<br>
<span style="color: #ff6633;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">TIP #2:</span>&nbsp;</span>To achieve less morphing of result face&nbsp;(in other words have it look more like SRC) it's best to try and achieve maximum variety using less different sources. Good practice is to separate sources when making your dataset, you can do it in variety of ways but the thing that matters is to name frames correctly before running extraction, say you have scenes of Tom Cruise from 2 movies, name frames for one to refer to that movie and the other one to other movie, example:&nbsp;TomCruiseTopGun and TomCruiseMissionImpossible<br>
<br>
The more different sources are used the higher chance is that result face will look less like our source and model will require use of true face or longer training.<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Examples:</span><br>
#1&nbsp;1000 faces, 3 different angles from&nbsp;1 source&nbsp;- result face&nbsp;will look most SRC like.<br>
#2&nbsp;1000 faces, 3 different angles from&nbsp;3 sources (each source for different angle with slight overlapping) - slightly worse resemblance to SRC.<br>
#3&nbsp;1000 faces, 3 different angles from&nbsp;3 sources (same angles visible in all 3 sources, all faces overlap and overall look similar) - worst resemblance to SRC.<br>
<br>
To combat this you can use sort by best (faster) which will target the specified number of face you enter before sorting and attempt to keep even amount of faces for all angles however there is no real tool to fix datasets and still keep all the unique faces, this sorting doesn't check for expressions, only pitch/yaw and histogram similarity so some may get removed. All unwated faces will get moved after this sorting is done to a new folder created in your "data_src" folder called "aligned_trash".<br>
<br>
On the other hand it's good to have several lighting conditions for each angle (like soft/diffuse lighting and 2 different ones, also soft coming from left and right, shots with direct&nbsp;lighting (sunlight, non diffused lights)&nbsp;and hard edge shadows should not be included) so it might be necessary to keep faces from similar angles from more than 3 sources but if your dataset has 10 different sources of similarly looking faces remove most of them and only keep those that differ the most in terms of lighting conditions and have the best quality/sharpness (and cover all the other requirements).<br>
<br>
<span style="color: #3399ff;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">3.</span>&nbsp;<span style="font-weight: bold;" class="mycode_b">Materials need to be consistent</span></span>&nbsp;- you don't want blurry, low resolution and compressed faces next to crisp, sharp and high quality ones so you should only use the best quality materials you can find, if however you can't or certain angles/expressions are present only in lower quality/blurry video/photo then you should keep it. Some blurry faces can be beneficial to better generalize face in the early stages of training. This also applies to features of the face, for male facesets you don't want to mix faces with and without a beard, similarly for female facesets you don't want to mix faces with different makeups.<br>
<br>
<span style="color: #ff6633;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">TIP #3:</span>&nbsp;</span>Fixing female datasets with varying makeups doesn't need to be performed if&nbsp;the only differences are slight shades of lips or eye shadows/other forms of makeup, in those cases&nbsp;it's fine to leave them in your source dataset, but if you have faces with no lipstick and light eye shadows next to faces with dark red lipstick and dark green/blue eye shadows then you either want to remove the more extreme ones or color correct them in your photo or video editing software, you can de-saturate colors, apply selective color correction, apply sepia filter at 40-80% strength&nbsp;or apply color matching to different faces with less makeup. You can edit faces in your source set without the need to re-extract them by using save/restore metadata function of DFL (you can read more about it in the main guide).<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #66cc33;" class="mycode_color">4. Most of it should be high quality</span></span>&nbsp;- as mentioned above, you can leave use some blurry photos/videos but only when you can't find certain expressions/face angles in others. No more than 1-5% of the dataset should be blurry.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff66ff;" class="mycode_color">5.&nbsp;Lighting should be consistent</span></span>&nbsp;- some small shadows are OK but you shouldn't include interviews with harsh, directional lighting, if possible try to use only those where shadows are soft and&nbsp;light is diffused. For LIAE architectures it may not be as important as it can handle lighting better&nbsp;but for DF architectures it's important to have several lighting conditions for each face angle, preferably at least 3 (frontal diffuse, left and right soft shadows). Source faceset/dataset&nbsp;can contain faces of varying brightness but overly bright or dark faces should not be included.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #6699ff;" class="mycode_color">6. If you are using only pictures or they are a majority of the dataset</span></span>&nbsp;- make sure they fill all the checks as mentioned above, 20 or so pictures is not enough. Don't even bother trying to make anything with so little pictures.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9999;" class="mycode_color">7. Keep the total amount of faces in your source faceset/dataset under 10.000</span></span>&nbsp;- the benefits or disadvantages&nbsp;of using a really big (in excess of 15.000 - 20.000 faces) facesets/datasets have not be proven yet, technically as long as amount of faces from each source is at least 500-1000 and similar angles/expressions don't overlap too much issues mentioned in&nbsp;<span style="font-weight: bold;" class="mycode_b">2.&nbsp;</span>with morphing and result face not looking like SRC&nbsp;shouldn't occur but having such big faceset/dataset is&nbsp;going to make the training longer. The more clean and robust faceset you make the better results you will achieve.<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Now you know what kinds of faces should be in your source datasets, you know what videos and photos to choose and what to do once you extract them all which leads us to the next step - extraction of faces.</span><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">1. Extract individual frames from videos.</span></span><br>
<br>
Following instruction is for when you have a couple videos/interviews to extract, if you only have a single video and some pictures, skip to step&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">2. Align faces.</span></span><br>
If you have few videos that you don't mind being mixed (like interviews)&nbsp;it's best to combine them all using a video editing software like Vegas Pro/Resolve/AE/Premiere and render it out directly into images&nbsp;(in that case also&nbsp;skip to step&nbsp;<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff3333;" class="mycode_color">2. Align faces.</span></span>).<br>
<br>
Otherwise you'll have to&nbsp;extract frames from each one,&nbsp;one by one.<br>
To do so copy over first source video to "workspace" folder, rename it to data_src.mp4 and&nbsp;start extracting frames from it using&nbsp;<span style="font-weight: bold;" class="mycode_b">2) extract images from video data_src from data_src.</span><br>
After the process finishes extracting frames&nbsp;delete data_src.mp4 file from the "workspace" folder&nbsp;and go into "data_src" folder&nbsp;and rename all extracted frames depending on the name of celebrity and source of the video (TIP#2 on separating sources)&nbsp;by selecting all frames with Ctrl + A and renaming with F2. This also let's use later extract from another data_src.mp4 and not overwrite existing images in your "data_src" folder.&nbsp;Then&nbsp;copy over next source video, name it data_src, extract, select all files, ctrl + a, F2, rename, delete data_src, bring another one over and repeat until you finish all. If it seems like a lot of work then that's because it is a lot of work.<br>
<br>
<span style="color: #ff3333;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">2. Align faces.</span></span><br>
<br>
After you've extracted all frames&nbsp;from videos&nbsp;copy all your pictures (if you have any)&nbsp;into "data_src" folder (you can rename them too to something like CelebrityNamePhotos)&nbsp;and run face extraction/alignment process using&nbsp;<span style="font-weight: bold;" class="mycode_b">4) data_src faceset extract.</span><br>
<br>
After you run this .bat you will have to select face type, resolution, maximum amount of faces to be extracted per frame, jpeg image quality and whether you want aligned_debug to be generated.<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Face_type:</span>&nbsp;you should choose the type you will run your model at however you can without any issues run higher face_type dataset with lower face_type model,&nbsp;but there are exceptions.<br>
I recommend to extract faces as WF regardless if you plan on training a WF or FF model, if you do HF still you may want to extract as FF or HF&nbsp;but most people don't use HF anymore so stick with WF for WF and FF models and for HEAD models do HEAD extraction.<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Resolution:</span>&nbsp;can be (and should be) higher than your planned model resolution so that you can always use this model in the future when you change your model to higher resolution one or just to "future proof" your datasets. I recommend following values, for WF:<br>
720p or lower resolution&nbsp;sources - 512-768<br>
1080p sources - 768-1024<br>
4K sources - 1024-2048<br>
For HEAD extraction, add extra 256-512 with 720p or 1080p source just to be sure you aren't missing any details of the extracted faces.<br>
<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Maximum amount of faces:</span>&nbsp;leave this at 0 so that it extracts all faces, if you choose 1 and there are 2 faces on a frame it may extract not the faces you want.<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Quality:</span>&nbsp;default is 90 and in most cases it's enough, 100 will produce unnecessarily large sized files so if you want better quality use 94-96.<br>
<br>
<span style="font-weight: bold;" class="mycode_b">Generate aligned_debug:</span>&nbsp;as the name suggest it will create a folder aligned_debug just like when extracting face for data_dst dataset. If you want to make sure all faces are perfectly extracted and want to check alignments on them you should enable it.<br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">After extraction finishes it will&nbsp;create a new folder "aligned" inside "data_src" folder&nbsp;with aligned/extracted faces from&nbsp;photos and video frames you've extracted in step 1.</span></span><br>
<br>
This process is not perfect and requires manual cleanup. This is a process where you go through all the aligned faces and delete all blurry, to dark and to bright faces as well as ones that don't belong to the celebrity of which you are making faceset (script will detect&nbsp;<span style="font-weight: bold;" class="mycode_b">ALL FACES</span>&nbsp;from your extracted frames/photos) or ones that were incorrectly aligned (rotated upside down, etc).<br>
<br>
To help you in this DFL comes with a sorting process that contains a wide range of sorting methods:<br>
<br>
[0] blur - sorts by image blurriness (determined by contrast). Slow.<br>
[1] face yaw direction - sorts by yaw (from faces looking to left to looking right).<br>
[2] face pitch direction - sorts&nbsp;by pitch (from faces looking up to looking down).<br>
[3] face rect size in source image - sorts by size of the face on the original frame (from biggest to smallest faces). Much faster than blur.<br>
[4] histogram similarity - sort by histogram similarity, dissimilar faces at the end, useful for removing drastically different looking faces, also groups them together.<br>
[5] histogram dissimilarity - as above but dissimilar faces are on the beginning.<br>
[6] brightness - sorts by overall image/face brightness.<br>
[7] hue - sorts by hue.<br>
[8] amount of black pixels - sorts by amount of completely black pixels (such as when face is cut off from frame and only partially visible).<br>
[9] original filename - sorts by original filename (of the frames from which faces were extracted).<br>
[10] one face in image - sorts faces in order of how many faces were in the original frame.<br>
[11] absolute pixel difference - sorts by absolute difference in how image works, useful&nbsp;to remove drastically different looking faces.<br>
[12] best faces - sorts by several factors including blur and removes duplicates/similar faces, has a target of how many faces we want to have after sorting, discard faces are moved to folder&nbsp;"aligned_trash".<br>
[13] best faces faster - similar to best faces but uses&nbsp;face rect size in source image instead blur to determine quality of faces, much faster than best faces.<br>
<br>
Here is a look at an example source dataset before cleanup with faces color coded according to what you should do with them.<br>
<br>
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/UAtctbK.png" width="1280" height="720" alt="[Image: UAtctbK.png]" class="mycode_img"><br>
<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Green</span>&nbsp;</span>- good faces/alignments.<br>
<span style="color: #ff3333;" class="mycode_color"><span style="font-weight: bold;" class="mycode_b">Red</span></span>&nbsp;- misaligned, you can see they are rotated slightly, you definitely don't want these in your dataset, you can either delete them or try to manually extract them.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #3333ff;" class="mycode_color">Blue</span></span>&nbsp;- obstructions/overlays/text over face - can be left if it's only a small obstruction on few faces in the whole dataset.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #cccc33;" class="mycode_color">Yellow</span></span>&nbsp;- blurry faces, should be removed unless it's a unique angle/expression, small amount may help to generalize face but you definitely don't want to many of these either (similar to obstructions, best to keep under 5%).<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #9966ff;" class="mycode_color">Violet</span></span>&nbsp;- faces of other people, obviously those must be removed.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff99cc;" class="mycode_color">Pink</span></span>&nbsp;- cut off faces, they can be left if it's only a bit of chin or forehead or it doesn't go over the face, assuming it's only few faces in the entire dataset&nbsp;or if it has unique angle/expression.<br>
<span style="font-weight: bold;" class="mycode_b"><span style="color: #ff6633;" class="mycode_color">Orange</span></span>&nbsp;- to dark/bright/overexposed/low contrast faces - also any pictures with strong photo/instagram filters, etc, in general they should be removed but you may want to try and go back to extracted frames, edit them (increase/decrease brightness/contrast/saturation) and extract again to be able to keep them, if they are only slightly different than the rest they can be left in, assuming you use color transfer during training to average them all out to others and DST.<br>
<br>
After you clean it all up you should revert it all back to the original order using<span style="font-weight: bold;" class="mycode_b">&nbsp;4.2) data_src util recover original filename</span>&nbsp;(assuming you did name various sources differently before extraction) and then place each source into a separate folder. If you didn't separate sources then after you clean it up you can skip the recovery of original order, you can then use such dataset for your deepfake or zip it and upload to google drive or mega and share on the forum.<br>
<br>
You can also use&nbsp;<span style="font-weight: bold;" class="mycode_b">5.2) data_src util faceset pack</span>&nbsp;and then later&nbsp;<span style="font-weight: bold;" class="mycode_b">5.2) data_src&nbsp;util faceset unpack</span>&nbsp;to quickly pack/unpack the whole source dataset into a single file which makes it easier to share and DFL can also load it up faster.
		</div>
		
		<!-- start: postbit_signature -->
<div class="panel panel-primary">
<div class="signature scaleimages padding-8px">
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Open for commissions</span>, if you want a custom deepfake made,&nbsp;send me a private message.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="color: #ffcc33;" class="mycode_color">Want to learn DFL and guides aren't enough? I offer DeepFaceLab courses, message me for details.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Also consider donation&nbsp;towards running our website!</span></span></div>

</div>
</div>
<!-- end: postbit_signature -->
		<div class="post_meta" id="post_meta_18459">
                        
                        <div style="" id="tyl_18459"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(18459);return false;" title="[-]" id="tyl_a_expcol_18459"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_18459"></a> 
	<span id="tyl_title_18459" style=""><strong>The following 2 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post:</strong></span><span id="tyl_title_collapsed_18459" style="display: none;"><strong>2 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post</strong></span><br>
	<span id="tyl_data_18459" style="">&nbsp;&nbsp;• <span class="smalltext"></span><a href="https://mrdeepfakes.com/forums/user-docjrabg" class="tt smalltext" title="01-13-2021">docjrabg</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-eiriyan" class="tt smalltext" title="05-02-2020">eiriyan</a></span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=24245" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=18459" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_18459_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_18459">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=18459" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_18459").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit --><!-- start: postbit -->

<a name="pid18964" id="pid18964"></a>
<div class="post " style="" id="post_18964">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-tuts"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_24245.jpg" alt="" width="55" height="55"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				Moderator<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat4">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat4">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=18964#pid18964" title="RE: [GUIDE] - DeepFaceLab 2.0 EXPLAINED AND TUTORIALS (recommended)">#5</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">04-13-2020, 01:47 PM <span class="post_edit" id="edited_by_18964"><!-- start: postbit_editedby -->
<span class="edited_post">(This post was last modified: 10-08-2020, 06:35 AM by <a href="https://mrdeepfakes.com/forums/user-tuts">Tuts</a>.)</span>
<!-- end: postbit_editedby --></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_18964">
			<span style="color: #ff3333;" class="mycode_color"><span style="font-size: medium;" class="mycode_size"><span style="font-weight: bold;" class="mycode_b">- reserved for future use -</span></span></span>
		</div>
		
		<!-- start: postbit_signature -->
<div class="panel panel-primary">
<div class="signature scaleimages padding-8px">
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Open for commissions</span>, if you want a custom deepfake made,&nbsp;send me a private message.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="color: #ffcc33;" class="mycode_color">Want to learn DFL and guides aren't enough? I offer DeepFaceLab courses, message me for details.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Also consider donation&nbsp;towards running our website!</span></span></div>

</div>
</div>
<!-- end: postbit_signature -->
		<div class="post_meta" id="post_meta_18964">
                        
                        <div style="" id="tyl_18964"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(18964);return false;" title="[-]" id="tyl_a_expcol_18964"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_18964"></a> 
	<span id="tyl_title_18964" style=""><strong>The following 2 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post:</strong></span><span id="tyl_title_collapsed_18964" style="display: none;"><strong>2 users Like <a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a>'s post</strong></span><br>
	<span id="tyl_data_18964" style="">&nbsp;&nbsp;• <span class="smalltext"></span><a href="https://mrdeepfakes.com/forums/user-mandark321" class="tt smalltext" title="01-17-2021">mandark321</a><span class="smalltext">, </span><a href="https://mrdeepfakes.com/forums/user-tomoctocat-gmail-com" class="tt smalltext" title="01-08-2021">tomoctocat@gmail.com</a></span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=24245" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=18964" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_18964_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_18964">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=18964" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_18964").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit --><!-- start: postbit -->

<a name="pid18976" id="pid18976"></a>
<div class="post " style="" id="post_18976">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-iperov"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_4808.jpg" alt="" width="55" height="55"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-iperov"><span style="color: #9ec6e0;"><strong>iperov</strong></span></a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				DeepFaceLab Developer<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				<!-- start: postbit_groupimage -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/developer-mdf.png" alt="Developers" title="Developers" style="height: 25px;">
<!-- end: postbit_groupimage -->
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 316<br>
	Threads: 9<br>
	Likes Received: 182 in 91 posts
<br>
Likes Given: 12<br>

	Joined: Oct 2018
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat5">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat5">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 316<br>
	Threads: 9<br>
	Likes Received: 182 in 91 posts
<br>
Likes Given: 12<br>

	Joined: Oct 2018
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=18976#pid18976" title="RE: [GUIDE] - DeepFaceLab 2.0 EXPLAINED AND TUTORIALS (recommended)">#6</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">04-13-2020, 07:46 PM <span class="post_edit" id="edited_by_18976"><!-- start: postbit_editedby -->
<span class="edited_post">(This post was last modified: 10-08-2020, 06:37 AM by <a href="https://mrdeepfakes.com/forums/user-tuts">Tuts</a>.)</span>
<!-- end: postbit_editedby --></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_18976">
			<div style="text-align: left;" class="mycode_align">My advices, translated using deepl.com</div>
<br>
<div style="text-align: left;" class="mycode_align">SAEHD model options.</div>
<br>
<div style="text-align: left;" class="mycode_align">Random_flip</div>
<div style="text-align: left;" class="mycode_align">Turn the image from left to right by random rotation. Allows for better generalization of faces. Slows down training slightly until a clear face is achieved. If both src and dst face sets are quite diverse, this option is not useful. You can turn it off after a workout.</div>
<br>
<div style="text-align: left;" class="mycode_align">Batch_size</div>
<div style="text-align: left;" class="mycode_align">Improves facial generalization, especially useful at an early stage. But it increases the time until a clear face is achieved. Increases memory usage. In terms of quality of the final fairy, the higher the value, the better. It's not worth putting it below 4.</div>
<br>
<div style="text-align: left;" class="mycode_align">Resolution.</div>
<div style="text-align: left;" class="mycode_align">At first glance, the more the better. However, if the face in the frame is small, there is no point in choosing a large resolution. By increasing the resolution, the training time increases. For face_type=wf, more resolution is required, because the coverage of the face is larger, thus the details of the face are reduced. For wf it makes no sense to choose less than 224.</div>
<br>
<div style="text-align: left;" class="mycode_align">Face_type.</div>
<div style="text-align: left;" class="mycode_align">Face coverage in training. The more facial area is covered, the more plausible the result will be.</div>
<div style="text-align: left;" class="mycode_align">The whole_face allows covering the area below the chin and forehead. However, there is no automatic removal of the mask with the forehead, so XSeg is required for the merge, either in Davinci Resolve or Adobe After Effects.</div>
<br>
<div style="text-align: left;" class="mycode_align">Archi.</div>
<div style="text-align: left;" class="mycode_align">Liae&nbsp;makes more morph under dst face, but src face in it will still be recognized.</div>
<div style="text-align: left;" class="mycode_align">Df&nbsp;allows you to make the most believable face, but requires more manual work to collect a good variety of src facets and a final color matching.</div>
<div style="text-align: left;" class="mycode_align">The effectiveness of&nbsp;hd&nbsp;architectures has not been proven at this time. The&nbsp;Hd&nbsp;architectures were designed to better smooth the subpixel transition of the face at micro displacements, but the micro shake is also eliminated at df, see below.</div>
<br>
<div style="text-align: left;" class="mycode_align">Ae_dims.</div>
<div style="text-align: left;" class="mycode_align">Dimensions&nbsp;of the main brain of the network, which is responsible for generating facial expressions created in the encoder and for supplying a variety of code to the decoder.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">E_dims.</div>
<div style="text-align: left;" class="mycode_align">The dimensions of the encoder network that are responsible for face detection and further recognition. When these dimensions are not enough, and the facial chips are too diverse, then we have to sacrifice non-standard cases, those that are as much as possible different from the general cases, thus reducing their quality.</div>
<br>
<div style="text-align: left;" class="mycode_align">D_dims.</div>
<div style="text-align: left;" class="mycode_align">The network dimensions of the decoder, which are responsible for generating the image from the code obtained from the&nbsp;brain of the network. When these dimensions are not enough, and the weekend faces are too different in color, lighting, etc., you have to sacrifice the maximum allowed sharpness.</div>
<br>
<div style="text-align: left;" class="mycode_align">D_mask_dims.</div>
<div style="text-align: left;" class="mycode_align">Dimensions of the mask decoder network, which are responsible for forming the mask image.&nbsp;</div>
<div style="text-align: left;" class="mycode_align">16-22 is the normal value for a fake without an edited mask in XSeg editor.</div>
<br>
<div style="text-align: left;" class="mycode_align">At the moment there is no experimentally proven data that would indicate which values are better. All we know is that if you put really low values, the error curve will reach the plateau quickly enough and the face will not reach clarity.</div>
<br>
<div style="text-align: left;" class="mycode_align">Masked_training. (only&nbsp;for&nbsp;whole_face).</div>
<div style="text-align: left;" class="mycode_align">Enabled (default) - trains only the area inside the face mask, and anything outside that area is ignored. Allows the net to focus on the face only, thus speeding up facial training and facial expressions.&nbsp;</div>
<div style="text-align: left;" class="mycode_align">When the face is sufficiently trained, you can disable this option, then everything outside the face - the forehead, part of the hair, background - will be trained.</div>
<br>
<div style="text-align: left;" class="mycode_align">Eyes_prio.</div>
<div style="text-align: left;" class="mycode_align">Set a higher priority for image reconstruction in the eye area. Thus improving the generalization and comparison of the eyes of two faces. Increases iteration time.</div>
<br>
<div style="text-align: left;" class="mycode_align">Lr_dropout.</div>
<div style="text-align: left;" class="mycode_align">Include only when the face is already sufficiently trained. Enhance facial detail and improve subpixel facial transitions to reduce shake.</div>
<div style="text-align: left;" class="mycode_align">Spends more video memory. So when selecting a network configuration for your graphics card, consider enabling this option.</div>
<br>
<div style="text-align: left;" class="mycode_align">Random_warp.</div>
<div style="text-align: left;" class="mycode_align">Turn it off only when your face is already sufficiently trained. Allows you to improve facial detail and subpixel transitions of facial features, reducing shake.</div>
<br>
<div style="text-align: left;" class="mycode_align">GAN_power.&nbsp;</div>
<div style="text-align: left;" class="mycode_align">Allows for improved facial detail. Include only when the face is already sufficiently trained. Requires more memory, greatly increases iteration time. &nbsp;</div>
<div style="text-align: left;" class="mycode_align">The work is based on the generative and adversarial principle. At first, you will see artifacts in areas that do not match the clarity of the target image, such as teeth, eye edges, etc. So train long enough.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">True_face_power.</div>
<div style="text-align: left;" class="mycode_align">Experimental option. You don't have to turn it on. Adjusts the predicted face to src in the most "hard way". Artifacts and incorrect light transfer from dst may appear.</div>
<br>
<div style="text-align: left;" class="mycode_align">Face_style_power.</div>
<br>
<div style="text-align: left;" class="mycode_align">Adjusts the color distribution of the predicted face in the area inside the mask to dst. Artefacts may appear. The face may become more like dst. The model may collapse.</div>
<div style="text-align: left;" class="mycode_align">Start at 0.0001 and watch the changes in preview_history, turn on the backup every hour.</div>
<br>
<div style="text-align: left;" class="mycode_align">Bg_style_power.</div>
<br>
<div style="text-align: left;" class="mycode_align">Trains the area in the predicted face outside the face mask to be equal to the same area in the dst face. In this way the predicted face is similar to the morph in dst face with already less recognizable facial src features.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">The&nbsp;Face_style_power and&nbsp;Bg_style_power&nbsp;must work in pairs to make the complexion fit to dst and the background take from dst. Morph allows you to get rid of many problems with color and face matching, but at the expense of recognition in it src face.</div>
<br>
<div style="text-align: left;" class="mycode_align">ct_mode.</div>
<br>
<div style="text-align: left;" class="mycode_align">It is used to fit the average color distribution of a face set src to dst. Unlike&nbsp;Face_style_power&nbsp;is a safer way, but not the fact that you get an identical color transfer. Try each one, look at the preview history which one is closer to dst and train on it.</div>
<br>
<div style="text-align: left;" class="mycode_align">Clipgrad.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">It reduces the chance of a model collapse to almost zero. Model collapse occurs when artifacts appear or when the windows of the predicted faces are colored in the same color. Model collapse can occur when using some options or when there is not enough variety of face sets dst.</div>
<div style="text-align: left;" class="mycode_align">Therefore, it is best to use autobackup every 2-4 hours, and if collapse occurs, roll back and turn on&nbsp;clipgrad.&nbsp;.</div>
<br>
<div style="text-align: left;" class="mycode_align">Pretrain.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">Engage model pre-training. Performed by 24 thousand people prepared in advance. Using the pre-trained model you accelerate the training of any fairy.&nbsp;</div>
<div style="text-align: left;" class="mycode_align">It is recommended to train as long as possible. 1-2 days is good. 2 weeks is perfect. At the end of the pre-training, save the model files for later use. Switch off the option and train as usual.</div>
<div style="text-align: left;" class="mycode_align">You can and should share your pre-trained model in the community.</div>
<br>
<div style="text-align: left;" class="mycode_align">Size of src and dst face set.</div>
<br>
<div style="text-align: left;" class="mycode_align">The problem with a large number of src images is repetitive faces, which will play little role. Therefore, faces with rare angles will train less frequently, which has a bad effect on quality. Therefore, 3000-4000 faces are optimal for src facial recruitment. If you have more than 5000 faces, sort by best into fewer faces. Sorting will select from the optimal ratio of angles and color variety.</div>
<br>
<div style="text-align: left;" class="mycode_align">The same logic is true for dst. But dst is footage from video, each of which must be well trained to be identified by the neural network when it is closer. So if you have too many faces in dst, from 3000 and more, it is optimal to make their backup, then sort by best in 3000, train the network to say 100.000 iterations, then return the original number of dst faces and train further until the optimal result is achieved.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">How to get lighting similar to dst face?</div>
<br>
<div style="text-align: left;" class="mycode_align">It's about lighting, not color matching. It's just about collecting a more diverse src set of faces.</div>
<br>
<br>
<div style="text-align: left;" class="mycode_align">How to suppress color flickering in&nbsp;DF&nbsp;model?&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">If the src set of faces contains a variety of make-up, it can lead to color shimmering DF model. Option: At the end of your training, leave at least 150 faces of the same makeup and train for several hours.</div>
<br>
<div style="text-align: left;" class="mycode_align">How else can you adjust the color of the predicted face to dst?</div>
<br>
<div style="text-align: left;" class="mycode_align">If nothing fits automatically, use the video editor and glue the faces in it. With the video editor, you get a lot more freedom to note colors.</div>
<br>
<div style="text-align: center;" class="mycode_align"><div style="text-align: left;" class="mycode_align">How to make a face look more like src?&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">1. Use DF architecture.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">2. Use a similar face shape in dst.</div>
<br>
<div style="text-align: left;" class="mycode_align"><div style="text-align: left;" class="mycode_align">3 It is known that a large color variety of facial src decreases facial resemblance, because a neural network essentially interpolates the face from what it has seen.</div>
<br>
<div style="text-align: left;" class="mycode_align">For example, in your src set of faces from 7 different color scenes, and the sum of faces is only 1500, so under each dst scene will be used 1500 / 7 faces, which is 7 times poorer than if you use 1500 faces of one scene. As a result, the predicted face will be very different from the src.&nbsp;</div>
<br>
</div>
<div style="text-align: left;" class="mycode_align">Microquake the predicted face in the end video.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">The higher the resolution of the model, the longer it needs to be trained to suppress the micro-shake.</div>
<div style="text-align: left;" class="mycode_align">You should also enable lr_dropout and disable random_warp after 200-300k iterations at batch_size 8.</div>
<div style="text-align: left;" class="mycode_align">It is not rare that the microshake can appear if the dst video is too clear. It is difficult for a neural network to distinguish unambiguous information about a face when it is overflowed with micro-pixel noise. Therefore, after extracting frames from dst video, before extracting faces, you can pass through the frames with the noise filter&nbsp;denoise data_dst images.bat.&nbsp;This filter will remove temporal noise.</div>
<div style="text-align: left;" class="mycode_align">Also, ae_dims magnification may suppress the microshock.</div>
<br>
<div style="text-align: left;" class="mycode_align">Use a quick model to check the generalization of facial features.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">If you're thinking of a higher resolution fake, start by running at least a few hours at resolution 96. This will help identify facial generalization problems and correct facial sets.&nbsp;</div>
<div style="text-align: left;" class="mycode_align">Examples of such problems:&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">1. Non-closing eyes/mouth - no closed eyes/mouth in src.</div>
<br>
<div style="text-align: left;" class="mycode_align">2. wrong face rotation - not enough faces with different turns in both src and dst face sets.</div>
</div>
<br>
<div style="text-align: left;" class="mycode_align">Training algorithm for achieving high definition.</div>
<div style="text-align: center;" class="mycode_align">
<div style="text-align: left;" class="mycode_align">1. use -ud model</div>
<div style="text-align: left;" class="mycode_align">2. train, say, up to 300k.</div>
<div style="text-align: left;" class="mycode_align">3. enable learning rate dropout for 100k&nbsp;</div>
<div style="text-align: left;" class="mycode_align">4. disable random warp for 50k.</div>
<div style="text-align: left;" class="mycode_align">5. enable gan</div>
</div>
<br>
<div style="text-align: left;" class="mycode_align">Do not use training GPU for video output.</div>
<br>
<div style="text-align: left;" class="mycode_align">This can reduce performance, reduce the amount of free GPU video memory, and in some cases lead to OOM errors.</div>
<div style="text-align: left;" class="mycode_align">Buy a second cheap video card such as GT 730 or a similar, use it for video output.</div>
<div style="text-align: left;" class="mycode_align">There is also an option to use the built-in GPU in Intel processors. To do this, activate it in BIOS, install drivers, connect the monitor to the motherboard.</div>
<br>
<div style="text-align: left;" class="mycode_align">Using Multi-GPU.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">Multi-GPU can improve the quality of the fake. In some cases, it can also accelerate training.&nbsp;</div>
<div style="text-align: left;" class="mycode_align">Choose identical GPU models, otherwise the fast model will wait for the slow model, thus you will not get the acceleration.</div>
<div style="text-align: left;" class="mycode_align">Working Principle: batch_size is divided into each GPU. Accordingly, you either get the acceleration due to the fact that less work is allocated to each GPU, or you increase batch_size by the number of GPUs, increasing the quality of the fairy.</div>
<div style="text-align: left;" class="mycode_align">In some cases, disabling the model_opts_on_gpu&nbsp;can speed up your training when using 4 or more GPUs.</div>
<div style="text-align: left;" class="mycode_align">As the number of samples increases, the load on the CPU to generate samples increases. Therefore it is recommended to use the latest generation CPU and memory.</div>
<br>
<div style="text-align: left;" class="mycode_align">NVLink,&nbsp;SLI mot working and not used. Moreover, the SLI enabled may cause errors.</div>
<br>
<div style="text-align: left;" class="mycode_align">Factors that reduce fairy success.&nbsp;</div>
<div style="text-align: left;" class="mycode_align">1. Big face in the frame.</div>
<br>
<div style="text-align: left;" class="mycode_align">2. Side lights. Transitions lighting. Color lighting.</div>
<br>
<div style="text-align: left;" class="mycode_align">3. not a diverse set of dst faces.&nbsp;</div>
<br>
<div style="text-align: left;" class="mycode_align">For example, you train a faceake, where the whole set of dst faces is a one-way turned head. Generating faces in this case can be bad. The solution: extract additional faces of the same actor, train them well enough, then leave only the target faces in dst.</div>
<br>
<div style="text-align: left;" class="mycode_align">Factors that increase the success of the fairy.</div>
<br>
<div style="text-align: left;" class="mycode_align">1. Variety of src faces: different angles including side faces. Variety of lighting.</div>
<br>
<div style="text-align: left;" class="mycode_align">Other.</div>
<br>
<div style="text-align: left;" class="mycode_align">In 2018, when fairies first appeared, people liked any lousy quality of fairies, where the face glimpsed, and was barely like a target celebrity. Now, even in a technically perfect replacement using a parodist similar to the target celebrity, the viral video effect may not be present at all. Popular youtube channels specializing in dipfeikas are constantly inventing something new to keep the audience. If you have watched and watched a lot of movies, know all the memo videos, you can probably come up with great ideas for dipfeik. A good idea is 50% success. The technical quality can be increased through practice.</div>
<br>
<div style="text-align: left;" class="mycode_align">Not all celebrity couples can be well used for a dipfeike. If the size of the skulls is significantly different, the similarity of the result will be extremely low. With experience dipfeik should understand what will be good fairies and what not.</div>
<br>
<br>
<div style="text-align: left;" class="mycode_align">Deepfake tutorial XSeg + Whole Face:</div>
<br>
<div style="text-align: left;" class="mycode_align"><iframe width="560" height="315" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/1smpMsfC3ls.html" frameborder="0" allowfullscreen=""></iframe></div>
		</div>
		
		
		<div class="post_meta" id="post_meta_18976">
                        
                        <div style="" id="tyl_18976"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(18976);return false;" title="[-]" id="tyl_a_expcol_18976"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_18976"></a> 
	<span id="tyl_title_18976" style=""><strong>The following 1 user Likes <a href="https://mrdeepfakes.com/forums/user-iperov"><span style="color: #9ec6e0;"><strong>iperov</strong></span></a>'s post:</strong></span><span id="tyl_title_collapsed_18976" style="display: none;"><strong>1 user Likes <a href="https://mrdeepfakes.com/forums/user-iperov"><span style="color: #9ec6e0;"><strong>iperov</strong></span></a>'s post</strong></span><br>
	<span id="tyl_data_18976" style="">&nbsp;&nbsp;• <span class="smalltext"></span><a href="https://mrdeepfakes.com/forums/user-tomoctocat-gmail-com" class="tt smalltext" title="01-08-2021">tomoctocat@gmail.com</a></span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=4808" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=18976" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_18976_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_18976">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=18976" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_18976").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit --><!-- start: postbit -->

<a name="pid19031" id="pid19031"></a>
<div class="post " style="" id="post_19031">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-tuts"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_24245.jpg" alt="" width="55" height="55"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				Moderator<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat6">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat6">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=19031#pid19031" title="RE: [GUIDE] - DeepFaceLab 2.0 EXPLAINED AND TUTORIALS (recommended)">#7</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">04-15-2020, 01:15 AM <span class="post_edit" id="edited_by_19031"><!-- start: postbit_editedby -->
<span class="edited_post">(This post was last modified: 10-08-2020, 06:38 AM by <a href="https://mrdeepfakes.com/forums/user-tuts">Tuts</a>.)</span>
<!-- end: postbit_editedby --></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_19031">
			<span style="color: #ff3333;" class="mycode_color"><span style="font-size: medium;" class="mycode_size"><span style="font-weight: bold;" class="mycode_b">- reserved for future use -</span></span></span>
		</div>
		
		<!-- start: postbit_signature -->
<div class="panel panel-primary">
<div class="signature scaleimages padding-8px">
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Open for commissions</span>, if you want a custom deepfake made,&nbsp;send me a private message.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="color: #ffcc33;" class="mycode_color">Want to learn DFL and guides aren't enough? I offer DeepFaceLab courses, message me for details.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Also consider donation&nbsp;towards running our website!</span></span></div>

</div>
</div>
<!-- end: postbit_signature -->
		<div class="post_meta" id="post_meta_19031">
                        
                        <div style="display: none;" id="tyl_19031"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(19031);return false;" title="[-]" id="tyl_a_expcol_19031"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_19031"></a> 
	<span id="tyl_title_19031" style=""></span><span id="tyl_title_collapsed_19031" style="display: none;"></span><br>
	<span id="tyl_data_19031" style="">&nbsp;&nbsp;• </span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=24245" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=19031" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_19031_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_19031">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=19031" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_19031").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit --><!-- start: postbit -->

<a name="pid19184" id="pid19184"></a>
<div class="post " style="" id="post_19184">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-jessica2020"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/default_avatar.png" alt="" width="55" height="55"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-jessica2020">Jessica2020</a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				DeepFaker<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				<!-- start: postbit_groupimage -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/member-mdf.png" alt="Validated Users" title="Validated Users" style="height: 25px;">
<!-- end: postbit_groupimage -->
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 52<br>
	Threads: 16<br>
	Likes Received: 6 in 6 posts
<br>
Likes Given: 70<br>

	Joined: Apr 2020
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat7">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat7">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 52<br>
	Threads: 16<br>
	Likes Received: 6 in 6 posts
<br>
Likes Given: 70<br>

	Joined: Apr 2020
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=19184#pid19184" title="RE: [GUIDE] - DeepFaceLab 2.0 EXPLAINED AND TUTORIALS (recommended)">#8</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">04-18-2020, 04:50 PM <span class="post_edit" id="edited_by_19184"><!-- start: postbit_editedby -->
<span class="edited_post">(This post was last modified: 04-18-2020, 04:50 PM by <a href="https://mrdeepfakes.com/forums/user-jessica2020">Jessica2020</a>.)</span>
<!-- end: postbit_editedby --></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_19184">
			Thank you so very much for the updated guide and tutorial - now i understand a lot more and have been able to alter my training accordingly.
		</div>
		
		
		<div class="post_meta" id="post_meta_19184">
                        
                        <div style="" id="tyl_19184"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(19184);return false;" title="[-]" id="tyl_a_expcol_19184"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_19184"></a> 
	<span id="tyl_title_19184" style=""><strong>The following 1 user Likes <a href="https://mrdeepfakes.com/forums/user-jessica2020">Jessica2020</a>'s post:</strong></span><span id="tyl_title_collapsed_19184" style="display: none;"><strong>1 user Likes <a href="https://mrdeepfakes.com/forums/user-jessica2020">Jessica2020</a>'s post</strong></span><br>
	<span id="tyl_data_19184" style="">&nbsp;&nbsp;• <span class="smalltext"></span><a href="https://mrdeepfakes.com/forums/user-demo10mdf" class="tt smalltext" title="04-21-2020">Demo10MDF</a></span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=145954" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=19184" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_19184_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_19184">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=19184" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_19184").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit --><!-- start: postbit -->

<a name="pid19240" id="pid19240"></a>
<div class="post " style="" id="post_19240">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-androsk"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_107450.jpg" alt="" width="55" height="49"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-androsk">androsk</a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				DeepFaker<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				<!-- start: postbit_groupimage -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/member-mdf.png" alt="Validated Users" title="Validated Users" style="height: 25px;">
<!-- end: postbit_groupimage -->
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 70<br>
	Threads: 3<br>
	Likes Received: 20 in 11 posts
<br>
Likes Given: 12<br>

	Joined: Feb 2020
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat8">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat8">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 70<br>
	Threads: 3<br>
	Likes Received: 20 in 11 posts
<br>
Likes Given: 12<br>

	Joined: Feb 2020
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=19240#pid19240" title="RE: [GUIDE] - DeepFaceLab 2.0 EXPLAINED AND TUTORIALS (recommended)">#9</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">04-20-2020, 01:04 AM <span class="post_edit" id="edited_by_19240"></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_19240">
			is there any other method for download beside MEGA?
		</div>
		
		
		<div class="post_meta" id="post_meta_19240">
                        
                        <div style="display: none;" id="tyl_19240"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(19240);return false;" title="[-]" id="tyl_a_expcol_19240"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_19240"></a> 
	<span id="tyl_title_19240" style=""></span><span id="tyl_title_collapsed_19240" style="display: none;"></span><br>
	<span id="tyl_data_19240" style="">&nbsp;&nbsp;• </span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=107450" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=19240" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_19240_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_19240">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=19240" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_19240").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit --><!-- start: postbit -->

<a name="pid19255" id="pid19255"></a>
<div class="post " style="" id="post_19255">
	<div class="post_author">
		<!-- start: postbit_avatar -->
<div class="author_avatar"><a href="https://mrdeepfakes.com/forums/user-tuts"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/avatar_24245.jpg" alt="" width="55" height="55"></a></div>
<!-- end: postbit_avatar -->
		<div class="author_information">
			<strong><span class="large"><a href="https://mrdeepfakes.com/forums/user-tuts"><span style="color: #CC00CC;"><strong>Tuts</strong></span></a></span></strong> <!-- start: postbit_offline -->
<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/buddy_offline.png" title="Offline" alt="Offline" class="buddy_status">
<!-- end: postbit_offline --><br>
			<span class="small">
				Moderator<br>
				<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/star.png" border="0" alt="*"><br>
				
			</span>
		</div>
<div class=" hidden-xs author_statistics">
	<strong><i class="fa fa-dot-circle-o"></i> Author's Statistic:</strong><br>
	<!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user -->
</div>

<script>
$(document).ready(function() {
  $('button.btn-info').each(function(index) {
    $(this).attr('data-target', '.user-stat' + index);
  })

  $('div.user-stat').each(function(index) {
    $(this).removeClass('user-stat');
    $(this).addClass('user-stat' + index);
  })
})
</script>

<div class="visible-xs author_statistics">
  <button type="button" class="btn btn-info" data-toggle="collapse" data-target=".user-stat9">
  <strong><i class="fa fa-eye"></i> Author's Statistic <i class="fa fa-angle-down"></i></strong>
  </button>
  <div class="panel-body collapse user-stat9">
    <div class="col-lg-12 scaleimages padding-8px"><!-- start: postbit_author_user -->
	Posts: 1,621<br>
	Threads: 45<br>
	Likes Received: 474 in 338 posts
<br>
Likes Given: 38<br>

	Joined: Mar 2019
	
<!-- end: postbit_author_user --></div>
  </div>
</div>
	</div>
	<div class="post_content">
		<div class="post_head">
			<!-- start: postbit_posturl -->
<div class="pull-right" style="vertical-align:top">
<!-- IS_UNREAD --><strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?pid=19255#pid19255" title="RE: [GUIDE] - DeepFaceLab 2.0 EXPLAINED AND TUTORIALS (recommended)">#10</a></strong>

</div>
<!-- end: postbit_posturl -->
			
			<span class="post_date">04-20-2020, 10:27 AM <span class="post_edit" id="edited_by_19255"></span></span>
			
		</div>
		<div class="post_body scaleimages" id="pid_19255">
			<blockquote class="mycode_quote"><cite><span> (04-20-2020, 01:04 AM)</span>androsk Wrote:  You are not allowed to view links. <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;signup&#39;);">Register</a> or <a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" onclick="kvsForm(&#39;login&#39;)">Login</a> to view.</cite>is there any other method for download beside MEGA?</blockquote><br>
No, mega is the only way right now.
		</div>
		
		<!-- start: postbit_signature -->
<div class="panel panel-primary">
<div class="signature scaleimages padding-8px">
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #33cc33;" class="mycode_color">Open for commissions</span>, if you want a custom deepfake made,&nbsp;send me a private message.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="color: #ffcc33;" class="mycode_color">Want to learn DFL and guides aren't enough? I offer DeepFaceLab courses, message me for details.</span></div>
<div style="text-align: center;" class="mycode_align"><span style="font-weight: bold;" class="mycode_b"><span style="color: #ff9933;" class="mycode_color">Also consider donation&nbsp;towards running our website!</span></span></div>

</div>
</div>
<!-- end: postbit_signature -->
		<div class="post_meta" id="post_meta_19255">
                        
                        <div style="display: none;" id="tyl_19255"><!-- start: thankyoulike_postbit -->
<div class="post_controls tyllist ">
	<a href="javascript:void(0)" onclick="thankyoulike.tgl(19255);return false;" title="[-]" id="tyl_a_expcol_19255"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/collapse.png" alt="[-]" id="tyl_i_expcol_19255"></a> 
	<span id="tyl_title_19255" style=""></span><span id="tyl_title_collapsed_19255" style="display: none;"></span><br>
	<span id="tyl_data_19255" style="">&nbsp;&nbsp;• </span>
</div>
<!-- end: thankyoulike_postbit --></div>
		</div>
	</div>

    	<div class="panel-footer post_controls">
		<div class="postbit_buttons author_buttons pull-left">
			<!-- start: postbit_find -->
<a href="https://mrdeepfakes.com/forums/search.php?action=finduser&amp;uid=24245" title="Find all posts by this user" class="tt postbit_find"><span>Find</span></a>
<!-- end: postbit_find -->
<!-- AddToAny BEGIN -->
<a class="a2a_dd" href="https://www.addtoany.com/share#url=https%3A%2F%2Fmrdeepfakes.com%2Fforums%2Fthread-guide-deepfacelab-2-0-guide&amp;title=%5BGUIDE%5D%20-%20DeepFaceLab%202.0%20Guide">Share</a>
<script async="" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/page.js.download"></script>
<!-- AddToAny END -->
		</div>
		<div class="postbit_buttons author_buttons pull-right">
			<!-- start: postbit_quote -->
<a href="https://mrdeepfakes.com/forums/newreply.php?tid=3886&amp;replyto=19255" title="Quote this message in a reply" class="tt postbit_quote"><span>Reply</span></a>
<!-- end: postbit_quote -->
		</div>	
<div id="edit_post_19255_popup" class="popup_menu1" style="display: none;"><div class="popup_item_container"><a href="javascript:;" class="popup_item quick_edit_button" id="quick_edit_post_19255">Quick Edit</a></div><div class="popup_item_container"><a href="https://mrdeepfakes.com/forums/editpost.php?pid=19255" class="popup_item">Full Edit</a></div></div>   
<script type="text/javascript">
// <!--
	if(use_xmlhttprequest == "1")
	{
		$("#edit_post_19255").popupMenu();
	}
// -->
	</script>		
	</div>
</div>
<!-- end: postbit -->
					</div>
				</div>
			</div>
		</div>
		<div class="panel-footer no-padding">
			<div class="row small">
				<div class="col-lg-6 padding-8px">
					<strong><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?action=nextoldest"><i class="fa fa-caret-left" aria-hidden="true"></i>&nbsp;Next Oldest</a>&nbsp;|&nbsp;<a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?action=nextnewest">Next Newest&nbsp;<i class="fa fa-caret-right" aria-hidden="true"></i></a></strong>				
				</div>
				<div class="col-lg-6">
					<!-- start: showthread_search -->
<form action="https://mrdeepfakes.com/forums/search.php" method="post">
	<input type="hidden" name="action" value="thread">
	<input type="hidden" name="tid" value="3886">
	<div class="input-group">		
		<input type="text" name="keywords" value="Enter Keywords" onfocus="if(this.value == &#39;Enter Keywords&#39;) { this.value = &#39;&#39;; }" onblur="if(this.value==&#39;&#39;) { this.value=&#39;Enter Keywords&#39;; }" class="form-control input-sm" size="25">
	<span class="input-group-btn">		
		<button type="submit" class="btn btn-sm btn-primary" value="Search Thread">Search Thread</button>
	</span>
	</div>	
</form>
<!-- end: showthread_search -->
				</div>			
			</div>		
		</div>
	</div>
	<div class="row">		
		<div class="col-lg-12 text-right">
			
		</div>	
	</div>
</div>
<!-- start: multipage -->
<div class="container-fluid">
	<div class="row"> 		
 		<div class="col-lg-12 text-right">
			<ul class="pagination pagination-sm">
				<!-- start: multipage_page_current -->
<li class="active"><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#">1<span class="sr-only">(current)</span></a></li>
<!-- end: multipage_page_current --><!-- start: multipage_page -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=2">2</a></li>
<!-- end: multipage_page --><!-- start: multipage_page -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=3">3</a></li>
<!-- end: multipage_page --><!-- start: multipage_page -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=4">4</a></li>
<!-- end: multipage_page --><!-- start: multipage_page -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=5">5</a></li>
<!-- end: multipage_page --><!-- start: multipage_end -->
...  <li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=33">33</a></li>
<!-- end: multipage_end --><!-- start: multipage_nextpage -->
<li><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=2">Next&nbsp;<i class="fa fa-angle-double-right"></i></a></li>
<!-- end: multipage_nextpage --><!-- start: multipage_jump_page -->
<div class="dropdown pull-right">
  <button class="btn btn-sm btn-primary dropdown-toggle" type="button" data-toggle="dropdown">
  <i class="fa fa-arrow-down" title="Jump to page"></i></button>
	<ul class="dropdown-menu">
		<li class="padding-8px">
			<form action="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide?page=1" method="post">
				<label for="page">Jump to page:<input type="text" class="form-control input-sm" name="page" id="page" value="1" size="4"></label>
				<input type="submit" class="btn btn-sm btn-primary" value="Go">
			</form>
		</li>
	</ul>	
</div>
<script>
	var go_page = 'go_page_' + $(".go_page").length;
	$(".go_page").last().attr('id', go_page);
	$(".drop_go_page").last().attr('id', go_page + '_popup');
	$('#' + go_page).popupMenu(false).click(function() {
		var drop_go_page = $(this).prev('.drop_go_page');
		if (drop_go_page.is(':visible')) {
			drop_go_page.find('.textbox').focus();
		}
	});
</script>
<!-- end: multipage_jump_page -->
			</ul>
		</div>
	</div>	
</div>
<!-- end: multipage -->	
<div class="container-fluid">	
	
	
	
	<br>	
	<div class="row">
		<div class="col-lg-5 col-lg-offset-7">
			
			<!-- start: forumjump_advanced -->
<form action="https://mrdeepfakes.com/forums/forumdisplay.php" method="get">
<span class="small"><strong>Forum Jump:</strong></span>
<div class="input-group">
<select class="form-control input-sm" name="fid">
<option value="-4">Private Messages</option>
<option value="-3">User Control Panel</option>
<option value="-5">Who's Online</option>
<option value="-2">Search</option>
<option value="-1">Forum Home</option>
<!-- start: forumjump_bit -->
<option value="3"> Announcements</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="4">-- Important Announcements and News</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="16">-- How to Use Features of MrDeepFakes.com</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="8"> Adult Content (18+)</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="9">-- Celebrity DeepFakes</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="10">-- Requests</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="30">---- PAID Requests</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="14"> Non-Adult Content (All Ages)</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="19">-- SFW DeepFake Videos</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="21">-- Requests</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="5"> DeepFake Creation Tools</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="15" selected="selected">-- Guides and Tutorials</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="17">-- Celebrity Facesets</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="35">---- Requests</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="22">-- Pornstar Facesets</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="34">-- Trained Models</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="26">-- Celebrity to Pornstar Matches</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="18">-- Downloads</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="41">---- Unofficial Mods</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="12">-- Questions</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="31"> Image Fakes (18+)</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="32">-- Celebrity Photo Fakes</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="37">-- Tools and Apps</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="33">-- Requests</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="6"> Lounge</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="11">-- Discussion</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="23">-- Claim Credit/Flag Videos</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="13">-- Suggestions and Feedback</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="45"> Other Languages</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="43">-- Russian Community</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="51">---- Discussion</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="48">---- Guides and Tutorials</option>
<!-- end: forumjump_bit --><!-- start: forumjump_bit -->
<option value="49">---- Questions</option>
<!-- end: forumjump_bit -->
</select>
<span class="input-group-btn"><!-- start: gobutton -->
<input type="submit" class="btn btn-sm btn-primary" value="Go">
<!-- end: gobutton --></span>
</div>		
</form>
<script>
$(".forumjump").change(function() {
	var option = $(this).val();

	if(option < 0)
	{
		window.location = 'forumdisplay.php?fid='+option;
	}
	else
	{
		window.location = 'forumdisplay.php?fid='+option;
	}
});
</script>
<!-- end: forumjump_advanced -->		
		</div>
	</div>	
	<!-- start: showthread_usersbrowsing -->
<br>
<div class="row">
	<div class="col-lg-12 small">Users browsing this thread: <a href="https://mrdeepfakes.com/forums/user-auphone" title="Reading... (11:45 AM)">auphone</a>, <a href="https://mrdeepfakes.com/forums/user-fake-eq" title="Reading... (11:48 AM)">fake_eq</a>, <a href="https://mrdeepfakes.com/forums/user-random10100" title="Reading... (11:54 AM)">random10100</a>, <a href="https://mrdeepfakes.com/forums/user-son324" title="Reading... (11:55 AM)">Son324</a>, 10 Guest(s)</div>
</div>
<br>
<!-- end: showthread_usersbrowsing -->
</div>	
	<!-- start: footer -->
		<div class="container-fluid"><!--OUGC_SPOILER--></div>
	</div>
</div>
</div>
<a id="back-to-top" href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#" class="btn btn-sm btn-primary back-to-top" role="button" title="" data-toggle="tooltip" data-placement="left" data-original-title="Click to return to the top of page" aria-describedby="tooltip676289" style="display: inline;"><i class="fa fa-chevron-up"></i></a><div class="tooltip fade left in" role="tooltip" id="tooltip676289" style="top: 0px; left: -197px; display: block;"><div class="tooltip-arrow" style="top: 0%;"></div><div class="tooltip-inner">Click to return to the top of page</div></div>
<br>
<footer>	
	<div class="footer-link">
				<div class="footer col-lg-3">
					<div class="logo-footer" style="text-align: center;">
						<div class="lg-footer clearbb"><a href="https://mrdeepfakes.com/forums/index.php"><img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/forums_logo.png" alt="MrDeepFakes Forums" title="MrDeepFakes Forums"></a></div>
						<p>©2021 <a href="https://mrdeepfakes.com/forums">All Rights Reserved.</a></p>
					</div>
		<div class="social">	
            <a href="https://mrdeepfakes.com/forums/search.php?action=getnew" class="tt icon-button newposts" title="View New Posts"><i class="fa fa-eye"></i><span></span></a>
            <a href="https://mrdeepfakes.com/forums/stats.php" class="tt icon-button fstats" title="Forum Stats"><i class="fa fa-bar-chart"></i><span></span></a>
            <a href="https://mrdeepfakes.com/forums/archive/index.php/thread-3886.html" class="tt icon-button litemod" title="Lite (Archive) Mode"><i class="fa fa-archive"></i><span></span></a>
			<!-- start: footer_contactus -->
<a href="https://mrdeepfakes.com/forums/hello@mrdeepfakes.com" class="tt icon-button contact" title="Contact Us"><i class="fa fa-envelope"></i><span></span></a>
<!-- end: footer_contactus -->			        
		</div>
				</div>
				<div class="footer col-lg-8">					
					<div class="footer-description">
						<div class="title-footer-links"><i class="fa fa-home"></i>MrDeepFakes Forums</div>
						<div>
MrDeepFakes is the largest deepfake community still actively running, and is dedicated to the members of the deepfake community. The purpose of these forums is to provide a safe-haven without censorship, where users can learn about this new AI technology, share deepfake videos, and promote developement of deepfake apps. Everything related to deepfakes can be found on these forums, but it is important to remember that deepfakes are fake videos, and any content you find at MrDeepFakes is likely fake. These deepfakes are created for entertainment and learning purposes only.<br> 
</div>
					</div>				
			    </div>
	</div>
<div class="footer-icons">
		<div class="copyright col-lg-7 pull-left">
					<a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#"><i style="margin-top: 6px;" class="fa fa-youtube"></i></a>
<a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide#"><i style="margin-top: 6px;" class="fa fa-facebook"></i></a>
					<a href="https://twitter.com/mr_deepfakes"><i style="margin-top: 6px;" class="fa fa-twitter"></i></a>
					<a href="https://mrdeepfakes.tumblr.com/"><i style="margin-top: 6px;" class="fa fa-tumblr"></i></a>

				</div>
			
			<!-- The following piece of code allows MyBB to run scheduled tasks. DO NOT REMOVE --><!-- End task image code --><!-- UNREADPOSTS_CSS --><!-- UNREADPOSTS_JS -->

		</div> 
		<div class="col-lg-4 pull-right text-right">
     		<ul class="nav navbar-nav navbar-right text-center">
					
						
      		</ul>	
		</div>
	</footer></div><div style="position: static;"><div class="a2a_overlay" id="a2a_overlay"></div><div id="a2a_modal" class="a2a_modal" role="dialog" tabindex="-1" aria-label="" style="display:none"><div class="a2a_modal_body a2a_menu" id="a2a_copy_link" style="display:none"><span id="a2a_copy_link_icon" class="a2a_svg a2a_s_link" style="background-color:#0166ff"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path fill="#FFF" d="M24.4 21.18c0-.36-.1-.67-.36-.92l-2.8-2.8a1.24 1.24 0 0 0-.92-.38c-.38 0-.7.14-.97.43.02.04.1.12.25.26l.3.3.2.24c.08.12.14.24.17.35.03.1.05.23.05.37 0 .36-.13.66-.38.92a1.25 1.25 0 0 1-.92.37 1.4 1.4 0 0 1-.37-.03 1.06 1.06 0 0 1-.35-.18 2.27 2.27 0 0 1-.25-.2 6.82 6.82 0 0 1-.3-.3l-.24-.25c-.3.28-.44.6-.44.98 0 .36.13.66.38.92l2.78 2.8c.24.23.54.35.9.35.37 0 .68-.12.93-.35l1.98-1.97c.26-.25.38-.55.38-.9zm-9.46-9.5c0-.37-.13-.67-.38-.92l-2.78-2.8a1.24 1.24 0 0 0-.9-.37c-.36 0-.67.1-.93.35L7.97 9.92c-.26.25-.38.55-.38.9 0 .36.1.67.37.92l2.8 2.8c.24.25.55.37.92.37.36 0 .7-.13.96-.4-.03-.04-.1-.12-.26-.26s-.24-.23-.3-.3a2.67 2.67 0 0 1-.2-.24 1.05 1.05 0 0 1-.17-.35 1.4 1.4 0 0 1-.04-.37c0-.36.1-.66.36-.9.26-.26.56-.4.92-.4.14 0 .26.03.37.06.12.03.23.1.35.17.1.1.2.16.25.2l.3.3.24.26c.3-.28.44-.6.44-.98zM27 21.17c0 1.07-.38 2-1.15 2.73l-1.98 1.98c-.74.75-1.66 1.12-2.73 1.12-1.1 0-2-.38-2.75-1.14l-2.8-2.8c-.74-.74-1.1-1.65-1.1-2.73 0-1.1.38-2.04 1.17-2.82l-1.18-1.17c-.8.8-1.72 1.18-2.82 1.18-1.08 0-2-.36-2.75-1.12l-2.8-2.8C5.38 12.8 5 11.9 5 10.82c0-1.08.38-2 1.15-2.74L8.13 6.1C8.87 5.37 9.78 5 10.86 5c1.1 0 2 .38 2.75 1.15l2.8 2.8c.74.73 1.1 1.65 1.1 2.72 0 1.1-.38 2.05-1.17 2.82l1.18 1.18c.8-.8 1.72-1.2 2.82-1.2 1.08 0 2 .4 2.75 1.14l2.8 2.8c.76.76 1.13 1.68 1.13 2.76z"></path></svg></span><input id="a2a_copy_link_text" type="text" title="Copy link" readonly=""><div id="a2a_copy_link_copied">✓</div></div><div class="a2a_modal_body a2a_menu a2a_thanks" id="a2a_thanks" style="display:none"><div class="a2a_localize" data-a2a-localize="inner,ThanksForSharing">Thanks for sharing!</div></div></div><div class="a2a_menu a2a_full a2a_localize" id="a2apage_full" role="dialog" tabindex="-1" aria-label="Share" data-a2a-localize="title,Share"><div class="a2a_full_header"><div id="a2apage_find_container" class="a2a_menu_find_container"><input id="a2apage_find" class="a2a_menu_find a2a_localize" type="text" autocomplete="off" title="Find any service" data-a2a-localize="title,FindAnyServiceToAddTo"><span id="a2apage_find_icon" class="a2a_svg a2a_s_find"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="#CCC" d="M19.7 18.2l-4.5-4.5c.7-1.1 1.2-2.3 1.2-3.6 0-3.5-2.8-6.3-6.3-6.3s-6.3 2.8-6.3 6.3 2.8 6.3 6.3 6.3c1.4 0 2.6-.4 3.6-1.2l4.5 4.5c.6.6 1.3.7 1.7.2.5-.4.4-1.1-.2-1.7zm-9.6-3.6c-2.5 0-4.5-2.1-4.5-4.5 0-2.5 2.1-4.5 4.5-4.5 2.5 0 4.5 2.1 4.5 4.5s-2 4.5-4.5 4.5z"></path></svg></span></div></div><div class="a2a_full_services" id="a2apage_full_services" role="presentation"></div><div class="a2a_full_footer"><a href="https://www.addtoany.com/" title="Share Buttons" rel="noopener" target="_blank"><span class="a2a_svg a2a_s__default a2a_s_a2a" style="background-color:#0166ff"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><g fill="#FFF"><path d="M14 7h4v18h-4z"></path><path d="M7 14h18v4H7z"></path></g></svg></span>AddToAny</a></div></div><div id="a2apage_dropdown" class="a2a_menu a2a_mini a2a_localize" tabindex="-1" aria-label="Share" data-a2a-localize="label,Share" style="display:none"><div id="a2apage_title_container" class="a2a_menu_title_container" style="display:none"><div id="a2apage_title" class="a2a_menu_title"></div></div><div class="a2a_mini_services" id="a2apage_mini_services"></div><div id="a2apage_cols_container" class="a2a_cols_container"><div class="a2a_col1" id="a2apage_col1"></div><div id="a2apage_2_col1" style="display:none"></div><div class="a2a_clear"></div></div><div class="a2apage_wide a2a_wide"><a href="https://mrdeepfakes.com/forums/thread-guide-deepfacelab-2-0-guide" id="a2apage_show_more_less" class="a2a_menu_show_more_less a2a_more a2a_localize" title="Show all" data-a2a-localize="title,ShowAll"><span class="a2a_svg a2a_s__default a2a_s_a2a" style="background-color:#0166ff"><svg focusable="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><g fill="#FFF"><path d="M14 7h4v18h-4z"></path><path d="M7 14h18v4H7z"></path></g></svg></span><span class="a2a_localize" data-a2a-localize="inner,More">More…</span></a></div></div></div>
	
<!-- The following piece of code allows MyBB to run scheduled tasks. DO NOT REMOVE --><!-- End task image code --><!-- UNREADPOSTS_CSS --><!-- UNREADPOSTS_JS --><!-- UNREADPOSTS_JS -->


<script src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/bootstrap.min.js.download"></script>
<script>
$(document).ready(function(){
     $(window).scroll(function () {
            if ($(this).scrollTop() > 50) {
                $('#back-to-top').fadeIn();
            } else {
                $('#back-to-top').fadeOut();
            }
        });
        // scroll body to 0px on click
        $('#back-to-top').click(function () {
            $('#back-to-top').tooltip('hide');
            $('body,html').animate({
                scrollTop: 0
            }, 800);
            return false;
        });
        $('#back-to-top').tooltip('show');
});
</script>

<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/jquery.tipsy.js.download"></script>
<script>
$('.tt').tipsy({position: 'top-right',})
</script><!-- MentionMe Autocomplete Scripts -->
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/jquery.caret.min.js.download"></script>
<script type="text/javascript" src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/autocomplete.min.js.download"></script>
<script type="text/javascript">
<!--
	MentionMe.autoComplete.setup({
		lang: {
			instructions: 'type a user name',
		},
		maxLength: '30',
		maxItems: '5',
		minWidth: '120',
		tid: '3886',
		fullText: '0',
		showAvatars: '1',
		imageDirectory: 'https://mrdeepfakes.com/forums/images/generic',
		lockSelection: '1',
	});
// -->
</script><!-- start: mentionme_popup -->
<div id="mentionme_master_popup" class="mentionme_popup" style="display: none;">
	<div class="mentionme_spinner">
		<img src="./[GUIDE] - DeepFaceLab 2.0 Guide_files/spinner.gif">
		<span></span>
	</div>
	<div class="mentionme_popup_input_container">
		<input class="mentionme_popup_input" type="text" autocomplete="off">
	</div>
	<div class="mentionme_popup_body"></div>
</div>
<!-- end: mentionme_popup -->
<!-- <script src="jscripts/winter/snowstorm-min.js"></script> -->
<!-- end: footer -->
	<script>
	// <!--
		if(use_xmlhttprequest == "1")
		{
			$("#thread_modes").popupMenu();
		}
	// -->
	</script>
	<script>
		$(".author_avatar img").error(function () {
			$(this).unbind("error").closest('.author_avatar').remove();

		});
	</script>


<!-- end: showthread --></body></html>